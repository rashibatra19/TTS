clips/audio_1.wav|There is a really old blog entry from Twi-lee-oh about testing the T T S in browser|There is a really old blog entry from Twi-lee-oh about testing the T T S in browser
clips/audio_2.wav|Unfortunately it doesn't contain enough information to put a test together|Unfortunately it doesn't contain enough information to put a test together
clips/audio_3.wav|It also contains a number of dead links and mentions a Github project that I can't find.|It also contains a number of dead links and mentions a Github project that I can't find.
clips/audio_4.wav|I'd really like for users to have the ability to hear what their announcement will sound like prior to firing off the form and starting the phone calls.|I'd really like for users to have the ability to hear what their announcement will sound like prior to firing off the form and starting the phone calls.
clips/audio_5.wav|I use Lasso which fires off CU R L requests to the Twi-lee-oh REST A P I, but any kind of tutorials or hints would be appreciated.|I use Lasso which fires off CU R L requests to the Twi-lee-oh REST A P I, but any kind of tutorials or hints would be appreciated.
clips/audio_6.wav|If you set up a demo account on Twi-lee-oh and use Glitch online php tester  or a local environment you can create a workable example like I did|If you set up a demo account on Twi-lee-oh and use Glitch online php tester  or a local environment you can create a workable example like I did
clips/audio_7.wav|Search for TwiML in the website to get to the right section to set the right url of your server that TWilio will call upon request to read content xml|Search for TwiML in the website to get to the right section to set the right url of your server that TWilio will call upon request to read content xml
clips/audio_8.wav|You need to grab the Twi-lee-oh P H P S D K and include the ServicesTwi-lee-ohCapability.php from  in your server code.|You need to grab the Twi-lee-oh P H P S D K and include the ServicesTwi-lee-ohCapability.php from  in your server code.
clips/audio_9.wav|Required, but never shown|Required, but never shown
clips/audio_10.wav|Required, but never shown|Required, but never shown
clips/audio_11.wav|Text To Speech T T S, also known as speech sin-thuh-sis, is a process in which text is converted into a human-sounding voice|Text To Speech T T S, also known as speech sin-thuh-sis, is a process in which text is converted into a human-sounding voice
clips/audio_12.wav|Developers and business users alike use T T S to turn traditional human-to-human interactions into seamless, machine-to-human interactions, and make every interaction over voice a frictionless and first-class experience.|Developers and business users alike use T T S to turn traditional human-to-human interactions into seamless, machine-to-human interactions, and make every interaction over voice a frictionless and first-class experience.
clips/audio_13.wav|Instead of recording audio files with human voices to play back in a call, which has limited flexibility and is not a scalable option, T T S prompts can be dynamically, programmatically generated from raw text as a response to events in your application|Instead of recording audio files with human voices to play back in a call, which has limited flexibility and is not a scalable option, T T S prompts can be dynamically, programmatically generated from raw text as a response to events in your application
clips/audio_14.wav|T T S is available via the Say TwiML verb and Studio's SayPlay Widget.|T T S is available via the Say TwiML verb and Studio's SayPlay Widget.
clips/audio_15.wav|To start using T T S, complete the following steps|To start using T T S, complete the following steps
clips/audio_16.wav|Twi-lee-oh Studio is a visual, serverless tool that uses Widgets to represent various parts of Twi-lee-oh's platform features and functionality to design and build applications with little or no code.|Twi-lee-oh Studio is a visual, serverless tool that uses Widgets to represent various parts of Twi-lee-oh's platform features and functionality to design and build applications with little or no code.
clips/audio_17.wav|The SayPlay Widget allows you to add Text To Speech capabilities to your application with ease, including embedding SSML for supported voices.|The SayPlay Widget allows you to add Text To Speech capabilities to your application with ease, including embedding SSML for supported voices.
clips/audio_18.wav|To start using T T S with Studio, complete the following steps|To start using T T S with Studio, complete the following steps
clips/audio_19.wav|They can be used to get started and familiarize yourself with Text To Speech capabilities using Say, but may not have enough human-like qualities to build conversational applications and deliver superior user experiences over a voice call|They can be used to get started and familiarize yourself with Text To Speech capabilities using Say, but may not have enough human-like qualities to build conversational applications and deliver superior user experiences over a voice call
clips/audio_20.wav|The voices in this tier are available in a limited number of languages at no cost.|The voices in this tier are available in a limited number of languages at no cost.
clips/audio_21.wav|Standard voices offer standard T T S technology and produce natural-sounding synthesized speech with a variety of lifelike voices|Standard voices offer standard T T S technology and produce natural-sounding synthesized speech with a variety of lifelike voices
clips/audio_22.wav|The voices in this tier are provided by Amazon Amazon Polly and Google Standard, with support for SSML Speech Synthesis Markup Language, which allows developers to control many aspects of the synthesized speech.|The voices in this tier are provided by Amazon Amazon Polly and Google Standard, with support for SSML Speech Synthesis Markup Language, which allows developers to control many aspects of the synthesized speech.
clips/audio_23.wav|These voices are generated using the latest technology and innovation in synthesized speech, providing the most human-like, expressive and natural-sounding text to speech voices possible, with higher quality than Standard voices|These voices are generated using the latest technology and innovation in synthesized speech, providing the most human-like, expressive and natural-sounding text to speech voices possible, with higher quality than Standard voices
clips/audio_24.wav|See the Pricing section below for additional information.|See the Pricing section below for additional information.
clips/audio_25.wav|Effective June 26 2023, Alice voices are no longer supported for Text-To-Speech and any request will be redirected to an alternate voice|Effective June 26 2023, Alice voices are no longer supported for Text-To-Speech and any request will be redirected to an alternate voice
clips/audio_26.wav|For more information, visit the Changeloglink takes you to an external page.|For more information, visit the Changeloglink takes you to an external page.
clips/audio_27.wav|You can test the different voices from the T T S Settingslink takes you to an external page page in the Twi-lee-oh Console.|You can test the different voices from the T T S Settingslink takes you to an external page page in the Twi-lee-oh Console.
clips/audio_28.wav|Note Invalid combination of voice and language attributes may result in error and Say instruction failure.|Note Invalid combination of voice and language attributes may result in error and Say instruction failure.
clips/audio_29.wav|At the moment only Amazon Polly has this capability for a limited number of voices|At the moment only Amazon Polly has this capability for a limited number of voices
clips/audio_30.wav|With these T T S settings, Twi-lee-oh uses the Man voice and the en-US American English accent and pronunciation when executing the following TwiML|With these T T S settings, Twi-lee-oh uses the Man voice and the en-US American English accent and pronunciation when executing the following TwiML
clips/audio_31.wav|This means that you can specify the language without needing to specifying the voice when using T T S capabilities in your application.|This means that you can specify the language without needing to specifying the voice when using T T S capabilities in your application.
clips/audio_32.wav|For example, if you configure English Britishen-gigabyte to use Amazon Polly and Emma, Twi-lee-oh uses the Amazon Polly Emma voice when executing Say with the language attribute set to en-gigabyte and no voice attribute see TwiML example below.|For example, if you configure English Britishen-gigabyte to use Amazon Polly and Emma, Twi-lee-oh uses the Amazon Polly Emma voice when executing Say with the language attribute set to en-gigabyte and no voice attribute see TwiML example below.
clips/audio_33.wav|For example, if your Account's default T T S voice is Amazon Polly Salli but you want to use Amazon Polly Joanna for a specific call, set the voice attribute to Polly.Joanna|For example, if your Account's default T T S voice is Amazon Polly Salli but you want to use Amazon Polly Joanna for a specific call, set the voice attribute to Polly.Joanna
clips/audio_34.wav|For example, if your Language Mapping for English Britishen-gigabyte uses Amazon Polly and Emma but you want to use the Amazon Polly Joanna voice for a specific Say instruction, you would use the voice attribute set to Polly.Joanna|For example, if your Language Mapping for English Britishen-gigabyte uses Amazon Polly and Emma but you want to use the Amazon Polly Joanna voice for a specific Say instruction, you would use the voice attribute set to Polly.Joanna
clips/audio_35.wav|For example, if your Account's default T T S Language is English US en-US, but wish to use German for a specific call, set the language attribute to de-DE in your TwiML|For example, if your Account's default T T S Language is English US en-US, but wish to use German for a specific call, set the language attribute to de-DE in your TwiML
clips/audio_36.wav|Speech Synthesis Markup Language SSMLlink takes you to an external page uses X M L-based tags that allow you to fine-tune the synthesized speech generated by T T S|Speech Synthesis Markup Language SSMLlink takes you to an external page uses X M L-based tags that allow you to fine-tune the synthesized speech generated by T T S
clips/audio_37.wav|In addition, SSML support including tags and accepted values may differ between T T S providers andor may be limited to specific voices|In addition, SSML support including tags and accepted values may differ between T T S providers andor may be limited to specific voices
clips/audio_38.wav|Use of unsupported SSML tags with any T T S provider may result in error and Say instruction failure.|Use of unsupported SSML tags with any T T S provider may result in error and Say instruction failure.
clips/audio_39.wav|The SSML prah-suh-dee tag allows you to control the volume, rate, and pitch of synthesized speech.|The SSML prah-suh-dee tag allows you to control the volume, rate, and pitch of synthesized speech.
clips/audio_40.wav|Without say-as, a phone number would be pronounced as a number, e.g|Without say-as, a phone number would be pronounced as a number, e.g
clips/audio_41.wav|The TwiML example below uses say-as so that the synthesized speech reads the phone number as "four one five, five five five, one two one two."|The TwiML example below uses say-as so that the synthesized speech reads the phone number as "four one five, five five five, one two one two."
clips/audio_42.wav|You can generate TwiML with SSML within the Say verb using one of Twi-lee-oh's helper libraries for Clink takes you to an external page, Javalink takes you to an external page, Node J Slink takes you to an external page, P H Plink takes you to an external page, Pythonlink takes you to an external page, Rubylink takes you to an external page, or Golink takes you to an external page.|You can generate TwiML with SSML within the Say verb using one of Twi-lee-oh's helper libraries for Clink takes you to an external page, Javalink takes you to an external page, Node J Slink takes you to an external page, P H Plink takes you to an external page, Pythonlink takes you to an external page, Rubylink takes you to an external page, or Golink takes you to an external page.
clips/audio_43.wav|Note Use of unsupported SSML tags with any T T S provider may result in error and Say instruction failure|Note Use of unsupported SSML tags with any T T S provider may result in error and Say instruction failure
clips/audio_44.wav|A software development kit S D K is a collection of software development tools in one installable package|A software development kit S D K is a collection of software development tools in one installable package
clips/audio_45.wav|They are normally specific to a hardware platform and operating system combination|They are normally specific to a hardware platform and operating system combination
clips/audio_46.wav|Some S D Ks are required for developing a platform-specific app|Some S D Ks are required for developing a platform-specific app
clips/audio_47.wav|For example, the development of an Android app on the Java platform requires a Java Development Kit|For example, the development of an Android app on the Java platform requires a Java Development Kit
clips/audio_48.wav|For iOS applications apps the iOS S D K is required|For iOS applications apps the iOS S D K is required
clips/audio_49.wav|For Universal Windows Platform the .NET Framework S D K might be used|For Universal Windows Platform the .NET Framework S D K might be used
clips/audio_50.wav|There are also S D Ks that add additional features and can be installed in apps to provide analytics, data about application activity, and monetization options|There are also S D Ks that add additional features and can be installed in apps to provide analytics, data about application activity, and monetization options
clips/audio_51.wav|Some prominent creators of these types of S D Ks include Google, Smaato, InMobi, and Facebook.|Some prominent creators of these types of S D Ks include Google, Smaato, InMobi, and Facebook.
clips/audio_52.wav|An S D K can take the form of application programming interfaces1 in the form of on-device libraries of reusable functions used to interface to a particular programming language, or it may be as complex as hardware-specific tools that can communicate with a particular embedded system.2 Common tools include debugging facilities and other utilities, often presented in an integrated development environment.3 S D Ks may include sample software andor technical notes along with documentation, and tutorials to help clarify points made by the primary reference material.45|An S D K can take the form of application programming interfaces1 in the form of on-device libraries of reusable functions used to interface to a particular programming language, or it may be as complex as hardware-specific tools that can communicate with a particular embedded system.2 Common tools include debugging facilities and other utilities, often presented in an integrated development environment.3 S D Ks may include sample software andor technical notes along with documentation, and tutorials to help clarify points made by the primary reference material.45
clips/audio_53.wav|S D Ks often include licenses that make them unsuitable for building software intended to be developed under an incompatible license|S D Ks often include licenses that make them unsuitable for building software intended to be developed under an incompatible license
clips/audio_54.wav|For example, a proprietary S D K is generally incompatible with free software development, while a GNU General Public License'd S D K could be incompatible with proprietary software development, for legal reasons.67 However, S D Ks built under the GNU Lesser General Public License are typically usable for proprietary development.8  In cases where the underlying technology is new, S D Ks may include hardware|For example, a proprietary S D K is generally incompatible with free software development, while a GNU General Public License'd S D K could be incompatible with proprietary software development, for legal reasons.67 However, S D Ks built under the GNU Lesser General Public License are typically usable for proprietary development.8  In cases where the underlying technology is new, S D Ks may include hardware
clips/audio_55.wav|For example, AirTag's 2021 near-field communication S D K included both the paying and the reading halves of the necessary hardware stack.9|For example, AirTag's 2021 near-field communication S D K included both the paying and the reading halves of the necessary hardware stack.9
clips/audio_56.wav|The average Android mobile app implements 15.6 separate S D Ks, with gaming apps implementing on average 17.5 different S D Ks.1011 The most popular S D K categories for Android mobile apps are analytics and advertising.11|The average Android mobile app implements 15.6 separate S D Ks, with gaming apps implementing on average 17.5 different S D Ks.1011 The most popular S D K categories for Android mobile apps are analytics and advertising.11
clips/audio_57.wav|S D Ks can be unsafe because they are implemented within apps yet run separate code|S D Ks can be unsafe because they are implemented within apps yet run separate code
clips/audio_58.wav|Malicious S D Ks with honest intentions or not can violate users' data privacy, damage app performance, or even cause apps to be banned from Google Play or the App Store.12 New technologies allow app developers to control and monitor client S D Ks in real time.|Malicious S D Ks with honest intentions or not can violate users' data privacy, damage app performance, or even cause apps to be banned from Google Play or the App Store.12 New technologies allow app developers to control and monitor client S D Ks in real time.
clips/audio_59.wav|Providers of S D Ks for specific systems or subsystems sometimes substitute a more specific term instead of software|Providers of S D Ks for specific systems or subsystems sometimes substitute a more specific term instead of software
clips/audio_60.wav|Examples of software development kits for various platforms include|Examples of software development kits for various platforms include
clips/audio_61.wav|Using T T S|Using T T S
clips/audio_62.wav|T T S Models|T T S Models
clips/audio_63.wav| T T Sv2 is here with 16 languages and better performance across the board.| T T Sv2 is here with 16 languages and better performance across the board.
clips/audio_64.wav| T T S fine-tuning code is out| T T S fine-tuning code is out
clips/audio_65.wav| T T S can now stream with two hundredms latency.| T T S can now stream with two hundredms latency.
clips/audio_66.wav| T T S, our production T T S model that can speak 13 languages, is released Blog Post, Demo, Docs| T T S, our production T T S model that can speak 13 languages, is released Blog Post, Demo, Docs
clips/audio_67.wav| You can use 1100 Fairseq models with T T S.| You can use 1100 Fairseq models with T T S.
clips/audio_68.wav| T T S now supports Tortoise with faster inference| T T S now supports Tortoise with faster inference
clips/audio_69.wav| Voice generation with prompts - Prompt to Voice - is live on Coqui Studio!! - Blog Post| Voice generation with prompts - Prompt to Voice - is live on Coqui Studio!! - Blog Post
clips/audio_70.wav| Voice generation with fusion - Voice fusion - is live on Coqui Studio.| Voice generation with fusion - Voice fusion - is live on Coqui Studio.
clips/audio_71.wav| Voice cloning is live on Coqui Studio.| Voice cloning is live on Coqui Studio.
clips/audio_72.wav|T T S is a library for advanced Text-to-Speech generation.|T T S is a library for advanced Text-to-Speech generation.
clips/audio_73.wav| pre-trained models in 1100 languages.| pre-trained models in 1100 languages.
clips/audio_74.wav| Tools for training new models and fine-tuning existing models in any language.| Tools for training new models and fine-tuning existing models in any language.
clips/audio_75.wav| Utilities for dataset analysis and curation.| Utilities for dataset analysis and curation.
clips/audio_76.wav|Platforms|Platforms
clips/audio_77.wav|T T SREADME.md|T T SREADME.md
clips/audio_78.wav|T T S Releases and Experimental Models|T T S Releases and Experimental Models
clips/audio_79.wav|T T S Papers|T T S Papers
clips/audio_80.wav|Underlined T T S and Judy are internal T T S models that are not released open-source|Underlined T T S and Judy are internal T T S models that are not released open-source
clips/audio_81.wav|High-performance Deep Learning models for Text2Speech tasks.|High-performance Deep Learning models for Text2Speech tasks.
clips/audio_82.wav|Text2Spec models Tacotron, Tacotron2, Glow-T T S, SpeedySpeech.|Text2Spec models Tacotron, Tacotron2, Glow-T T S, SpeedySpeech.
clips/audio_83.wav|Speaker Encoder to compute speaker embeddings efficiently.|Speaker Encoder to compute speaker embeddings efficiently.
clips/audio_84.wav|Vocoder models MelG A N, Multiband-MelG A N, G A N-T T S, ParallelWaveG A N, WaveGrad, WaveR N N|Vocoder models MelG A N, Multiband-MelG A N, G A N-T T S, ParallelWaveG A N, WaveGrad, WaveR N N
clips/audio_85.wav|Support for Multi-speaker T T S.|Support for Multi-speaker T T S.
clips/audio_86.wav|Efficient, flexible, lightweight but feature complete Trainer A P I.|Efficient, flexible, lightweight but feature complete Trainer A P I.
clips/audio_87.wav|Tools to curate Text2Speech datasets underdataset_analysis.|Tools to curate Text2Speech datasets underdataset_analysis.
clips/audio_88.wav|Glow-T T S paper|Glow-T T S paper
clips/audio_89.wav|Align-T T S paper|Align-T T S paper
clips/audio_90.wav|SC-GlowT T S paper|SC-GlowT T S paper
clips/audio_91.wav|Neural HMM T T S paper|Neural HMM T T S paper
clips/audio_92.wav|Delightful T T S paper|Delightful T T S paper
clips/audio_93.wav|T T S blog|T T S blog
clips/audio_94.wav| YourT T S paper| YourT T S paper
clips/audio_95.wav|Guided Attention paper|Guided Attention paper
clips/audio_96.wav|alignment Network paper|alignment Network paper
clips/audio_97.wav|MelG A N paper|MelG A N paper
clips/audio_98.wav|MultiBandMelG A N paper|MultiBandMelG A N paper
clips/audio_99.wav|ParallelWaveG A N paper|ParallelWaveG A N paper
clips/audio_100.wav|G A N-T T S discriminators paper|G A N-T T S discriminators paper
clips/audio_101.wav|WaveR N N origin|WaveR N N origin
clips/audio_102.wav|HiFiG A N paper|HiFiG A N paper
clips/audio_103.wav|T T S is tested on Ubuntu 18.04 with python  3.9,  3.12..|T T S is tested on Ubuntu 18.04 with python  3.9,  3.12..
clips/audio_104.wav|If you are only interested in synthesizing speech with the released T T S models, installing from PyPI is the easiest option.|If you are only interested in synthesizing speech with the released T T S models, installing from PyPI is the easiest option.
clips/audio_105.wav|If you plan to code or train models, clone T T S and install it locally.|If you plan to code or train models, clone T T S and install it locally.
clips/audio_106.wav|You can also try T T S without install with the docker image.|You can also try T T S without install with the docker image.
clips/audio_107.wav|You can then enjoy the T T S server here More details about the docker images like GPU support can be found here|You can then enjoy the T T S server here More details about the docker images like GPU support can be found here
clips/audio_108.wav|This way, you can clone voices by using any model in T T S.|This way, you can clone voices by using any model in T T S.
clips/audio_109.wav|For Fairseq models, use the following name format T T S_modelslang-iso_codefairseqvits.You can find the language ISO codes here and learn about the Fairseq models here.|For Fairseq models, use the following name format T T S_modelslang-iso_codefairseqvits.You can find the language ISO codes here and learn about the Fairseq models here.
clips/audio_110.wav|Get model info for both T T S_models and vocoder_models|Get model info for both T T S_models and vocoder_models
clips/audio_111.wav|Run T T S with default models|Run T T S with default models
clips/audio_112.wav|Run T T S and pipe out the generated T T S wav file data|Run T T S and pipe out the generated T T S wav file data
clips/audio_113.wav|Run a T T S model with its default vocoder model|Run a T T S model with its default vocoder model
clips/audio_114.wav|Run with specific T T S and vocoder models from the list|Run with specific T T S and vocoder models from the list
clips/audio_115.wav|Run your own T T S model Using Griffin-Lim Vocoder|Run your own T T S model Using Griffin-Lim Vocoder
clips/audio_116.wav|Run your own T T S and Vocoder models|Run your own T T S and Vocoder models
clips/audio_117.wav|Run the multi-speaker T T S model with the target speaker ID|Run the multi-speaker T T S model with the target speaker ID
clips/audio_118.wav|Run your own multi-speaker T T S model|Run your own multi-speaker T T S model
clips/audio_119.wav|Using T T S|Using T T S
clips/audio_120.wav|T T S Models|T T S Models
clips/audio_121.wav|Intro to A P I Platforms|Intro to A P I Platforms
clips/audio_122.wav|A P I documentation is a set of human-readable instructions for using and integrating with an A P I.|A P I documentation is a set of human-readable instructions for using and integrating with an A P I.
clips/audio_123.wav|A P I documentation includes detailed information about an A P I's available endpoints, methods, resources, authentication protocols, parameters, and headers, as well as examples of common requests and responses|A P I documentation includes detailed information about an A P I's available endpoints, methods, resources, authentication protocols, parameters, and headers, as well as examples of common requests and responses
clips/audio_124.wav|Effective A P I documentation improves the developer experience for private, partner, and public A P Is, but it also offers distinct benefits for each A P I type|Effective A P I documentation improves the developer experience for private, partner, and public A P Is, but it also offers distinct benefits for each A P I type
clips/audio_125.wav|For instance, private A P I documentation improves cross-team collaboration, while public A P I documentation makes it easier for leaders to understand a third-party A P I's intended use case and determine whether it will help advance their organization's business goals|For instance, private A P I documentation improves cross-team collaboration, while public A P I documentation makes it easier for leaders to understand a third-party A P I's intended use case and determine whether it will help advance their organization's business goals
clips/audio_126.wav|Teams that prioritize A P I documentation typically see higher rates of A P I adoption, fewer support tickets, andin the case of public A P Isincreased revenue.|Teams that prioritize A P I documentation typically see higher rates of A P I adoption, fewer support tickets, andin the case of public A P Isincreased revenue.
clips/audio_127.wav|Here, we'll start by discussing the role that A P I documentation plays in an A P I-first world|Here, we'll start by discussing the role that A P I documentation plays in an A P I-first world
clips/audio_128.wav|Then, we'll review the key components of A P I documentation, as well as some A P I documentation best practices|Then, we'll review the key components of A P I documentation, as well as some A P I documentation best practices
clips/audio_129.wav|Finally, we'll explore how the Postman A P I Platform enables producers to create A P I documentation that sets their consumers up for success.|Finally, we'll explore how the Postman A P I Platform enables producers to create A P I documentation that sets their consumers up for success.
clips/audio_130.wav|A P I-first is a development model in which applications are conceptualized and built by composing internal or external services that are delivered through A P Is|A P I-first is a development model in which applications are conceptualized and built by composing internal or external services that are delivered through A P Is
clips/audio_131.wav|This approach not only enables teams to build highly performant applications that are powered by an intricate web of microservices, but also complements the A P I-as-a-Product strategy, in which A P Is are offered as billable products to third-party consumers|This approach not only enables teams to build highly performant applications that are powered by an intricate web of microservices, but also complements the A P I-as-a-Product strategy, in which A P Is are offered as billable products to third-party consumers
clips/audio_132.wav|An increasing number of organizations are therefore adopting the A P I-first strategy to help them systematically develop high-quality A P Is that advance business objectives in myriad ways.|An increasing number of organizations are therefore adopting the A P I-first strategy to help them systematically develop high-quality A P Is that advance business objectives in myriad ways.
clips/audio_133.wav|A P I documentation plays a crucial role in ensuring the success of any A P Iwhether it's private or public|A P I documentation plays a crucial role in ensuring the success of any A P Iwhether it's private or public
clips/audio_134.wav|For instance, internal A P I documentation facilitates cross-team collaboration, reduces code duplication, and streamlines the onboarding process for new employees|For instance, internal A P I documentation facilitates cross-team collaboration, reduces code duplication, and streamlines the onboarding process for new employees
clips/audio_135.wav|In contrast, public A P I documentation helps potential consumers understand and experiment with an A P I, which leads to increased adoption and, by extension, revenue|In contrast, public A P I documentation helps potential consumers understand and experiment with an A P I, which leads to increased adoption and, by extension, revenue
clips/audio_136.wav|In fact, Postman's 2022 State of the A P I report indicates that documentation is one of the top four things leaders consider when deciding whether to integrate with a third-party A P I.|In fact, Postman's 2022 State of the A P I report indicates that documentation is one of the top four things leaders consider when deciding whether to integrate with a third-party A P I.
clips/audio_137.wav|There are many different types of A P I documentation, and each one plays an important role in helping consumers use an A P I effectively|There are many different types of A P I documentation, and each one plays an important role in helping consumers use an A P I effectively
clips/audio_138.wav|Every A P I is different and therefore requires documentation that is tailor-made for its consumers|Every A P I is different and therefore requires documentation that is tailor-made for its consumers
clips/audio_139.wav|Nevertheless, the following components can serve as an initial checklist for creating high-quality A P I documentation|Nevertheless, the following components can serve as an initial checklist for creating high-quality A P I documentation
clips/audio_140.wav|Authentication helps keep an A P I's data safe and secure, and it is the first hurdle that a developer must cross when using a new A P I|Authentication helps keep an A P I's data safe and secure, and it is the first hurdle that a developer must cross when using a new A P I
clips/audio_141.wav|If an A P I's authentication process is too difficult or poorly documented, the developer might become frustrated and decide to try a different A P I|If an A P I's authentication process is too difficult or poorly documented, the developer might become frustrated and decide to try a different A P I
clips/audio_142.wav|A P I documentation must therefore include a clear explanation of the available authentication methods and provide thorough, step-by-step instructions for obtaining and using authentication credentials.|A P I documentation must therefore include a clear explanation of the available authentication methods and provide thorough, step-by-step instructions for obtaining and using authentication credentials.
clips/audio_143.wav|A P I documentation should offer a comprehensive overview of every A P I endpoint and operation, including parameters, headers, and request and response bodies|A P I documentation should offer a comprehensive overview of every A P I endpoint and operation, including parameters, headers, and request and response bodies
clips/audio_144.wav|It should also thoroughly explain the relevant data models, including their required attributes and any default, minimum, and maximum values|It should also thoroughly explain the relevant data models, including their required attributes and any default, minimum, and maximum values
clips/audio_145.wav|Examples are a crucial part of effective A P I documentation, as they help consumers understand endpoint behavior under a variety of conditions|Examples are a crucial part of effective A P I documentation, as they help consumers understand endpoint behavior under a variety of conditions
clips/audio_146.wav|Examples can also be used to guide new users through a sequence of A P I calls that are involved in a specific workflow, which provides important insight into how an A P I can support sophisticated use cases.|Examples can also be used to guide new users through a sequence of A P I calls that are involved in a specific workflow, which provides important insight into how an A P I can support sophisticated use cases.
clips/audio_147.wav|Public A P I documentation should include a Terms of Use, which is a legal agreement that helps producers ensure their A P I's data and functionality is not abused by consumers|Public A P I documentation should include a Terms of Use, which is a legal agreement that helps producers ensure their A P I's data and functionality is not abused by consumers
clips/audio_148.wav|It should also include information on the A P I's rate limits, which dictate how many A P I calls a consumer can make in a given period of time|It should also include information on the A P I's rate limits, which dictate how many A P I calls a consumer can make in a given period of time
clips/audio_149.wav|Rate limits help protect an A P I from denial-of-service DoS attacks, as well as any other activity that may negatively affect its performance|Rate limits help protect an A P I from denial-of-service DoS attacks, as well as any other activity that may negatively affect its performance
clips/audio_150.wav|Writing A P I documentation is a multi-step process that requires familiarity with the A P I's functionality, empathy for its consumers, and a willingness to iterate|Writing A P I documentation is a multi-step process that requires familiarity with the A P I's functionality, empathy for its consumers, and a willingness to iterate
clips/audio_151.wav|A P I documentation is an essential deliverable that has a significant impact on consumers, and its quality can be directly correlated with the overall success of the A P I|A P I documentation is an essential deliverable that has a significant impact on consumers, and its quality can be directly correlated with the overall success of the A P I
clips/audio_152.wav|It is therefore crucial for teams to adhere to the following best practices when writing A P I documentation|It is therefore crucial for teams to adhere to the following best practices when writing A P I documentation
clips/audio_153.wav|Every A P I plays a unique role in the software landscape of its producers and consumers, and A P I documentation is responsible for telling its story|Every A P I plays a unique role in the software landscape of its producers and consumers, and A P I documentation is responsible for telling its story
clips/audio_154.wav|Documentation readers should be able to learn who the A P I is meant for, how they can use it, and how it can help them achieve their goals|Documentation readers should be able to learn who the A P I is meant for, how they can use it, and how it can help them achieve their goals
clips/audio_155.wav|This big picture provides important context for more technical implementation details, which can be useful as developers begin to understand the possibilities of a given A P I.|This big picture provides important context for more technical implementation details, which can be useful as developers begin to understand the possibilities of a given A P I.
clips/audio_156.wav|Many A P I development teams ship code changes several times a week, which puts their documentation at risk of falling out of date|Many A P I development teams ship code changes several times a week, which puts their documentation at risk of falling out of date
clips/audio_157.wav|It's therefore essential for teams to systematize the process of updating their documentation to ensure it always reflects the current state of their A P I in production|It's therefore essential for teams to systematize the process of updating their documentation to ensure it always reflects the current state of their A P I in production
clips/audio_158.wav|They should also capture updates in a changelog, which is a dated record of every change to an A P I's resources and functionality.|They should also capture updates in a changelog, which is a dated record of every change to an A P I's resources and functionality.
clips/audio_159.wav|A P I documentation is an important resource for a wide range of software and business professionals|A P I documentation is an important resource for a wide range of software and business professionals
clips/audio_160.wav|Developers will consult an A P I's documentation to learn how to interact with it, while CTOs may use documentation to help them understand an A P I's pricing and evaluate whether it will help them meet their business goals|Developers will consult an A P I's documentation to learn how to interact with it, while CTOs may use documentation to help them understand an A P I's pricing and evaluate whether it will help them meet their business goals
clips/audio_161.wav|For instance, they must thoroughly describe the A P I's functionality without relying too heavily on technical language or obscuring the larger purpose that the A P I serves.|For instance, they must thoroughly describe the A P I's functionality without relying too heavily on technical language or obscuring the larger purpose that the A P I serves.
clips/audio_162.wav|Postman's Public A P I Network is a global, centralized A P I catalog, where producers can share their A P Is and A P I documentation with a community of over 30 million developers|Postman's Public A P I Network is a global, centralized A P I catalog, where producers can share their A P Is and A P I documentation with a community of over 30 million developers
clips/audio_163.wav|Teams that publish their A P I documentation on the Public A P I Network can include detailed descriptions and tutorials, example requests and responses, and environment variables, which can increase A P I adoption and reduce ticket volumes|Teams that publish their A P I documentation on the Public A P I Network can include detailed descriptions and tutorials, example requests and responses, and environment variables, which can increase A P I adoption and reduce ticket volumes
clips/audio_164.wav|Some teams that have published excellent A P I documentation in the Public A P I Network include Stripe, Notion, PayPal, Amplitude, Salesforce, and DoorDash, and this list just scratches the surface|Some teams that have published excellent A P I documentation in the Public A P I Network include Stripe, Notion, PayPal, Amplitude, Salesforce, and DoorDash, and this list just scratches the surface
clips/audio_165.wav|Explore the Public A P I Network to see more.|Explore the Public A P I Network to see more.
clips/audio_166.wav|The Postman A P I Platform includes several features that enable teams to make effective documentation a core part of their A P I workflow|The Postman A P I Platform includes several features that enable teams to make effective documentation a core part of their A P I workflow
clips/audio_167.wav|It's jam-packed with updates to help you collaborate on your A P Is, augment yourself with AI, and more.|It's jam-packed with updates to help you collaborate on your A P Is, augment yourself with AI, and more.
clips/audio_168.wav|Installation Guides|Installation Guides
clips/audio_169.wav|Programming Guides|Programming Guides
clips/audio_170.wav|koo-duh A P I References|koo-duh A P I References
clips/audio_171.wav|PTX Compiler A P I References|PTX Compiler A P I References
clips/audio_172.wav|Compiler S D K|Compiler S D K
clips/audio_173.wav|The NVIDIA koo-duh Toolkit provides a development environment for creating high performance GPU-accelerated applications|The NVIDIA koo-duh Toolkit provides a development environment for creating high performance GPU-accelerated applications
clips/audio_174.wav|With the koo-duh Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a CC compiler, and a runtime library to deploy your application.|With the koo-duh Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a CC compiler, and a runtime library to deploy your application.
clips/audio_175.wav|Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.|Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.
clips/audio_176.wav|The koo-duh Toolkit End User License Agreement applies to the NVIDIA koo-duh Toolkit, the NVIDIA koo-duh Samples, the NVIDIA Display Driver, NVIDIA Nsight tools Visual Studio Edition, and the associated documentation on koo-duh A P Is, programming model and development tools|The koo-duh Toolkit End User License Agreement applies to the NVIDIA koo-duh Toolkit, the NVIDIA koo-duh Samples, the NVIDIA Display Driver, NVIDIA Nsight tools Visual Studio Edition, and the associated documentation on koo-duh A P Is, programming model and development tools
clips/audio_177.wav|This guide provides the minimal first-steps instructions for installation and verifying koo-duh on a standard system.|This guide provides the minimal first-steps instructions for installation and verifying koo-duh on a standard system.
clips/audio_178.wav|This guide discusses how to install and check for correct operation of the koo-duh Development Tools on Microsoft Windows systems.|This guide discusses how to install and check for correct operation of the koo-duh Development Tools on Microsoft Windows systems.
clips/audio_179.wav|This guide discusses how to install and check for correct operation of the koo-duh Development Tools on GNULi-nux systems.|This guide discusses how to install and check for correct operation of the koo-duh Development Tools on GNULi-nux systems.
clips/audio_180.wav|This guide provides a detailed discussion of the koo-duh programming model and programming interface|This guide provides a detailed discussion of the koo-duh programming model and programming interface
clips/audio_181.wav|It then describes the hardware implementation, and provides guidance on how to achieve maximum performance|It then describes the hardware implementation, and provides guidance on how to achieve maximum performance
clips/audio_182.wav|The appendices include a list of all koo-duh-enabled devices, detailed description of all extensions to the C language, listings of supported mathematical functions, C features supported in host and device code, details on texture fetching, technical specifications of various devices, and concludes by introducing the low-level driver A P I.|The appendices include a list of all koo-duh-enabled devices, detailed description of all extensions to the C language, listings of supported mathematical functions, C features supported in host and device code, details on texture fetching, technical specifications of various devices, and concludes by introducing the low-level driver A P I.
clips/audio_183.wav|This guide presents established parallelization and optimization techniques and explains coding metaphors and idioms that can greatly simplify programming for koo-duh-capable GPU architectures|This guide presents established parallelization and optimization techniques and explains coding metaphors and idioms that can greatly simplify programming for koo-duh-capable GPU architectures
clips/audio_184.wav|The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the koo-duh Toolkit.|The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the koo-duh Toolkit.
clips/audio_185.wav|This document provides guidance to ensure that your software applications are compatible with Maxwell.|This document provides guidance to ensure that your software applications are compatible with Maxwell.
clips/audio_186.wav|This document provides guidance to ensure that your software applications are compatible with Pascal.|This document provides guidance to ensure that your software applications are compatible with Pascal.
clips/audio_187.wav|This document provides guidance to ensure that your software applications are compatible with Volta.|This document provides guidance to ensure that your software applications are compatible with Volta.
clips/audio_188.wav|This document provides guidance to ensure that your software applications are compatible with Turing.|This document provides guidance to ensure that your software applications are compatible with Turing.
clips/audio_189.wav|This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.|This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.
clips/audio_190.wav|This document provides guidance to ensure that your software applications are compatible with Hopper architecture.|This document provides guidance to ensure that your software applications are compatible with Hopper architecture.
clips/audio_191.wav|This document provides guidance to ensure that your software applications are compatible with Ada architecture.|This document provides guidance to ensure that your software applications are compatible with Ada architecture.
clips/audio_192.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features.
clips/audio_193.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features.
clips/audio_194.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features.
clips/audio_195.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features.
clips/audio_196.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architectures features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architectures features.
clips/audio_197.wav|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architectures features.|This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architectures features.
clips/audio_198.wav|This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architectures features.|This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architectures features.
clips/audio_199.wav|This guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture ISA|This guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture ISA
clips/audio_200.wav|Instead, use the NVIDIA Video Codec S D K|Instead, use the NVIDIA Video Codec S D K
clips/audio_201.wav|This document shows how to inline PTX parallel thread execution assembly language statements into koo-duh code|This document shows how to inline PTX parallel thread execution assembly language statements into koo-duh code
clips/audio_202.wav|It describes available assembler statement parameters and constraints, and the document also provides a list of some pitfalls that you may encounter.|It describes available assembler statement parameters and constraints, and the document also provides a list of some pitfalls that you may encounter.
clips/audio_203.wav|The koo-duh math A P I.|The koo-duh math A P I.
clips/audio_204.wav|The cuDLA A P I.|The cuDLA A P I.
clips/audio_205.wav|The NVBLAS library is a multi-GPUs accelerated drop-in BLAS Basic Linear Algebra Subprograms built on top of the NVIDIA cuBLAS Library.|The NVBLAS library is a multi-GPUs accelerated drop-in BLAS Basic Linear Algebra Subprograms built on top of the NVIDIA cuBLAS Library.
clips/audio_206.wav|The nvJPEG Library provides high-performance GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications.|The nvJPEG Library provides high-performance GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications.
clips/audio_207.wav|The cuFFT library user guide.|The cuFFT library user guide.
clips/audio_208.wav|The user guide for CUB.|The user guide for CUB.
clips/audio_209.wav|The A P I reference for libcu, the koo-duh C standard library.|The A P I reference for libcu, the koo-duh C standard library.
clips/audio_210.wav|The NVIDIA GPUDirect Storage cuFile A P I Reference Guide provides information about the preliminary version of the cuFile A P I reference guide that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those A P Is, which are part of the GDS technology.|The NVIDIA GPUDirect Storage cuFile A P I Reference Guide provides information about the preliminary version of the cuFile A P I reference guide that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those A P Is, which are part of the GDS technology.
clips/audio_211.wav|The cuRAND library user guide.|The cuRAND library user guide.
clips/audio_212.wav|The cuSPARSE library user guide.|The cuSPARSE library user guide.
clips/audio_213.wav|NVIDIA NPP is a library of functions for performing koo-duh accelerated processing|NVIDIA NPP is a library of functions for performing koo-duh accelerated processing
clips/audio_214.wav|The NPP library is written to maximize flexibility, while maintaining high performance.|The NPP library is written to maximize flexibility, while maintaining high performance.
clips/audio_215.wav|The user guide for the nvJitLink library.|The user guide for the nvJitLink library.
clips/audio_216.wav|The user guide for the nvFatbin library.|The user guide for the nvFatbin library.
clips/audio_217.wav|It accepts koo-duh C source code in character string form and creates handles that can be used to obtain the PTX|It accepts koo-duh C source code in character string form and creates handles that can be used to obtain the PTX
clips/audio_218.wav|The PTX string generated by NVRTC can be loaded by cuModuleLoadData and cuModuleLoadDataEx, and linked with other modules by cuLinkAddData of the koo-duh Driver A P I|The PTX string generated by NVRTC can be loaded by cuModuleLoadData and cuModuleLoadDataEx, and linked with other modules by cuLinkAddData of the koo-duh Driver A P I
clips/audio_219.wav|This facility can often provide optimizations and performance not possible in a purely offline static compilation.|This facility can often provide optimizations and performance not possible in a purely offline static compilation.
clips/audio_220.wav|The cuSOLVER library user guide.|The cuSOLVER library user guide.
clips/audio_221.wav|This guide shows how to compile a PTX program into GPU assembly code using A P Is provided by the static PTX Compiler library.|This guide shows how to compile a PTX program into GPU assembly code using A P Is provided by the static PTX Compiler library.
clips/audio_222.wav|This document describes the demo applications shipped with the koo-duh Demo Suite.|This document describes the demo applications shipped with the koo-duh Demo Suite.
clips/audio_223.wav|This guide is intended to help users get started with using NVIDIA koo-duh on Windows Subsystem for Li-nux WSL 2|This guide is intended to help users get started with using NVIDIA koo-duh on Windows Subsystem for Li-nux WSL 2
clips/audio_224.wav|The guide covers installation and running koo-duh applications and containers in this environment.|The guide covers installation and running koo-duh applications and containers in this environment.
clips/audio_225.wav|This edition of the user guide describes the Multi-Instance GPU feature of the NVIDIA A100 GPU.|This edition of the user guide describes the Multi-Instance GPU feature of the NVIDIA A100 GPU.
clips/audio_226.wav|The CUPTI-A P I|The CUPTI-A P I
clips/audio_227.wav|The koo-duh debugger A P I.|The koo-duh debugger A P I.
clips/audio_228.wav|This document introduces the technology and describes the steps necessary to enable a GPUDirect RDMA connection to NVIDIA GPUs within the Li-nux device driver model.|This document introduces the technology and describes the steps necessary to enable a GPUDirect RDMA connection to NVIDIA GPUs within the Li-nux device driver model.
clips/audio_229.wav|The NVIDIA tool for debugging koo-duh applications running on Li-nux and QNX, providing developers with a mechanism for debugging koo-duh applications running on actual hardware|The NVIDIA tool for debugging koo-duh applications running on Li-nux and QNX, providing developers with a mechanism for debugging koo-duh applications running on actual hardware
clips/audio_230.wav|The user guide for Compute Sanitizer.|The user guide for Compute Sanitizer.
clips/audio_231.wav|Nsight Eclipse Plugins Installation Guide|Nsight Eclipse Plugins Installation Guide
clips/audio_232.wav|Nsight Eclipse Plugins Edition getting started guide|Nsight Eclipse Plugins Edition getting started guide
clips/audio_233.wav|It provides detailed performance metrics and A P I debugging via a user interface and command line tool.|It provides detailed performance metrics and A P I debugging via a user interface and command line tool.
clips/audio_234.wav|This is the guide to the Profiler.|This is the guide to the Profiler.
clips/audio_235.wav|A number of issues related to floating point accuracy and compliance are a frequent source of confusion on both CPUs and GPUs|A number of issues related to floating point accuracy and compliance are a frequent source of confusion on both CPUs and GPUs
clips/audio_236.wav|The purpose of this white paper is to discuss the most common issues related to NVIDIA GPUs and to supplement the documentation in the koo-duh C Programming Guide.|The purpose of this white paper is to discuss the most common issues related to NVIDIA GPUs and to supplement the documentation in the koo-duh C Programming Guide.
clips/audio_237.wav|Also, we comment on the parallel sparse triangular solve, which is an essential building block in these algorithms.|Also, we comment on the parallel sparse triangular solve, which is an essential building block in these algorithms.
clips/audio_238.wav|The libNVVM A P I.|The libNVVM A P I.
clips/audio_239.wav|Interfaces for building web applications|Interfaces for building web applications
clips/audio_240.wav|Learn to structure web content with H T M L|Learn to structure web content with H T M L
clips/audio_241.wav|Learn to style content using C S S|Learn to style content using C S S
clips/audio_242.wav|The TRACE method performs a message loop-back test along the path to the target resource.|The TRACE method performs a message loop-back test along the path to the target resource.
clips/audio_243.wav|The following table lists H T T P request methods and their categorization in terms of safety, cacheability, and idempotency.|The following table lists H T T P request methods and their categorization in terms of safety, cacheability, and idempotency.
clips/audio_244.wav| POST and PATCH are cacheable when responses explicitly include freshness information and a matching Content-Location header.| POST and PATCH are cacheable when responses explicitly include freshness information and a matching Content-Location header.
clips/audio_245.wav|BCD tables only load in the browser with Java-Script enabled|BCD tables only load in the browser with Java-Script enabled
clips/audio_246.wav|Enable Java-Script to view data.|Enable Java-Script to view data.
clips/audio_247.wav|B E R T language model is an open source machine learning framework for natural language processing N L P|B E R T language model is an open source machine learning framework for natural language processing N L P
clips/audio_248.wav|B E R T is designed to help computers understand the meaning of ambiguous language in text by using surrounding text to establish context|B E R T is designed to help computers understand the meaning of ambiguous language in text by using surrounding text to establish context
clips/audio_249.wav|The B E R T framework was pretrained using text from Wikipedia and can be fine-tuned with question-and-answer data sets.|The B E R T framework was pretrained using text from Wikipedia and can be fine-tuned with question-and-answer data sets.
clips/audio_250.wav|B E R T, which stands for Bidirectional Encoder Representations from Transformers, is based on transformers, a deep learning model in which every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection.|B E R T, which stands for Bidirectional Encoder Representations from Transformers, is based on transformers, a deep learning model in which every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection.
clips/audio_251.wav|B E R T is different because it's designed to read in both directions at once|B E R T is different because it's designed to read in both directions at once
clips/audio_252.wav|The introduction of transformer models enabled this capability, which is known as bidirectionality|The introduction of transformer models enabled this capability, which is known as bidirectionality
clips/audio_253.wav|Using bidirectionality, B E R T is pretrained on two different but related N L P tasks masked language modeling MLM and next sentence prediction NSP.|Using bidirectionality, B E R T is pretrained on two different but related N L P tasks masked language modeling MLM and next sentence prediction NSP.
clips/audio_254.wav|Google first introduced the transformer model in 2017|Google first introduced the transformer model in 2017
clips/audio_255.wav|At that time, language models primarily used recurrent neural networks R N N and convolutional neural networks C N N to handle N L P tasks.|At that time, language models primarily used recurrent neural networks R N N and convolutional neural networks C N N to handle N L P tasks.
clips/audio_256.wav|C N Ns and R N Ns are competent models, however, they require sequences of data to be processed in a fixed order|C N Ns and R N Ns are competent models, however, they require sequences of data to be processed in a fixed order
clips/audio_257.wav|transformer models are considered a significant improvement because they don't require data sequences to be processed in any fixed order.|transformer models are considered a significant improvement because they don't require data sequences to be processed in any fixed order.
clips/audio_258.wav|Because transformers can process data in any order, they enable training on larger amounts of data than was possible before their existence|Because transformers can process data in any order, they enable training on larger amounts of data than was possible before their existence
clips/audio_259.wav|This facilitated the creation of pretrained models like B E R T, which was trained on massive amounts of language data prior to its release.|This facilitated the creation of pretrained models like B E R T, which was trained on massive amounts of language data prior to its release.
clips/audio_260.wav|In 2018, Google introduced and open sourced B E R T|In 2018, Google introduced and open sourced B E R T
clips/audio_261.wav|In its research stages, the framework achieved state-of-the-art results in 11 natural language understanding NLU tasks, including sentiment analysis, semantic role labeling, text classification and the disambiguation of words with multiple meanings|In its research stages, the framework achieved state-of-the-art results in 11 natural language understanding NLU tasks, including sentiment analysis, semantic role labeling, text classification and the disambiguation of words with multiple meanings
clips/audio_262.wav|Completing these tasks distinguished B E R T from previous language models, such as word2vec and GloVe|Completing these tasks distinguished B E R T from previous language models, such as word2vec and GloVe
clips/audio_263.wav|B E R T effectively addresses ambiguity, which is the greatest challenge to NLU, according to research scientists in the field|B E R T effectively addresses ambiguity, which is the greatest challenge to NLU, according to research scientists in the field
clips/audio_264.wav|In October 2019, Google announced that it would begin applying B E R T to its U.S.-based production search algorithms.|In October 2019, Google announced that it would begin applying B E R T to its U.S.-based production search algorithms.
clips/audio_265.wav|It is estimated that B E R T enhances Google's understanding of approximately 10 of U.S.-based English language Google search queries|It is estimated that B E R T enhances Google's understanding of approximately 10 of U.S.-based English language Google search queries
clips/audio_266.wav|Google recommends that organizations not try to optimize content for B E R T, as B E R T aims to provide a natural-feeling search experience|Google recommends that organizations not try to optimize content for B E R T, as B E R T aims to provide a natural-feeling search experience
clips/audio_267.wav|BY December 2019, B E R T had been applied to more than 70 different languages|BY December 2019, B E R T had been applied to more than 70 different languages
clips/audio_268.wav|The model has had a large impact on voice search as well as text-based search, which prior to 2018 had been error-prone with Google's N L P techniques|The model has had a large impact on voice search as well as text-based search, which prior to 2018 had been error-prone with Google's N L P techniques
clips/audio_269.wav|Once B E R T was applied to many languages, it improved search engine optimization its proficiency in understanding context helps it interpret patterns that different languages share without having to completely understand the language.|Once B E R T was applied to many languages, it improved search engine optimization its proficiency in understanding context helps it interpret patterns that different languages share without having to completely understand the language.
clips/audio_270.wav|B E R T went on to influence many artificial intelligence systems|B E R T went on to influence many artificial intelligence systems
clips/audio_271.wav|Various lighter versions of B E R T and similar training methods have been applied to models from G P T-2 to ChatG P T.|Various lighter versions of B E R T and similar training methods have been applied to models from G P T-2 to ChatG P T.
clips/audio_272.wav|The goal of any given N L P technique is to understand human language as it is spoken naturally|The goal of any given N L P technique is to understand human language as it is spoken naturally
clips/audio_273.wav|In B E R T's case, this means predicting a word in a blank|In B E R T's case, this means predicting a word in a blank
clips/audio_274.wav|To do this, models typically train using a large repository of specialized, labeled training data|To do this, models typically train using a large repository of specialized, labeled training data
clips/audio_275.wav|This process involves linguists doing laborious manual data labeling.|This process involves linguists doing laborious manual data labeling.
clips/audio_276.wav|B E R T, however, was pretrained using only a collection of unlabeled, plain text, namely the entirety of English Wikipedia and the Brown Corpus|B E R T, however, was pretrained using only a collection of unlabeled, plain text, namely the entirety of English Wikipedia and the Brown Corpus
clips/audio_277.wav|B E R T's pretraining serves as a base layer of knowledge from which it can build its responses|B E R T's pretraining serves as a base layer of knowledge from which it can build its responses
clips/audio_278.wav|From there, B E R T can adapt to the ever-growing body of searchable content and queries, and it can be fine-tuned to a user's specifications|From there, B E R T can adapt to the ever-growing body of searchable content and queries, and it can be fine-tuned to a user's specifications
clips/audio_279.wav|Aside from this pretraining process, B E R T has multiple other aspects it relies on to function as intended, including the following|Aside from this pretraining process, B E R T has multiple other aspects it relies on to function as intended, including the following
clips/audio_280.wav|Google's work on transformers made B E R T possible|Google's work on transformers made B E R T possible
clips/audio_281.wav|The transformer is the part of the model that gives B E R T its increased capacity for understanding context and ambiguity in language|The transformer is the part of the model that gives B E R T its increased capacity for understanding context and ambiguity in language
clips/audio_282.wav|The transformer processes any given word in relation to all other words in a sentence, rather than processing them one at a time|The transformer processes any given word in relation to all other words in a sentence, rather than processing them one at a time
clips/audio_283.wav|By looking at all surrounding words, the transformer enables B E R T to understand the full context of the word and therefore better understand searcher intent.|By looking at all surrounding words, the transformer enables B E R T to understand the full context of the word and therefore better understand searcher intent.
clips/audio_284.wav|This is contrasted against the traditional method of language processing, known as word embedding|This is contrasted against the traditional method of language processing, known as word embedding
clips/audio_285.wav|Word embedding models require large data sets of structured data|Word embedding models require large data sets of structured data
clips/audio_286.wav|While they are adept at many general N L P tasks, they fail at the context-heavy, predictive nature of question answering because all words are in some sense fixed to a vector or meaning.|While they are adept at many general N L P tasks, they fail at the context-heavy, predictive nature of question answering because all words are in some sense fixed to a vector or meaning.
clips/audio_287.wav|B E R T uses an MLM method to keep the word in focus from seeing itself, or having a fixed meaning independent of its context|B E R T uses an MLM method to keep the word in focus from seeing itself, or having a fixed meaning independent of its context
clips/audio_288.wav|B E R T is forced to identify the masked word based on context alone|B E R T is forced to identify the masked word based on context alone
clips/audio_289.wav|In B E R T, words are defined by their surroundings, not by a prefixed identity.|In B E R T, words are defined by their surroundings, not by a prefixed identity.
clips/audio_290.wav|B E R T also relies on a self-attention mechanism that captures and understands relationships among words in a sentence|B E R T also relies on a self-attention mechanism that captures and understands relationships among words in a sentence
clips/audio_291.wav|The bidirectional transformers at the center of B E R T's design make this possible|The bidirectional transformers at the center of B E R T's design make this possible
clips/audio_292.wav|Each word added augments the overall meaning of the word the N L P algorithm is focusing on|Each word added augments the overall meaning of the word the N L P algorithm is focusing on
clips/audio_293.wav|The more words that are present in each sentence or phrase, the more ambiguous the word in focus becomes|The more words that are present in each sentence or phrase, the more ambiguous the word in focus becomes
clips/audio_294.wav|B E R T accounts for the augmented meaning by reading bidirectionally, accounting for the effect of all other words in a sentence on the focus word and eliminating the left-to-right momentum that biases words towards a certain meaning as a sentence progresses.|B E R T accounts for the augmented meaning by reading bidirectionally, accounting for the effect of all other words in a sentence on the focus word and eliminating the left-to-right momentum that biases words towards a certain meaning as a sentence progresses.
clips/audio_295.wav|For example, in the image above, B E R T is determining which prior word in the sentence the word "it" refers to, and then using the self-attention mechanism to weigh the options|For example, in the image above, B E R T is determining which prior word in the sentence the word "it" refers to, and then using the self-attention mechanism to weigh the options
clips/audio_296.wav|If this phrase was a search query, the results would reflect this subtler, more precise understanding B E R T reached.|If this phrase was a search query, the results would reflect this subtler, more precise understanding B E R T reached.
clips/audio_297.wav|NSP is a training technique that teaches B E R T to predict whether a certain sentence follows a previous sentence to test its knowledge of relationships between sentences|NSP is a training technique that teaches B E R T to predict whether a certain sentence follows a previous sentence to test its knowledge of relationships between sentences
clips/audio_298.wav|Specifically, B E R T is given both sentence pairs that are correctly paired and pairs that are wrongly paired so it gets better at understanding the difference|Specifically, B E R T is given both sentence pairs that are correctly paired and pairs that are wrongly paired so it gets better at understanding the difference
clips/audio_299.wav|Over time, B E R T gets better at predicting next sentences accurately|Over time, B E R T gets better at predicting next sentences accurately
clips/audio_300.wav|Google uses B E R T to optimize the interpretation of user search queries|Google uses B E R T to optimize the interpretation of user search queries
clips/audio_301.wav|B E R T excels at functions that make this possible, including the following|B E R T excels at functions that make this possible, including the following
clips/audio_302.wav|B E R T is open source, meaning anyone can use it|B E R T is open source, meaning anyone can use it
clips/audio_303.wav|Many other organizations, research groups and separate factions of Google are fine-tuning the model's architecture with supervised training to either optimize it for efficiency or specialize it for specific tasks by pretraining B E R T with certain contextual representations|Many other organizations, research groups and separate factions of Google are fine-tuning the model's architecture with supervised training to either optimize it for efficiency or specialize it for specific tasks by pretraining B E R T with certain contextual representations
clips/audio_304.wav|While B E R T and G P T models are among the best language models, they exist for different reasons|While B E R T and G P T models are among the best language models, they exist for different reasons
clips/audio_305.wav|The initial G P T-3 model, along with OpenAI's subsequent more advanced G P T models, are also language models trained on massive data sets|The initial G P T-3 model, along with OpenAI's subsequent more advanced G P T models, are also language models trained on massive data sets
clips/audio_306.wav|While they share this in common with B E R T, B E R T differs in multiple ways.|While they share this in common with B E R T, B E R T differs in multiple ways.
clips/audio_307.wav|Google developed B E R T to serve as a bidirectional transformer model that examines words within text by considering both left-to-right and right-to-left contexts|Google developed B E R T to serve as a bidirectional transformer model that examines words within text by considering both left-to-right and right-to-left contexts
clips/audio_308.wav|It helps computer systems understand text as opposed to creating text, which G P T models are made to do|It helps computer systems understand text as opposed to creating text, which G P T models are made to do
clips/audio_309.wav|B E R T excels at NLU tasks as well as performing sentiment analysis|B E R T excels at NLU tasks as well as performing sentiment analysis
clips/audio_310.wav|G P T models differ from B E R T in both their objectives and their use cases|G P T models differ from B E R T in both their objectives and their use cases
clips/audio_311.wav|G P T models are forms of generative AI that generate original text and other forms of content|G P T models are forms of generative AI that generate original text and other forms of content
clips/audio_312.wav|They're also well-suited for summarizing long pieces of text and text that's hard to interpret.|They're also well-suited for summarizing long pieces of text and text that's hard to interpret.
clips/audio_313.wav|B E R T and other language models differ not only in scope and applications but also in architecture|B E R T and other language models differ not only in scope and applications but also in architecture
clips/audio_314.wav|Learn more about G P T-3's architecture and how it's different from B E R T.|Learn more about G P T-3's architecture and how it's different from B E R T.
clips/audio_315.wav|Using AI and ML in a data warehouse gives the whole organization a single source of truth that can align decision making and ...|Using AI and ML in a data warehouse gives the whole organization a single source of truth that can align decision making and ...
clips/audio_316.wav|As analytics enters a new era dominated by GenAI, the vendor has named former Salesforce Sales Cloud and Einstein Analytics ...|As analytics enters a new era dominated by GenAI, the vendor has named former Salesforce Sales Cloud and Einstein Analytics ...
clips/audio_317.wav|The vendor's new capabilities are designed to enable Databricks and GitLab users to quickly discover and resolve the underlying ...|The vendor's new capabilities are designed to enable Databricks and GitLab users to quickly discover and resolve the underlying ...
clips/audio_318.wav|The data platform vendor's purchase adds full change data capture capabilities and is aimed at improving data ingestion and ...|The data platform vendor's purchase adds full change data capture capabilities and is aimed at improving data ingestion and ...
clips/audio_319.wav|Initially slow to adopt digital transformation, manufacturers are recognizing the power of AI technologies as they seek ways to ...|Initially slow to adopt digital transformation, manufacturers are recognizing the power of AI technologies as they seek ways to ...
clips/audio_320.wav|Acumatica unveiled a new user interface and hundreds of new AI- and ML-based capabilities in Acumatica twenty twenty-four R2's Construction, Distribution, ...|Acumatica unveiled a new user interface and hundreds of new AI- and ML-based capabilities in Acumatica twenty twenty-four R2's Construction, Distribution, ...
clips/audio_321.wav|Connected worker capabilities are now part of the Plex smart manufacturing platform, designed for manufacturers to address worker...|Connected worker capabilities are now part of the Plex smart manufacturing platform, designed for manufacturers to address worker...
clips/audio_322.wav|All Rights Reserved, Copyright 2018 - twenty twenty-four, TechTarget Privacy Policy Cookie Preferences  Cookie Preferences  Do Not Sell or Share My Personal Information|All Rights Reserved, Copyright 2018 - twenty twenty-four, TechTarget Privacy Policy Cookie Preferences  Cookie Preferences  Do Not Sell or Share My Personal Information
clips/audio_323.wav|Natural language processing N L P is an interdisciplinary subfield of computer science and artificial intelligence|Natural language processing N L P is an interdisciplinary subfield of computer science and artificial intelligence
clips/audio_324.wav|It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics|It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics
clips/audio_325.wav|Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.|Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.
clips/audio_326.wav|The premise of symbolic N L P is well-summarized by John Searle's Chinese room experiment Given a collection of rules e.g., a Chinese phrasebook, with questions and matching answers, the computer emulates natural language understanding or other N L P tasks by applying those rules to the data it confronts.|The premise of symbolic N L P is well-summarized by John Searle's Chinese room experiment Given a collection of rules e.g., a Chinese phrasebook, with questions and matching answers, the computer emulates natural language understanding or other N L P tasks by applying those rules to the data it confronts.
clips/audio_327.wav|This was due to both the steady increase in computational power see Moore's law and the gradual lessening of the dominance of Chomskyan theories of linguistics e.g|This was due to both the steady increase in computational power see Moore's law and the gradual lessening of the dominance of Chomskyan theories of linguistics e.g
clips/audio_328.wav|transformational grammar, whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.8|transformational grammar, whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.8
clips/audio_329.wav|In two hundred3, word n-gram model, at the time the best statistical algorithm, was outperformed by a multi-layer perceptron with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling by Yoshua Bengio with co-authors.9|In two hundred3, word n-gram model, at the time the best statistical algorithm, was outperformed by a multi-layer perceptron with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling by Yoshua Bengio with co-authors.9
clips/audio_330.wav|That popularity was due partly to a flurry of results showing that such techniques1112 can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling13 and parsing.1415 This is increasingly important in medicine and healthcare, where N L P helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care16 or protect patient privacy.17|That popularity was due partly to a flurry of results showing that such techniques1112 can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling13 and parsing.1415 This is increasingly important in medicine and healthcare, where N L P helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care16 or protect patient privacy.17
clips/audio_331.wav|Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by N L P in particular1819 such as by writing grammars or devising heuristic rules for stemming.|Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by N L P in particular1819 such as by writing grammars or devising heuristic rules for stemming.
clips/audio_332.wav|Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach|Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach
clips/audio_333.wav|Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023|Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023
clips/audio_334.wav|A major drawback of statistical methods is that they require elaborate feature engineering|A major drawback of statistical methods is that they require elaborate feature engineering
clips/audio_335.wav|Since 2015,22 the statistical approach has been replaced by the neural networks approach, using semantic networks23 and word embeddings to capture semantic properties of words|Since 2015,22 the statistical approach has been replaced by the neural networks approach, using semantic networks23 and word embeddings to capture semantic properties of words
clips/audio_336.wav|Neural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.|Neural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.
clips/audio_337.wav|Based on long-standing trends in the field, it is possible to extrapolate future directions of N L P|Based on long-standing trends in the field, it is possible to extrapolate future directions of N L P
clips/audio_338.wav|Most higher-level N L P applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language|Most higher-level N L P applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language
clips/audio_339.wav|More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of N L P see trends among CoNLL shared tasks above.|More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of N L P see trends among CoNLL shared tasks above.
clips/audio_340.wav|Cognition refers to "the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses."47 Cognitive science is the interdisciplinary, scientific study of the mind and its processes.48 Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.49 Especially during the age of symbolic N L P, the area of computational linguistics maintained strong ties with cognitive studies.|Cognition refers to "the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses."47 Cognitive science is the interdisciplinary, scientific study of the mind and its processes.48 Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.49 Especially during the age of symbolic N L P, the area of computational linguistics maintained strong ties with cognitive studies.
clips/audio_341.wav|As an example, George Lakoff offers a methodology to build natural language processing N L P algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,50 with two defining aspects|As an example, George Lakoff offers a methodology to build natural language processing N L P algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,50 with two defining aspects
clips/audio_342.wav|Ties with cognitive linguistics are part of the historical heritage of N L P, but they have been less frequently addressed since the statistical turn during the 1990s|Ties with cognitive linguistics are part of the historical heritage of N L P, but they have been less frequently addressed since the statistical turn during the 1990s
clips/audio_343.wav|Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,53 functional grammar,54 construction grammar,55 computational psycholinguistics and cognitive neuroscience e.g., ACT-R, however, with limited uptake in mainstream N L P as measured by presence on major conferences56 of the ACL|Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,53 functional grammar,54 construction grammar,55 computational psycholinguistics and cognitive neuroscience e.g., ACT-R, however, with limited uptake in mainstream N L P as measured by presence on major conferences56 of the ACL
clips/audio_344.wav|More recently, ideas of cognitive N L P have been revived as an approach to achieve explainability, e.g., under the notion of "cognitive AI".57 Likewise, ideas of cognitive N L P are inherent to neural models multimodal N L P although rarely made explicit58 and developments in artificial intelligence, specifically tools and technologies using large language model approaches59 and new directions in artificial general intelligence based on the free energy principle60 by British neuroscientist and theoretician at University College London Karl J|More recently, ideas of cognitive N L P have been revived as an approach to achieve explainability, e.g., under the notion of "cognitive AI".57 Likewise, ideas of cognitive N L P are inherent to neural models multimodal N L P although rarely made explicit58 and developments in artificial intelligence, specifically tools and technologies using large language model approaches59 and new directions in artificial general intelligence based on the free energy principle60 by British neuroscientist and theoretician at University College London Karl J
clips/audio_345.wav|Extensible Markup Language X M L is a markup language and file format for storing, transmitting, and reconstructing arbitrary data|Extensible Markup Language X M L is a markup language and file format for storing, transmitting, and reconstructing arbitrary data
clips/audio_346.wav|It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable|It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable
clips/audio_347.wav|The World Wide Web Consortium's X M L 1.0 Specification2 of 19983 and several other related specifications4all of them free open standardsdefine X M L.5|The World Wide Web Consortium's X M L 1.0 Specification2 of 19983 and several other related specifications4all of them free open standardsdefine X M L.5
clips/audio_348.wav|The design goals of X M L emphasize simplicity, generality, and usability across the Internet.6 It is a textual data format with strong support via Unicode for different human languages|The design goals of X M L emphasize simplicity, generality, and usability across the Internet.6 It is a textual data format with strong support via Unicode for different human languages
clips/audio_349.wav|Although the design of X M L focuses on documents, the language is widely used for the representation of arbitrary data structures,7 such as those used in web services.|Although the design of X M L focuses on documents, the language is widely used for the representation of arbitrary data structures,7 such as those used in web services.
clips/audio_350.wav|Several schema systems exist to aid in the definition of X M L-based languages, while programmers have developed many application programming interfaces A P Is to aid the processing of X M L data.|Several schema systems exist to aid in the definition of X M L-based languages, while programmers have developed many application programming interfaces A P Is to aid the processing of X M L data.
clips/audio_351.wav|The main purpose of X M L is serialization, i.e|The main purpose of X M L is serialization, i.e
clips/audio_352.wav|For two disparate systems to exchange information, they need to agree upon a file format|For two disparate systems to exchange information, they need to agree upon a file format
clips/audio_353.wav|X M L standardizes this process|X M L standardizes this process
clips/audio_354.wav|It is therefore analogous to a lingua franca for representing information.81|It is therefore analogous to a lingua franca for representing information.81
clips/audio_355.wav|As a markup language, X M L labels, categorizes, and structurally organizes information.811 X M L tags represent the data structure and contain metadata|As a markup language, X M L labels, categorizes, and structurally organizes information.811 X M L tags represent the data structure and contain metadata
clips/audio_356.wav|What's within the tags is data, encoded in the way the X M L standard specifies.811 An additional X M L schema XSD defines the necessary metadata for interpreting and validating X M L|What's within the tags is data, encoded in the way the X M L standard specifies.811 An additional X M L schema XSD defines the necessary metadata for interpreting and validating X M L
clips/audio_357.wav|This is also referred to as the canonical schema.8135 An X M L document that adheres to basic X M L rules is "well-formed" one that adheres to its schema is "valid."8135|This is also referred to as the canonical schema.8135 An X M L document that adheres to basic X M L rules is "well-formed" one that adheres to its schema is "valid."8135
clips/audio_358.wav|IETF RFC 7303 which supersedes the older RFC 3023, provides rules for the construction of media types for use in X M L message|IETF RFC 7303 which supersedes the older RFC 3023, provides rules for the construction of media types for use in X M L message
clips/audio_359.wav|It defines three media types applicationxml textxml is an alias, applicationxml-external-parsed-entity textxml-external-parsed-entity is an alias and applicationxml-dtd|It defines three media types applicationxml textxml is an alias, applicationxml-external-parsed-entity textxml-external-parsed-entity is an alias and applicationxml-dtd
clips/audio_360.wav|They are used for transmitting raw X M L files without exposing their internal semantics|They are used for transmitting raw X M L files without exposing their internal semantics
clips/audio_361.wav|RFC 7303 further recommends that X M L-based languages be given media types ending in xml, for example, imagesvgxml for SVG.|RFC 7303 further recommends that X M L-based languages be given media types ending in xml, for example, imagesvgxml for SVG.
clips/audio_362.wav|Further guidelines for the use of X M L in a networked context appear in RFC 3470, also known as IETF BCP 70, a document covering many aspects of designing and deploying an X M L-based language.|Further guidelines for the use of X M L in a networked context appear in RFC 3470, also known as IETF BCP 70, a document covering many aspects of designing and deploying an X M L-based language.
clips/audio_363.wav|X M L has come into common use for the interchange of data over the Internet|X M L has come into common use for the interchange of data over the Internet
clips/audio_364.wav|Hundreds of document formats using X M L syntax have been developed,9 including RSS, Atom, Office Open X M L, OpenDocument, SVG, COLLADA, and XH T M L|Hundreds of document formats using X M L syntax have been developed,9 including RSS, Atom, Office Open X M L, OpenDocument, SVG, COLLADA, and XH T M L
clips/audio_365.wav|X M L also provides the base language for communication protocols such as SOAP and XMPP|X M L also provides the base language for communication protocols such as SOAP and XMPP
clips/audio_366.wav|It is one of the message exchange formats used in the Asynchronous Java-Script and X M L AJAX programming technique.|It is one of the message exchange formats used in the Asynchronous Java-Script and X M L AJAX programming technique.
clips/audio_367.wav|Many industry data standards, such as Health Level 7, OpenTravel Alliance, FpML, MISMO, and National Information Exchange Model are based on X M L and the rich features of the X M L schema specification|Many industry data standards, such as Health Level 7, OpenTravel Alliance, FpML, MISMO, and National Information Exchange Model are based on X M L and the rich features of the X M L schema specification
clips/audio_368.wav|In publishing, Darwin Information Typing Architecture is an X M L industry data standard|In publishing, Darwin Information Typing Architecture is an X M L industry data standard
clips/audio_369.wav|X M L is used extensively to underpin various publishing formats.|X M L is used extensively to underpin various publishing formats.
clips/audio_370.wav|One of the applications of X M L is in the transfer of Operational meteorology OPMET information based on IWXXM standards.10|One of the applications of X M L is in the transfer of Operational meteorology OPMET information based on IWXXM standards.10
clips/audio_371.wav|The material in this section is based on the X M L Specification|The material in this section is based on the X M L Specification
clips/audio_372.wav|This is not an exhaustive list of all the constructs that appear in X M L it provides an introduction to the key constructs most often encountered in day-to-day use.|This is not an exhaustive list of all the constructs that appear in X M L it provides an introduction to the key constructs most often encountered in day-to-day use.
clips/audio_373.wav|X M L documents consist entirely of characters from the Unicode repertoire|X M L documents consist entirely of characters from the Unicode repertoire
clips/audio_374.wav|Except for a small number of specifically excluded control characters, any character defined by Unicode may appear within the content of an X M L document.|Except for a small number of specifically excluded control characters, any character defined by Unicode may appear within the content of an X M L document.
clips/audio_375.wav|X M L includes facilities for identifying the encoding of the Unicode characters that make up the document, and for expressing characters that, for one reason or another, cannot be used directly.|X M L includes facilities for identifying the encoding of the Unicode characters that make up the document, and for expressing characters that, for one reason or another, cannot be used directly.
clips/audio_376.wav|Unicode code points in the following ranges are valid in X M L 1.0 documents11|Unicode code points in the following ranges are valid in X M L 1.0 documents11
clips/audio_377.wav|X M L 1.1 extends the set of allowed characters to include all the above, plus the remaining characters in the range U0001U001F.12 At the same time, however, it restricts the use of C0 and C1 control characters other than U0009 Horizontal Tab, U000A Line Feed, U000D Carriage Return, and U0085 Next Line by requiring them to be written in escaped form for example U0001 must be written as x01 or its equivalent|X M L 1.1 extends the set of allowed characters to include all the above, plus the remaining characters in the range U0001U001F.12 At the same time, however, it restricts the use of C0 and C1 control characters other than U0009 Horizontal Tab, U000A Line Feed, U000D Carriage Return, and U0085 Next Line by requiring them to be written in escaped form for example U0001 must be written as x01 or its equivalent
clips/audio_378.wav|The code point U0000 Null is the only character that is not permitted in any X M L 1.1 document.|The code point U0000 Null is the only character that is not permitted in any X M L 1.1 document.
clips/audio_379.wav|Unicode itself defines encodings that cover the entire repertoire well-known ones include UTF-8 which the X M L standard recommends using, without a BOM and UTF-16.13 There are many other text encodings that predate Unicode, such as ASCII and various ISOIEC 8859 their character repertoires are in every case subsets of the Unicode character set.|Unicode itself defines encodings that cover the entire repertoire well-known ones include UTF-8 which the X M L standard recommends using, without a BOM and UTF-16.13 There are many other text encodings that predate Unicode, such as ASCII and various ISOIEC 8859 their character repertoires are in every case subsets of the Unicode character set.
clips/audio_380.wav|X M L allows the use of any of the Unicode-defined encodings and any other encodings whose characters also appear in Unicode|X M L allows the use of any of the Unicode-defined encodings and any other encodings whose characters also appear in Unicode
clips/audio_381.wav|X M L also provides a mechanism whereby an X M L processor can reliably, without any prior knowledge, determine which encoding is being used.14 Encodings other than UTF-8 and UTF-16 are not necessarily recognized by every X M L parser and in some cases not even UTF-16, even though the standard mandates it to also be recognized.|X M L also provides a mechanism whereby an X M L processor can reliably, without any prior knowledge, determine which encoding is being used.14 Encodings other than UTF-8 and UTF-16 are not necessarily recognized by every X M L parser and in some cases not even UTF-16, even though the standard mandates it to also be recognized.
clips/audio_382.wav|X M L provides escape facilities for including characters that are problematic to include directly|X M L provides escape facilities for including characters that are problematic to include directly
clips/audio_383.wav|A user whose keyboard offers no method for entering this character could still insert it in an X M L document encoded either as two hundred13 or x4e2d|A user whose keyboard offers no method for entering this character could still insert it in an X M L document encoded either as two hundred13 or x4e2d
clips/audio_384.wav|Similarly, the string "I 3 Jrg" could be encoded for inclusion in an X M L document as I lt3 JxF6rg.|Similarly, the string "I 3 Jrg" could be encoded for inclusion in an X M L document as I lt3 JxF6rg.
clips/audio_385.wav|0 is not permitted because the null character is one of the control characters excluded from X M L, even when using a numeric character reference.16 An alternative encoding mechanism such as Base64 is needed to represent such characters.|0 is not permitted because the null character is one of the control characters excluded from X M L, even when using a numeric character reference.16 An alternative encoding mechanism such as Base64 is needed to represent such characters.
clips/audio_386.wav|Comments cannot appear before the X M L declaration|Comments cannot appear before the X M L declaration
clips/audio_387.wav|X M L 1.0 Fifth Edition and X M L 1.1 support the direct use of almost any Unicode character in element names, attributes, comments, character data, and processing instructions other than the ones that have special symbolic meaning in X M L itself, such as the less-than sign, ""|X M L 1.0 Fifth Edition and X M L 1.1 support the direct use of almost any Unicode character in element names, attributes, comments, character data, and processing instructions other than the ones that have special symbolic meaning in X M L itself, such as the less-than sign, ""
clips/audio_388.wav|The following is a well-formed X M L document including Chinese, Armenian and Cyrillic characters|The following is a well-formed X M L document including Chinese, Armenian and Cyrillic characters
clips/audio_389.wav|The X M L specification defines an X M L document as a well-formed text, meaning that it satisfies a list of syntax rules provided in the specification|The X M L specification defines an X M L document as a well-formed text, meaning that it satisfies a list of syntax rules provided in the specification
clips/audio_390.wav|The definition of an X M L document excludes texts that contain violations of well-formedness rules they are simply not X M L|The definition of an X M L document excludes texts that contain violations of well-formedness rules they are simply not X M L
clips/audio_391.wav|An X M L processor that encounters such a violation is required to report such errors and to cease normal processing|An X M L processor that encounters such a violation is required to report such errors and to cease normal processing
clips/audio_392.wav|This policy, occasionally referred to as "draconian error handling", stands in notable contrast to the behavior of programs that process H T M L, which are designed to produce a reasonable result even in the presence of severe markup errors.18 X M L's policy in this area has been criticized as a violation of Postel's law "Be conservative in what you send be liberal in what you accept".19|This policy, occasionally referred to as "draconian error handling", stands in notable contrast to the behavior of programs that process H T M L, which are designed to produce a reasonable result even in the presence of severe markup errors.18 X M L's policy in this area has been criticized as a violation of Postel's law "Be conservative in what you send be liberal in what you accept".19
clips/audio_393.wav|The X M L specification defines a valid X M L document as a well-formed X M L document which also conforms to the rules of a Document Type Definition DTD.2021|The X M L specification defines a valid X M L document as a well-formed X M L document which also conforms to the rules of a Document Type Definition DTD.2021
clips/audio_394.wav|In addition to being well formed, an X M L document may be valid|In addition to being well formed, an X M L document may be valid
clips/audio_395.wav|X M L processors are classified as validating or non-validating depending on whether or not they check X M L documents for validity|X M L processors are classified as validating or non-validating depending on whether or not they check X M L documents for validity
clips/audio_396.wav|A processor that discovers a validity error must be able to report it, but may continue normal processing.|A processor that discovers a validity error must be able to report it, but may continue normal processing.
clips/audio_397.wav|Since the initial publication of X M L 1.0, there has been substantial work in the area of schema languages for X M L|Since the initial publication of X M L 1.0, there has been substantial work in the area of schema languages for X M L
clips/audio_398.wav|The oldest schema language for X M L is the document type definition DTD, inherited from SGML.|The oldest schema language for X M L is the document type definition DTD, inherited from SGML.
clips/audio_399.wav|Two peculiar features that distinguish DTDs from other schema types are the syntactic support for embedding a DTD within X M L documents and for defining entities, which are arbitrary fragments of text or markup that the X M L processor inserts in the DTD itself and in the X M L document wherever they are referenced, like character escapes.|Two peculiar features that distinguish DTDs from other schema types are the syntactic support for embedding a DTD within X M L documents and for defining entities, which are arbitrary fragments of text or markup that the X M L processor inserts in the DTD itself and in the X M L document wherever they are referenced, like character escapes.
clips/audio_400.wav|DTD technology is still used in many applications because of its ubiquity.|DTD technology is still used in many applications because of its ubiquity.
clips/audio_401.wav|A newer schema language, described by the W3C as the successor of DTDs, is X M L Schema, often referred to by the initialism for X M L Schema instances, XSD X M L Schema Definition|A newer schema language, described by the W3C as the successor of DTDs, is X M L Schema, often referred to by the initialism for X M L Schema instances, XSD X M L Schema Definition
clips/audio_402.wav|XSDs are far more powerful than DTDs in describing X M L languages|XSDs are far more powerful than DTDs in describing X M L languages
clips/audio_403.wav|They use a rich datatyping system and allow for more detailed constraints on an X M L document's logical structure|They use a rich datatyping system and allow for more detailed constraints on an X M L document's logical structure
clips/audio_404.wav|XSDs also use an X M L-based format, which makes it possible to use ordinary X M L tools to help process them.|XSDs also use an X M L-based format, which makes it possible to use ordinary X M L tools to help process them.
clips/audio_405.wav|RELAX NG Regular Language for X M L Next Generation was initially specified by OASIS and is now a standard Part 2 Regular-grammar-based validation of ISOIEC 19757  DSDL|RELAX NG Regular Language for X M L Next Generation was initially specified by OASIS and is now a standard Part 2 Regular-grammar-based validation of ISOIEC 19757  DSDL
clips/audio_406.wav|RELAX NG schemas may be written in either an X M L based syntax or a more compact non-X M L syntax the two syntaxes are isomorphic and James Clark's conversion toolTrangcan convert between them without loss of information|RELAX NG schemas may be written in either an X M L based syntax or a more compact non-X M L syntax the two syntaxes are isomorphic and James Clark's conversion toolTrangcan convert between them without loss of information
clips/audio_407.wav|RELAX NG has a simpler definition and validation framework than X M L Schema, making it easier to use and implement|RELAX NG has a simpler definition and validation framework than X M L Schema, making it easier to use and implement
clips/audio_408.wav|It also has the ability to use datatype framework plug-ins a RELAX NG schema author, for example, can require values in an X M L document to conform to definitions in X M L Schema Datatypes.|It also has the ability to use datatype framework plug-ins a RELAX NG schema author, for example, can require values in an X M L document to conform to definitions in X M L Schema Datatypes.
clips/audio_409.wav|Schematron is a language for making assertions about the presence or absence of patterns in an X M L document|Schematron is a language for making assertions about the presence or absence of patterns in an X M L document
clips/audio_410.wav|DSDL schema languages do not have the vendor support of X M L Schemas yet, and are to some extent a grassroots reaction of industrial publishers to the lack of utility of X M L Schemas for publishing.|DSDL schema languages do not have the vendor support of X M L Schemas yet, and are to some extent a grassroots reaction of industrial publishers to the lack of utility of X M L Schemas for publishing.
clips/audio_411.wav|Some schema languages not only describe the structure of a particular X M L format but also offer limited facilities to influence processing of individual X M L files that conform to this format|Some schema languages not only describe the structure of a particular X M L format but also offer limited facilities to influence processing of individual X M L files that conform to this format
clips/audio_412.wav|A cluster of specifications closely related to X M L have been developed, starting soon after the initial publication of X M L 1.0|A cluster of specifications closely related to X M L have been developed, starting soon after the initial publication of X M L 1.0
clips/audio_413.wav|It is frequently the case that the term "X M L" is used to refer to X M L together with one or more of these other technologies that have come to be seen as part of the X M L core.|It is frequently the case that the term "X M L" is used to refer to X M L together with one or more of these other technologies that have come to be seen as part of the X M L core.
clips/audio_414.wav|Some other specifications conceived as part of the "X M L Core" have failed to find wide adoption, including XInclude, XLink, and XPointer.|Some other specifications conceived as part of the "X M L Core" have failed to find wide adoption, including XInclude, XLink, and XPointer.
clips/audio_415.wav|The design goals of X M L include, "It shall be easy to write programs which process X M L documents."6 Despite this, the X M L specification contains almost no information about how programmers might go about doing such processing|The design goals of X M L include, "It shall be easy to write programs which process X M L documents."6 Despite this, the X M L specification contains almost no information about how programmers might go about doing such processing
clips/audio_416.wav|The X M L Infoset specification provides a vocabulary to refer to the constructs within an X M L document, but does not provide any guidance on how to access this information|The X M L Infoset specification provides a vocabulary to refer to the constructs within an X M L document, but does not provide any guidance on how to access this information
clips/audio_417.wav|A variety of A P Is for accessing X M L have been developed and used, and some have been standardized.|A variety of A P Is for accessing X M L have been developed and used, and some have been standardized.
clips/audio_418.wav|Existing A P Is for X M L processing tend to fall into these categories|Existing A P Is for X M L processing tend to fall into these categories
clips/audio_419.wav|Stream-oriented facilities require less memory and, for certain tasks based on a linear traversal of an X M L document, are faster and simpler than other alternatives|Stream-oriented facilities require less memory and, for certain tasks based on a linear traversal of an X M L document, are faster and simpler than other alternatives
clips/audio_420.wav|Tree-traversal and data-binding A P Is typically require the use of much more memory, but are often found more convenient for use by programmers some include declarative retrieval of document components via the use of XPath expressions.|Tree-traversal and data-binding A P Is typically require the use of much more memory, but are often found more convenient for use by programmers some include declarative retrieval of document components via the use of XPath expressions.
clips/audio_421.wav|XSLT is designed for declarative description of X M L document transformations, and has been widely implemented both in server-side packages and Web browsers|XSLT is designed for declarative description of X M L document transformations, and has been widely implemented both in server-side packages and Web browsers
clips/audio_422.wav|XQuery overlaps XSLT in its functionality, but is designed more for searching of large X M L databases.|XQuery overlaps XSLT in its functionality, but is designed more for searching of large X M L databases.
clips/audio_423.wav|Simple A P I for X M L SAX is a lexical, event-driven A P I in which a document is read serially and its contents are reported as callbacks to various methods on a handler object of the user's design|Simple A P I for X M L SAX is a lexical, event-driven A P I in which a document is read serially and its contents are reported as callbacks to various methods on a handler object of the user's design
clips/audio_424.wav|SAX is fast and efficient to implement, but difficult to use for extracting information at random from the X M L, since it tends to burden the application author with keeping track of what part of the document is being processed|SAX is fast and efficient to implement, but difficult to use for extracting information at random from the X M L, since it tends to burden the application author with keeping track of what part of the document is being processed
clips/audio_425.wav|It is better suited to situations in which certain types of information are always handled the same way, no matter where they occur in the document.|It is better suited to situations in which certain types of information are always handled the same way, no matter where they occur in the document.
clips/audio_426.wav|This allows for writing of recursive descent parsers in which the structure of the code performing the parsing mirrors the structure of the X M L being parsed, and intermediate parsed results can be used and accessed as local variables within the functions performing the parsing, or passed down as function parameters into lower-level functions, or returned as function return values to higher-level functions.22 Examples of pull parsers include DataEditXml in Perl, StAX in the Java programming language, X M LPullParser in Smalltalk, X M LReader in P H P, ElementTree.iterparse in Python, SmartX M L in Red, System.Xml.XmlReader in the .NET Framework, and the DOM traversal A P I NodeIterator and TreeWalker.|This allows for writing of recursive descent parsers in which the structure of the code performing the parsing mirrors the structure of the X M L being parsed, and intermediate parsed results can be used and accessed as local variables within the functions performing the parsing, or passed down as function parameters into lower-level functions, or returned as function return values to higher-level functions.22 Examples of pull parsers include DataEditXml in Perl, StAX in the Java programming language, X M LPullParser in Smalltalk, X M LReader in P H P, ElementTree.iterparse in Python, SmartX M L in Red, System.Xml.XmlReader in the .NET Framework, and the DOM traversal A P I NodeIterator and TreeWalker.
clips/audio_427.wav|A pull parser creates an iterator that sequentially visits the various elements, attributes, and data in an X M L document|A pull parser creates an iterator that sequentially visits the various elements, attributes, and data in an X M L document
clips/audio_428.wav|Code that uses this iterator can test the current item to tell, for example, whether it is a start-tag or end-tag, or text, and inspect its attributes local name, namespace, values of X M L attributes, value of text, etc., and can also move the iterator to the next item|Code that uses this iterator can test the current item to tell, for example, whether it is a start-tag or end-tag, or text, and inspect its attributes local name, namespace, values of X M L attributes, value of text, etc., and can also move the iterator to the next item
clips/audio_429.wav|The code can thus extract information from the document as it traverses it|The code can thus extract information from the document as it traverses it
clips/audio_430.wav|The recursive-descent approach tends to lend itself to keeping data as typed local variables in the code doing the parsing, while SAX, for instance, typically requires a parser to manually maintain intermediate data within a stack of elements that are parent elements of the element being parsed|The recursive-descent approach tends to lend itself to keeping data as typed local variables in the code doing the parsing, while SAX, for instance, typically requires a parser to manually maintain intermediate data within a stack of elements that are parent elements of the element being parsed
clips/audio_431.wav|Document Object Model DOM is an A P I that allows for navigation of the entire document as if it were a tree of node objects representing the document's contents|Document Object Model DOM is an A P I that allows for navigation of the entire document as if it were a tree of node objects representing the document's contents
clips/audio_432.wav|DOM implementations tend to be memory intensive, as they generally require the entire document to be loaded into memory and constructed as a tree of objects before access is allowed.|DOM implementations tend to be memory intensive, as they generally require the entire document to be loaded into memory and constructed as a tree of objects before access is allowed.
clips/audio_433.wav|X M L data binding is a technique for simplifying development of applications that need to work with X M L documents|X M L data binding is a technique for simplifying development of applications that need to work with X M L documents
clips/audio_434.wav|It involves mapping the X M L document to a hierarchy of strongly typed objects, rather than using the generic objects created by a DOM parser|It involves mapping the X M L document to a hierarchy of strongly typed objects, rather than using the generic objects created by a DOM parser
clips/audio_435.wav|X M L data binding is particularly well-suited for applications where the document structure is known and fixed at the time the application is written|X M L data binding is particularly well-suited for applications where the document structure is known and fixed at the time the application is written
clips/audio_436.wav|By creating a strongly typed representation of the X M L data, developers can take advantage of modern integrated development environments IDEs that provide features like auto-complete, code refactoring, and code highlighting|By creating a strongly typed representation of the X M L data, developers can take advantage of modern integrated development environments IDEs that provide features like auto-complete, code refactoring, and code highlighting
clips/audio_437.wav|Example data-binding systems include the Java Architecture for X M L Binding JAXB, X M L Serialization in .NET Framework,23 and X M L serialization in gSOAP.|Example data-binding systems include the Java Architecture for X M L Binding JAXB, X M L Serialization in .NET Framework,23 and X M L serialization in gSOAP.
clips/audio_438.wav|X M L has appeared as a first-class data type in other languages|X M L has appeared as a first-class data type in other languages
clips/audio_439.wav|The ECMAScript for X M L E4X extension to the ECMAScriptJava-Script language explicitly defines two specific objects X M L and X M LList for Java-Script, which support X M L document nodes and X M L node lists as distinct objects and use a dot-notation specifying parent-child relationships.24 E4X is supported by the Mozilla 2.5 browsers though now deprecated and Adobe Actionscript but has not been widely adopted|The ECMAScript for X M L E4X extension to the ECMAScriptJava-Script language explicitly defines two specific objects X M L and X M LList for Java-Script, which support X M L document nodes and X M L node lists as distinct objects and use a dot-notation specifying parent-child relationships.24 E4X is supported by the Mozilla 2.5 browsers though now deprecated and Adobe Actionscript but has not been widely adopted
clips/audio_440.wav|The open-source xmlsh application, which provides a Li-nux-like shell with special features for X M L manipulation, similarly treats X M L as a data type, using the   notation.25 The Resource Description Framework defines a data type rdfX M LLiteral to hold wrapped, canonical X M L.26 Facebook has produced extensions to the P H P and Java-Script languages that add X M L to the core syntax in a similar fashion to E4X, namely XHP and JSX respectively.|The open-source xmlsh application, which provides a Li-nux-like shell with special features for X M L manipulation, similarly treats X M L as a data type, using the   notation.25 The Resource Description Framework defines a data type rdfX M LLiteral to hold wrapped, canonical X M L.26 Facebook has produced extensions to the P H P and Java-Script languages that add X M L to the core syntax in a similar fashion to E4X, namely XHP and JSX respectively.
clips/audio_441.wav|X M L is an application profile of SGML ISO 8879.27|X M L is an application profile of SGML ISO 8879.27
clips/audio_442.wav|The versatility of SGML for dynamic information display was understood by early digital media publishers in the late 1980s prior to the rise of the Internet.2829 By the mid-1990s some practitioners of SGML had gained experience with the then-new World Wide Web, and believed that SGML offered solutions to some of the problems the Web was likely to face as it grew|The versatility of SGML for dynamic information display was understood by early digital media publishers in the late 1980s prior to the rise of the Internet.2829 By the mid-1990s some practitioners of SGML had gained experience with the then-new World Wide Web, and believed that SGML offered solutions to some of the problems the Web was likely to face as it grew
clips/audio_443.wav|Dan Connolly added SGML to the list of W3C's activities when he joined the staff in 1995 work began in mid-1996 when Sun Microsystems engineer Jon Bosak developed a charter and recruited collaborators|Dan Connolly added SGML to the list of W3C's activities when he joined the staff in 1995 work began in mid-1996 when Sun Microsystems engineer Jon Bosak developed a charter and recruited collaborators
clips/audio_444.wav|X M L was compiled by a working group of eleven members,31 supported by a roughly 150-member Interest Group|X M L was compiled by a working group of eleven members,31 supported by a roughly 150-member Interest Group
clips/audio_445.wav|A record of design decisions and their rationales was compiled by Michael Sperberg-McQueen on December 4, 1997.32 James Clark served as Technical Lead of the Working Group, notably contributing the empty-element empty syntax and the name "X M L"|A record of design decisions and their rationales was compiled by Michael Sperberg-McQueen on December 4, 1997.32 James Clark served as Technical Lead of the Working Group, notably contributing the empty-element empty syntax and the name "X M L"
clips/audio_446.wav|The X M L Working Group communicated primarily through email and weekly teleconferences|The X M L Working Group communicated primarily through email and weekly teleconferences
clips/audio_447.wav|The major design decisions were reached in a short burst of intense work between August and November 1996,33 when the first Working Draft of an X M L specification was published.34 Further design work continued through 1997, and X M L 1.0 became a W3C Recommendation on February 10, 1998.|The major design decisions were reached in a short burst of intense work between August and November 1996,33 when the first Working Draft of an X M L specification was published.34 Further design work continued through 1997, and X M L 1.0 became a W3C Recommendation on February 10, 1998.
clips/audio_448.wav|X M L is a profile of an ISO standard SGML, and most of X M L comes from SGML unchanged|X M L is a profile of an ISO standard SGML, and most of X M L comes from SGML unchanged
clips/audio_449.wav|The SGML declaration was removed thus X M L has a fixed delimiter set and adopts Unicode as the document character set.|The SGML declaration was removed thus X M L has a fixed delimiter set and adopts Unicode as the document character set.
clips/audio_450.wav|Other sources of technology for X M L were the TEI Text Encoding Initiative, which defined a profile of SGML for use as a "transfer syntax" and H T M L|Other sources of technology for X M L were the TEI Text Encoding Initiative, which defined a profile of SGML for use as a "transfer syntax" and H T M L
clips/audio_451.wav|The ERCSExtended Reference Concrete Syntax project of the SPREAD Standardization Project Regarding East Asian Documents project of the ISO-related ChinaJapanKorea Document Processing expert group was the basis of X M L 1.0's naming rules SPREAD also introduced hexadecimal numeric character references and the concept of references to make available all Unicode characters|The ERCSExtended Reference Concrete Syntax project of the SPREAD Standardization Project Regarding East Asian Documents project of the ISO-related ChinaJapanKorea Document Processing expert group was the basis of X M L 1.0's naming rules SPREAD also introduced hexadecimal numeric character references and the concept of references to make available all Unicode characters
clips/audio_452.wav|To support ERCS, X M L and H T M L better, the SGML standard IS 8879 was revised in 1996 and 1998 with WebSGML Adaptations.|To support ERCS, X M L and H T M L better, the SGML standard IS 8879 was revised in 1996 and 1998 with WebSGML Adaptations.
clips/audio_453.wav|Ideas that developed during discussion that are novel in X M L included the algorithm for encoding detection and the encoding header, the processing instruction target, the xmlspace attribute, and the new close delimiter for empty-element tags|Ideas that developed during discussion that are novel in X M L included the algorithm for encoding detection and the encoding header, the processing instruction target, the xmlspace attribute, and the new close delimiter for empty-element tags
clips/audio_454.wav|The notion of well-formedness as opposed to validity which enables parsing without a schema was first formalized in X M L, although it had been implemented successfully in the Electronic Book Technology "Dynatext" software35 the software from the University of Waterloo New Oxford English Dictionary Project the RISP LISP SGML text processor at Uniscope, Tokyo the US Army Missile Command IADS hypertext system Mentor Graphics Context Interleaf and Xerox Publishing System.|The notion of well-formedness as opposed to validity which enables parsing without a schema was first formalized in X M L, although it had been implemented successfully in the Electronic Book Technology "Dynatext" software35 the software from the University of Waterloo New Oxford English Dictionary Project the RISP LISP SGML text processor at Uniscope, Tokyo the US Army Missile Command IADS hypertext system Mentor Graphics Context Interleaf and Xerox Publishing System.
clips/audio_455.wav|The first X M L 1.0 was initially defined in 1998|The first X M L 1.0 was initially defined in 1998
clips/audio_456.wav|It has undergone minor revisions since then, without being given a new version number, and is currently in its fifth edition, as published on November 26, two hundred8|It has undergone minor revisions since then, without being given a new version number, and is currently in its fifth edition, as published on November 26, two hundred8
clips/audio_457.wav|The second X M L 1.1 was initially published on February 4, two hundred4, the same day as X M L 1.0 Third Edition,36 and is currently in its second edition, as published on August 16, two hundred6|The second X M L 1.1 was initially published on February 4, two hundred4, the same day as X M L 1.0 Third Edition,36 and is currently in its second edition, as published on August 16, two hundred6
clips/audio_458.wav|It contains features some contentious that are intended to make X M L easier to use in certain cases.37 The main changes are to enable the use of line-ending characters used on EBCDIC platforms, and the use of scripts and characters absent from Unicode 3.2|It contains features some contentious that are intended to make X M L easier to use in certain cases.37 The main changes are to enable the use of line-ending characters used on EBCDIC platforms, and the use of scripts and characters absent from Unicode 3.2
clips/audio_459.wav|X M L 1.1 is not very widely implemented and is recommended for use only by those who need its particular features.38|X M L 1.1 is not very widely implemented and is recommended for use only by those who need its particular features.38
clips/audio_460.wav|Prior to its fifth edition release, X M L 1.0 differed from X M L 1.1 in having stricter requirements for characters available for use in element and attribute names and unique identifiers in the first four editions of X M L 1.0 the characters were exclusively enumerated using a specific version of the Unicode standard Unicode 2.0 to Unicode 3.2. The fifth edition substitutes the mechanism of X M L 1.1, which is more future-proof but reduces redundancy|Prior to its fifth edition release, X M L 1.0 differed from X M L 1.1 in having stricter requirements for characters available for use in element and attribute names and unique identifiers in the first four editions of X M L 1.0 the characters were exclusively enumerated using a specific version of the Unicode standard Unicode 2.0 to Unicode 3.2. The fifth edition substitutes the mechanism of X M L 1.1, which is more future-proof but reduces redundancy
clips/audio_461.wav|The approach taken in the fifth edition of X M L 1.0 and in all editions of X M L 1.1 is that only certain characters are forbidden in names, and everything else is allowed to accommodate suitable name characters in future Unicode versions|The approach taken in the fifth edition of X M L 1.0 and in all editions of X M L 1.1 is that only certain characters are forbidden in names, and everything else is allowed to accommodate suitable name characters in future Unicode versions
clips/audio_462.wav|In the fifth edition, X M L names may contain characters in the Balinese, Cham, or Phoenician scripts among many others added to Unicode since Unicode 3.2.37|In the fifth edition, X M L names may contain characters in the Balinese, Cham, or Phoenician scripts among many others added to Unicode since Unicode 3.2.37
clips/audio_463.wav|Almost any Unicode code point can be used in the character data and attribute values of an X M L 1.01.1 document, even if the character corresponding to the code point is not defined in the current version of Unicode|Almost any Unicode code point can be used in the character data and attribute values of an X M L 1.01.1 document, even if the character corresponding to the code point is not defined in the current version of Unicode
clips/audio_464.wav|In character data and attribute values, X M L 1.1 allows the use of more control characters than X M L 1.0, but, for "robustness", most of the control characters introduced in X M L 1.1 must be expressed as numeric character references and x7F through x9F, which had been allowed in X M L 1.0, are in X M L 1.1 even required to be expressed as numeric character references39|In character data and attribute values, X M L 1.1 allows the use of more control characters than X M L 1.0, but, for "robustness", most of the control characters introduced in X M L 1.1 must be expressed as numeric character references and x7F through x9F, which had been allowed in X M L 1.0, are in X M L 1.1 even required to be expressed as numeric character references39
clips/audio_465.wav|Among the supported control characters in X M L 1.1 are two line break codes that must be treated as whitespace characters, which are the only control codes that can be written directly.|Among the supported control characters in X M L 1.1 are two line break codes that must be treated as whitespace characters, which are the only control codes that can be written directly.
clips/audio_466.wav|There has been discussion of an X M L 2.0, although no organization has announced plans for work on such a project|There has been discussion of an X M L 2.0, although no organization has announced plans for work on such a project
clips/audio_467.wav|X M L-SW SW for skunkworks, which one of the original developers of X M L has written,40 contains some proposals for what an X M L 2.0 might look like, including elimination of DTDs from syntax, as well as integration of X M L namespaces, X M L Base and X M L Information Set into the base standard.|X M L-SW SW for skunkworks, which one of the original developers of X M L has written,40 contains some proposals for what an X M L 2.0 might look like, including elimination of DTDs from syntax, as well as integration of X M L namespaces, X M L Base and X M L Information Set into the base standard.
clips/audio_468.wav|In 2012, James Clark technical lead of the X M L Working Group and John Cowan editor of the X M L 1.1 specification formed the MicroX M L Community Group within the W3C and published a specification for a significantly reduced subset of X M L.41|In 2012, James Clark technical lead of the X M L Working Group and John Cowan editor of the X M L 1.1 specification formed the MicroX M L Community Group within the W3C and published a specification for a significantly reduced subset of X M L.41
clips/audio_469.wav|The World Wide Web Consortium also has an X M L Binary Characterization Working Group doing preliminary research into use cases and properties for a binary encoding of X M L Information Set|The World Wide Web Consortium also has an X M L Binary Characterization Working Group doing preliminary research into use cases and properties for a binary encoding of X M L Information Set
clips/audio_470.wav|Since X M L is by definition text-based, ITU-T and ISO are using the name Fast Infoset for their own binary format ITU-T Rec|Since X M L is by definition text-based, ITU-T and ISO are using the name Fast Infoset for their own binary format ITU-T Rec
clips/audio_471.wav|X M L and its extensions have regularly been criticized for verbosity, complexity and redundancy.42|X M L and its extensions have regularly been criticized for verbosity, complexity and redundancy.42
clips/audio_472.wav|Mapping the basic tree model of X M L to type systems of programming languages or databases can be difficult, especially when X M L is used for exchanging highly structured data between applications, which was not its primary design goal|Mapping the basic tree model of X M L to type systems of programming languages or databases can be difficult, especially when X M L is used for exchanging highly structured data between applications, which was not its primary design goal
clips/audio_473.wav|However, X M L data binding systems allow applications to access X M L data directly from objects representing a data structure of the data in the programming language used, which ensures type safety, rather than using the DOM or SAX to retrieve data from a direct representation of the X M L itself|However, X M L data binding systems allow applications to access X M L data directly from objects representing a data structure of the data in the programming language used, which ensures type safety, rather than using the DOM or SAX to retrieve data from a direct representation of the X M L itself
clips/audio_474.wav|This is accomplished by automatically creating a mapping between elements of the X M L schema XSD of the document and members of a class to be represented in memory.|This is accomplished by automatically creating a mapping between elements of the X M L schema XSD of the document and members of a class to be represented in memory.
clips/audio_475.wav|Other criticisms attempt to refute the claim that X M L is a self-describing language43 though the X M L specification itself makes no such claim.|Other criticisms attempt to refute the claim that X M L is a self-describing language43 though the X M L specification itself makes no such claim.
clips/audio_476.wav|Jay-son, Yam-ul, and S-Expressions are frequently proposed as simpler alternatives see Comparison of data-serialization formats44 that focus on representing highly structured data rather than documents, which may contain both highly structured and relatively unstructured content|Jay-son, Yam-ul, and S-Expressions are frequently proposed as simpler alternatives see Comparison of data-serialization formats44 that focus on representing highly structured data rather than documents, which may contain both highly structured and relatively unstructured content
clips/audio_477.wav|However, W3C standardized X M L schema specifications offer a broader range of structured XSD data types compared to simpler serialization formats and offer modularity and reuse through X M L namespaces.|However, W3C standardized X M L schema specifications offer a broader range of structured XSD data types compared to simpler serialization formats and offer modularity and reuse through X M L namespaces.
clips/audio_478.wav|When A P Is send data, chances are they send it as Jay-son objects|When A P Is send data, chances are they send it as Jay-son objects
clips/audio_479.wav|Here's a primer on why Jay-son is how networked applications send data|Here's a primer on why Jay-son is how networked applications send data
clips/audio_480.wav|From early on, the format that this data was transferred in mattered, and like the web, the best formats were open standards that anyone could use and contribute to|From early on, the format that this data was transferred in mattered, and like the web, the best formats were open standards that anyone could use and contribute to
clips/audio_481.wav|X M L gained early popularity, as it looked like H T M L, the foundation of the web|X M L gained early popularity, as it looked like H T M L, the foundation of the web
clips/audio_482.wav|Thats where Jay-son Java-Script Object Notation comes in|Thats where Jay-son Java-Script Object Notation comes in
clips/audio_483.wav|If youve consumed an A P I in the last five to ten years, youve probably seen Jay-son data|If youve consumed an A P I in the last five to ten years, youve probably seen Jay-son data
clips/audio_484.wav|While the format was first developed in the early two hundred0s, the first standards were published in two hundred6|While the format was first developed in the early two hundred0s, the first standards were published in two hundred6
clips/audio_485.wav|Understanding what Jay-son is and how it works is a foundational skill for any web developer.|Understanding what Jay-son is and how it works is a foundational skill for any web developer.
clips/audio_486.wav|In this article, well cover the basics of what Jay-son looks like and how to use it in your web applications, as well as talk about serialized Jay-sonJST and J W Tand the competing data formats.|In this article, well cover the basics of what Jay-son looks like and how to use it in your web applications, as well as talk about serialized Jay-sonJST and J W Tand the competing data formats.
clips/audio_487.wav|Jay-son is a human-readable format for storing and transmitting data|Jay-son is a human-readable format for storing and transmitting data
clips/audio_488.wav|As the name implies, it was originally developed for Java-Script, but can be used in any language and is very popular in web applications|As the name implies, it was originally developed for Java-Script, but can be used in any language and is very popular in web applications
clips/audio_489.wav|The basic structure is built from one or more keys and values|The basic structure is built from one or more keys and values
clips/audio_490.wav|Youll often see a collection of keyvalue pairs enclosed in brackets described as a Jay-son object|Youll often see a collection of keyvalue pairs enclosed in brackets described as a Jay-son object
clips/audio_491.wav|While the key is any string, the value can be a string, number, array, additional object, or the literals, false, true and null|While the key is any string, the value can be a string, number, array, additional object, or the literals, false, true and null
clips/audio_492.wav|For example, the following is valid Jay-son|For example, the following is valid Jay-son
clips/audio_493.wav|Jay-son doesn't have to have only keyvalue pairs the specification allows to any value to be passed without a key|Jay-son doesn't have to have only keyvalue pairs the specification allows to any value to be passed without a key
clips/audio_494.wav|However, almost all of the Jay-son objects that you see will contain keyvalue pairs.|However, almost all of the Jay-son objects that you see will contain keyvalue pairs.
clips/audio_495.wav|One of the most common uses for Jay-son is when using an A P I, both in requests and responses|One of the most common uses for Jay-son is when using an A P I, both in requests and responses
clips/audio_496.wav|It is much more compact than other standards and allows for easy consumption in web browsers as Java-Script can easily parse Jay-son strings, only requiring Jay-son.parse to start using it.|It is much more compact than other standards and allows for easy consumption in web browsers as Java-Script can easily parse Jay-son strings, only requiring Jay-son.parse to start using it.
clips/audio_497.wav|Jay-son.parsestring takes a string of valid Jay-son and returns a Java-Script object|Jay-son.parsestring takes a string of valid Jay-son and returns a Java-Script object
clips/audio_498.wav|For example, it can be called on the body of an A P I response to give you a usable object|For example, it can be called on the body of an A P I response to give you a usable object
clips/audio_499.wav|The inverse of this function is Jay-son.stringifyobject which takes a Java-Script object and returns a string of Jay-son, which can then be transmitted in an A P I request or response.|The inverse of this function is Jay-son.stringifyobject which takes a Java-Script object and returns a string of Jay-son, which can then be transmitted in an A P I request or response.
clips/audio_500.wav|Jay-son isnt required by REST or GraphQL, both very popular A P I formats|Jay-son isnt required by REST or GraphQL, both very popular A P I formats
clips/audio_501.wav|However, they are often used together, particularly with GraphQL, where it is best practice to use Jay-son due to it being small and mostly text|However, they are often used together, particularly with GraphQL, where it is best practice to use Jay-son due to it being small and mostly text
clips/audio_502.wav|GraphQL's requests arent made in Jay-son, instead using a system that resembles Jay-son, like this|GraphQL's requests arent made in Jay-son, instead using a system that resembles Jay-son, like this
clips/audio_503.wav|Which will return the relevant data, and if using Jay-son, it will match very closely|Which will return the relevant data, and if using Jay-son, it will match very closely
clips/audio_504.wav|In some cases, you may want to load Jay-son from a file, such as for configuration files or mock data|In some cases, you may want to load Jay-son from a file, such as for configuration files or mock data
clips/audio_505.wav|Using pure Java-Script, it currently isnt possible to import a Jay-son file, however a proposal has been created to allow this|Using pure Java-Script, it currently isnt possible to import a Jay-son file, however a proposal has been created to allow this
clips/audio_506.wav|Currently, you can get equivalent functionality by exporting a Java-Script Object the same as your desired Jay-son from a Java-Script file.|Currently, you can get equivalent functionality by exporting a Java-Script Object the same as your desired Jay-son from a Java-Script file.
clips/audio_507.wav|Now this object will be stored in the constant, data, and will be accessible throughout your application using import or require statements|Now this object will be stored in the constant, data, and will be accessible throughout your application using import or require statements
clips/audio_508.wav|Jay-son isnt the only web-friendly data standard out there|Jay-son isnt the only web-friendly data standard out there
clips/audio_509.wav|The major competitor for Jay-son in A P Is is X M L|The major competitor for Jay-son in A P Is is X M L
clips/audio_510.wav|Instead of the following Jay-son|Instead of the following Jay-son
clips/audio_511.wav|in X M L, youd instead have|in X M L, youd instead have
clips/audio_512.wav|Jay-son was standardized much later than X M L, with the specification for X M L coming in 1998, whereas Ecma International standardized Jay-son in 2013|Jay-son was standardized much later than X M L, with the specification for X M L coming in 1998, whereas Ecma International standardized Jay-son in 2013
clips/audio_513.wav|X M L was extremely popular and seen in standards such as AJAX Asynchronous Java-Script and X M L and the X M LHttpRequest function in Java-Script.|X M L was extremely popular and seen in standards such as AJAX Asynchronous Java-Script and X M L and the X M LHttpRequest function in Java-Script.
clips/audio_514.wav|X M L used by a major A P I standard Simple Object Access Protocol SOAP|X M L used by a major A P I standard Simple Object Access Protocol SOAP
clips/audio_515.wav|This standard can be significantly more verbose than REST and GraphQL, in part due to the usage of X M L and because the standard includes more information, such as describing the X M L namespace as part of the envelope system|This standard can be significantly more verbose than REST and GraphQL, in part due to the usage of X M L and because the standard includes more information, such as describing the X M L namespace as part of the envelope system
clips/audio_516.wav|Another alternative is Yam-ul, which is much more similar in length to Jay-son compared to X M L, with the same example being|Another alternative is Yam-ul, which is much more similar in length to Jay-son compared to X M L, with the same example being
clips/audio_517.wav|However, unlike X M L, Yam-ul doesnt really compete with Jay-son as an A P I data format|However, unlike X M L, Yam-ul doesnt really compete with Jay-son as an A P I data format
clips/audio_518.wav|Instead, its primarily used for configuration filesKoo-ber-net-ees primarily uses Yam-ul to configure infrastructure|Instead, its primarily used for configuration filesKoo-ber-net-ees primarily uses Yam-ul to configure infrastructure
clips/audio_519.wav|Yam-ul offers features that Jay-son doesnt have, such as comments|Yam-ul offers features that Jay-son doesnt have, such as comments
clips/audio_520.wav|Unlike Jay-son and X M L, browsers cannot parse Yam-ul, so a parser would need to be added as a library if you want to use Yam-ul for data interchange.|Unlike Jay-son and X M L, browsers cannot parse Yam-ul, so a parser would need to be added as a library if you want to use Yam-ul for data interchange.
clips/audio_521.wav|While many of Jay-sons use cases transmit it as clear text, the format can be used for secure data transfers as well|While many of Jay-sons use cases transmit it as clear text, the format can be used for secure data transfers as well
clips/audio_522.wav|Jay-son web signatures JWS are Jay-son objects securely signed using either a secret or a publicprivate key pair|Jay-son web signatures JWS are Jay-son objects securely signed using either a secret or a publicprivate key pair
clips/audio_523.wav|The only required field is alg to specify the encryption algorithm used, but many other keys can be included, such as typ for the type of signature it is.|The only required field is alg to specify the encryption algorithm used, but many other keys can be included, such as typ for the type of signature it is.
clips/audio_524.wav|The payload of a JWS is the information being transmitted and doesnt need to be formatted in Jay-son though commonly is.|The payload of a JWS is the information being transmitted and doesnt need to be formatted in Jay-son though commonly is.
clips/audio_525.wav|eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly9leGFtcGxlLmNvbS9pc19yb290Ijp0cnVlfQ.dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk|eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly9leGFtcGxlLmNvbS9pc19yb290Ijp0cnVlfQ.dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk
clips/audio_526.wav|Jay-son Web Tokens J W T are a special form of a JWS|Jay-son Web Tokens J W T are a special form of a JWS
clips/audio_527.wav|These are particularly useful for authorization when a user logs into a website, they will be provided with a J W T|These are particularly useful for authorization when a user logs into a website, they will be provided with a J W T
clips/audio_528.wav|To create a J W T from a JWS, youll need to configure each section specifically|To create a J W T from a JWS, youll need to configure each section specifically
clips/audio_529.wav|In the header, ensure that the typ key is J W T|In the header, ensure that the typ key is J W T
clips/audio_530.wav|For the alg key, the options of HS256 HMAC SHA-256 and none unencrypted must be supported by the authorization server in order to be a conforming J W T implementation, so can always be used|For the alg key, the options of HS256 HMAC SHA-256 and none unencrypted must be supported by the authorization server in order to be a conforming J W T implementation, so can always be used
clips/audio_531.wav|In the payload are a series of keys called claims, which are pieces of information about a subject, as J W Ts are most commonly used for authentication, this is commonly a user, but could be anything when used for exchanging information.|In the payload are a series of keys called claims, which are pieces of information about a subject, as J W Ts are most commonly used for authentication, this is commonly a user, but could be anything when used for exchanging information.
clips/audio_532.wav|Compared to Security Assertion Markup Language Tokens SAML, a similar standard that uses X M L, Jay-son allows for J W Ts to be smaller than SAML tokens and is easier to parse due to the use of both tokens in the browser, where Java-Script is the primary language, and can easily parse Jay-son.|Compared to Security Assertion Markup Language Tokens SAML, a similar standard that uses X M L, Jay-son allows for J W Ts to be smaller than SAML tokens and is easier to parse due to the use of both tokens in the browser, where Java-Script is the primary language, and can easily parse Jay-son.
clips/audio_533.wav|Jay-son has come to be one of the most popular standards for data interchange, being easy for humans to read while being lightweight to ensure small transmission size|Jay-son has come to be one of the most popular standards for data interchange, being easy for humans to read while being lightweight to ensure small transmission size
clips/audio_534.wav|Its success has also been caused by it being equivalent to Java-Script objects, making it simple to process in web frontends|Its success has also been caused by it being equivalent to Java-Script objects, making it simple to process in web frontends
clips/audio_535.wav|However, Jay-son isnt the solution for everything, and alternate standards like Yam-ul are more popular for things like configuration files, so its important to consider your purpose before choosing.|However, Jay-son isnt the solution for everything, and alternate standards like Yam-ul are more popular for things like configuration files, so its important to consider your purpose before choosing.
clips/audio_536.wav|Interviewer What motivated you to pursue a career in Google Cloud Platform?Candidate As a technologist, Ive always been fascinated by cutting-edge technologies|Interviewer What motivated you to pursue a career in Google Cloud Platform?Candidate As a technologist, Ive always been fascinated by cutting-edge technologies
clips/audio_537.wav|G C Ps reputation for innovation, scalability, and reliability aligns with my career aspirations, prompting me to specialize in this platform.|G C Ps reputation for innovation, scalability, and reliability aligns with my career aspirations, prompting me to specialize in this platform.
clips/audio_538.wav|Interviewer Can you explain the key components of Google Clouds networking infrastructure?Candidate Google Clouds networking infrastructure comprises Virtual Private Cloud V P C, Cloud Load Balancing, Cloud CDN, Cloud D N S, and Virtual Private Network VPN services, which collectively enable secure and efficient communication across distributed systems.|Interviewer Can you explain the key components of Google Clouds networking infrastructure?Candidate Google Clouds networking infrastructure comprises Virtual Private Cloud V P C, Cloud Load Balancing, Cloud CDN, Cloud D N S, and Virtual Private Network VPN services, which collectively enable secure and efficient communication across distributed systems.
clips/audio_539.wav|Interviewer Describe a scenario where you would recommend using Google Koo-ber-net-ees Engine GKE over other deployment options.Candidate GKE is ideal for deploying containerized applications at scale, especially in scenarios where dynamic scaling, automated management, and high availability are critical, such as microservices architectures or continuous integrationcontinuous deployment CICD pipelines.|Interviewer Describe a scenario where you would recommend using Google Koo-ber-net-ees Engine GKE over other deployment options.Candidate GKE is ideal for deploying containerized applications at scale, especially in scenarios where dynamic scaling, automated management, and high availability are critical, such as microservices architectures or continuous integrationcontinuous deployment CICD pipelines.
clips/audio_540.wav|Interviewer How does Cloud Identity and Access Management I A M ensure security in Google Cloud Platform?Candidate I A M allows organizations to manage access control by defining roles and permissions for users, groups, and service accounts|Interviewer How does Cloud Identity and Access Management I A M ensure security in Google Cloud Platform?Candidate I A M allows organizations to manage access control by defining roles and permissions for users, groups, and service accounts
clips/audio_541.wav|Interviewer What are the benefits of using BigQuery for data analytics?Candidate BigQuery offers real-time analytics, scalability, and cost-effectiveness by allowing users to analyze large datasets quickly using S Q L queries|Interviewer What are the benefits of using BigQuery for data analytics?Candidate BigQuery offers real-time analytics, scalability, and cost-effectiveness by allowing users to analyze large datasets quickly using S Q L queries
clips/audio_542.wav|Its serverless architecture eliminates the need for infrastructure management, enabling organizations to focus on insights rather than infrastructure.|Its serverless architecture eliminates the need for infrastructure management, enabling organizations to focus on insights rather than infrastructure.
clips/audio_543.wav|Interviewer How does Google Clouds security model differ from traditional on-premises security approaches?Candidate Google Cloud adopts a shared responsibility model, where Google is responsible for the security of the infrastructure, while customers are responsible for securing their data and applications|Interviewer How does Google Clouds security model differ from traditional on-premises security approaches?Candidate Google Cloud adopts a shared responsibility model, where Google is responsible for the security of the infrastructure, while customers are responsible for securing their data and applications
clips/audio_544.wav|This approach shifts the burden of infrastructure security to the cloud provider, allowing organizations to focus on application-level security.|This approach shifts the burden of infrastructure security to the cloud provider, allowing organizations to focus on application-level security.
clips/audio_545.wav|In contrast, Compute Engine provides virtual machines that can be customized for various workloads, offering more control over the underlying infrastructure but requiring more management overhead.|In contrast, Compute Engine provides virtual machines that can be customized for various workloads, offering more control over the underlying infrastructure but requiring more management overhead.
clips/audio_546.wav|Interviewer What strategies would you recommend for optimizing costs in Google Cloud Platform?Candidate Optimizing costs in G C P involves rightsizing resources, leveraging committed use discounts, utilizing preemptible VMs, implementing autoscaling, and regularly monitoring resource usage to identify and eliminate waste.|Interviewer What strategies would you recommend for optimizing costs in Google Cloud Platform?Candidate Optimizing costs in G C P involves rightsizing resources, leveraging committed use discounts, utilizing preemptible VMs, implementing autoscaling, and regularly monitoring resource usage to identify and eliminate waste.
clips/audio_547.wav|Interviewer How does Google Cloud Storage ensure durability and availability of data?Candidate Google Cloud Storage replicates data across multiple locations and storage devices, ensuring high durability and availability|Interviewer How does Google Cloud Storage ensure durability and availability of data?Candidate Google Cloud Storage replicates data across multiple locations and storage devices, ensuring high durability and availability
clips/audio_548.wav|Interviewer Describe a scenario where you would recommend using Google Cloud Spanner over traditional relational databases.Candidate Google Cloud Spanner is suitable for globally distributed applications requiring strong consistency, high availability, and horizontal scalability|Interviewer Describe a scenario where you would recommend using Google Cloud Spanner over traditional relational databases.Candidate Google Cloud Spanner is suitable for globally distributed applications requiring strong consistency, high availability, and horizontal scalability
clips/audio_549.wav|Its ideal for scenarios like financial transactions, real-time analytics, and multi-region deployments where traditional relational databases may struggle to meet performance and scalability requirements.|Its ideal for scenarios like financial transactions, real-time analytics, and multi-region deployments where traditional relational databases may struggle to meet performance and scalability requirements.
clips/audio_550.wav|Interviewer How does Google Clouds AI and machine learning services differentiate it from other cloud providers?Candidate Google Cloud offers advanced AI and machine learning services such as Ten-sor-flow, AI Platform, and AutoML, which leverage Googles expertise in artificial intelligence and vast data resources|Interviewer How does Google Clouds AI and machine learning services differentiate it from other cloud providers?Candidate Google Cloud offers advanced AI and machine learning services such as Ten-sor-flow, AI Platform, and AutoML, which leverage Googles expertise in artificial intelligence and vast data resources
clips/audio_551.wav|These services provide developers with powerful tools for building and deploying machine learning models at scale, enabling innovation and differentiation in various industries.|These services provide developers with powerful tools for building and deploying machine learning models at scale, enabling innovation and differentiation in various industries.
clips/audio_552.wav|Interviewer Can you explain the concept of serverless computing and its benefits in Google Cloud?Candidate Serverless computing, exemplified by services like Cloud Functions and Cloud Run, allows developers to run code without managing servers or infrastructure|Interviewer Can you explain the concept of serverless computing and its benefits in Google Cloud?Candidate Serverless computing, exemplified by services like Cloud Functions and Cloud Run, allows developers to run code without managing servers or infrastructure
clips/audio_553.wav|Interviewer How does Google Cloud ensure data privacy and compliance with regulations like GDPR?Candidate Google Cloud implements robust security measures, including encryption at rest and in transit, data access controls, and compliance certifications such as ISO 27001 and SOC 2|Interviewer How does Google Cloud ensure data privacy and compliance with regulations like GDPR?Candidate Google Cloud implements robust security measures, including encryption at rest and in transit, data access controls, and compliance certifications such as ISO 27001 and SOC 2
clips/audio_554.wav|Additionally, features like Data Loss Prevention DLP and Access Transparency logs help organizations maintain data privacy and meet regulatory requirements.|Additionally, features like Data Loss Prevention DLP and Access Transparency logs help organizations maintain data privacy and meet regulatory requirements.
clips/audio_555.wav|Interviewer What role does Cloud Monitoring play in managing Google Cloud resources?Candidate Cloud Monitoring provides visibility into the performance, uptime, and health of Google Cloud resources through metrics, dashboards, and alerts|Interviewer What role does Cloud Monitoring play in managing Google Cloud resources?Candidate Cloud Monitoring provides visibility into the performance, uptime, and health of Google Cloud resources through metrics, dashboards, and alerts
clips/audio_556.wav|It helps organizations proactively identify and troubleshoot issues, optimize resource utilization, and ensure reliable service delivery to end-users.|It helps organizations proactively identify and troubleshoot issues, optimize resource utilization, and ensure reliable service delivery to end-users.
clips/audio_557.wav|Interviewer How does Google Clouds global infrastructure contribute to high availability and low latency?Candidate Google Clouds global network spans multiple regions and points of presence, interconnected by a high-speed backbone|Interviewer How does Google Clouds global infrastructure contribute to high availability and low latency?Candidate Google Clouds global network spans multiple regions and points of presence, interconnected by a high-speed backbone
clips/audio_558.wav|Interviewer Can you explain the significance of Google Clouds Anthos platform in hybrid and multi-cloud environments?Candidate Anthos allows organizations to build, deploy, and manage applications consistently across on-premises, hybrid, and multi-cloud environments|Interviewer Can you explain the significance of Google Clouds Anthos platform in hybrid and multi-cloud environments?Candidate Anthos allows organizations to build, deploy, and manage applications consistently across on-premises, hybrid, and multi-cloud environments
clips/audio_559.wav|It provides a unified platform for containerized workloads, enabling portability, agility, and operational consistency while leveraging Google Cloud services and Koo-ber-net-ees orchestration.|It provides a unified platform for containerized workloads, enabling portability, agility, and operational consistency while leveraging Google Cloud services and Koo-ber-net-ees orchestration.
clips/audio_560.wav|Interviewer How does Google Clouds BigTable differ from traditional relational databases like MyS Q L?Candidate BigTable is a NoS Q L database designed for massive scalability and high-performance, suitable for storing and analyzing large-scale, semi-structured data|Interviewer How does Google Clouds BigTable differ from traditional relational databases like MyS Q L?Candidate BigTable is a NoS Q L database designed for massive scalability and high-performance, suitable for storing and analyzing large-scale, semi-structured data
clips/audio_561.wav|Interviewer Describe a scenario where you would recommend using Google Cloud CDN to improve website performance.Candidate Google Cloud CDN is beneficial for accelerating website performance and reducing latency by caching content closer to end-users|Interviewer Describe a scenario where you would recommend using Google Cloud CDN to improve website performance.Candidate Google Cloud CDN is beneficial for accelerating website performance and reducing latency by caching content closer to end-users
clips/audio_562.wav|Interviewer How does Google Clouds managed database services like Cloud S Q L simplify database administration?Candidate Cloud S Q L offers fully managed database services for MyS Q L, PostgreS Q L, and S Q L Server, handling routine database administration tasks such as backups, replication, and maintenance automatically|Interviewer How does Google Clouds managed database services like Cloud S Q L simplify database administration?Candidate Cloud S Q L offers fully managed database services for MyS Q L, PostgreS Q L, and S Q L Server, handling routine database administration tasks such as backups, replication, and maintenance automatically
clips/audio_563.wav|Interviewer What are the key considerations for designing a resilient and scalable architecture in Google Cloud Platform?Candidate Designing a resilient and scalable architecture in G C P involves leveraging managed services, implementing redundancy and failover mechanisms, designing for elasticity and auto-scaling, ensuring data durability and availability, and conducting thorough testing and monitoring to identify and mitigate potential points of failure.|Interviewer What are the key considerations for designing a resilient and scalable architecture in Google Cloud Platform?Candidate Designing a resilient and scalable architecture in G C P involves leveraging managed services, implementing redundancy and failover mechanisms, designing for elasticity and auto-scaling, ensuring data durability and availability, and conducting thorough testing and monitoring to identify and mitigate potential points of failure.
clips/audio_564.wav|REST A P I Tutorial|REST A P I Tutorial
clips/audio_565.wav|Since then it has become one of the most widely used approaches for building web-based A P Is Application Programming Interfaces|Since then it has become one of the most widely used approaches for building web-based A P Is Application Programming Interfaces
clips/audio_566.wav|Last Updated December 12, 2023|Last Updated December 12, 2023
clips/audio_567.wav|Since then it has become one of the most widely used approaches for building web-based A P Is Application Programming Interfaces.|Since then it has become one of the most widely used approaches for building web-based A P Is Application Programming Interfaces.
clips/audio_568.wav|During the development phase, A P I developers can implement REST in a variety of ways.|During the development phase, A P I developers can implement REST in a variety of ways.
clips/audio_569.wav|Like the other architectural styles, REST also has its guiding principles and constraints|Like the other architectural styles, REST also has its guiding principles and constraints
clips/audio_570.wav|A Web A P I or Web Service conforming to the REST architectural style is called aREST A P I or RESTful A P I.|A Web A P I or Web Service conforming to the REST architectural style is called aREST A P I or RESTful A P I.
clips/audio_571.wav|The six guiding principles orconstraints of the RESTful architectureare|The six guiding principles orconstraints of the RESTful architectureare
clips/audio_572.wav|Multiple architectural constraints help in obtaining a uniform interface and guiding the behavior of components.|Multiple architectural constraints help in obtaining a uniform interface and guiding the behavior of components.
clips/audio_573.wav|The following four constraints can achieve a uniform REST interface|The following four constraints can achieve a uniform REST interface
clips/audio_574.wav|In simpler words, REST defines a consistent and uniform interface for interactions between clients and servers|In simpler words, REST defines a consistent and uniform interface for interactions between clients and servers
clips/audio_575.wav|For example, the H T T P-based REST A P Is make use of the standard H T T P methods GET, POST, PUT, DELETE, etc. and the URIs Uniform Resource Identifiers to identify resources.|For example, the H T T P-based REST A P Is make use of the standard H T T P methods GET, POST, PUT, DELETE, etc. and the URIs Uniform Resource Identifiers to identify resources.
clips/audio_576.wav|By separating the user interface concerns client from the data storage concerns server, we improve the portability of the user interface across multiple platforms and improve scalability by simplifying the server components.|By separating the user interface concerns client from the data storage concerns server, we improve the portability of the user interface across multiple platforms and improve scalability by simplifying the server components.
clips/audio_577.wav|Statelessnessmandates that each request from the client to the server must contain all of the information necessary to understand and complete the request.|Statelessnessmandates that each request from the client to the server must contain all of the information necessary to understand and complete the request.
clips/audio_578.wav|The server cannot take advantage of any previously stored context information on the server.|The server cannot take advantage of any previously stored context information on the server.
clips/audio_579.wav|Thecacheable constraintrequires that a response should implicitly or explicitly label itself as cacheable or non-cacheable.|Thecacheable constraintrequires that a response should implicitly or explicitly label itself as cacheable or non-cacheable.
clips/audio_580.wav|If the response is cacheable, the client application gets the right to reuse the response data later for equivalent requests and a specified period.|If the response is cacheable, the client application gets the right to reuse the response data later for equivalent requests and a specified period.
clips/audio_581.wav|REST also allows client functionality to extend by downloading and executing code in the form of applets or scripts.|REST also allows client functionality to extend by downloading and executing code in the form of applets or scripts.
clips/audio_582.wav|The downloaded code simplifies clients by reducing the number of features required to be pre-implemented|The downloaded code simplifies clients by reducing the number of features required to be pre-implemented
clips/audio_583.wav|Servers can provide part of features delivered to the client in the form of code, and the client only needs to execute the code.|Servers can provide part of features delivered to the client in the form of code, and the client only needs to execute the code.
clips/audio_584.wav|The keyabstraction of informationin REST is aresource|The keyabstraction of informationin REST is aresource
clips/audio_585.wav|Any information that we can name can be a resource|Any information that we can name can be a resource
clips/audio_586.wav|A REST A P I consists of an assembly of interlinked resources|A REST A P I consists of an assembly of interlinked resources
clips/audio_587.wav|This set of resources is known as the REST A P Isresource model.|This set of resources is known as the REST A P Isresource model.
clips/audio_588.wav|The data format of a representation is known as amedia type|The data format of a representation is known as amedia type
clips/audio_589.wav|A RESTful A P I looks likehypertext|A RESTful A P I looks likehypertext
clips/audio_590.wav|Every addressable unit of information carries an address, either explicitly e.g., link and id attributes or implicitly e.g., derived from the media type definition and representation structure.|Every addressable unit of information carries an address, either explicitly e.g., link and id attributes or implicitly e.g., derived from the media type definition and representation structure.
clips/audio_591.wav|Hypertext or hypermedia means thesimultaneous presentation of information and controlssuch that the information becomes the affordance through which the user or automaton obtains choices and selects actions.|Hypertext or hypermedia means thesimultaneous presentation of information and controlssuch that the information becomes the affordance through which the user or automaton obtains choices and selects actions.
clips/audio_592.wav|Remember that hypertext does not need to be H T M L or X M L or Jay-son on a browser|Remember that hypertext does not need to be H T M L or X M L or Jay-son on a browser
clips/audio_593.wav|Machines can follow links when they understand the data format and relationship types.|Machines can follow links when they understand the data format and relationship types.
clips/audio_594.wav|For example, H T M L defines a rendering process for hypertext and the browser behavior around each element.|For example, H T M L defines a rendering process for hypertext and the browser behavior around each element.
clips/audio_595.wav|Consider the following REST resource that represents a blog post with links to related resources in an H T T P-based REST A P I|Consider the following REST resource that represents a blog post with links to related resources in an H T T P-based REST A P I
clips/audio_596.wav|This has the necessary information about the blog post, as well as the hypermedia links to the related resources such as author and comments|This has the necessary information about the blog post, as well as the hypermedia links to the related resources such as author and comments
clips/audio_597.wav|Clients can follow these links to discover additional information or perform actions.|Clients can follow these links to discover additional information or perform actions.
clips/audio_598.wav|These resource methods are used to perform the desired transition between two states of any resource.|These resource methods are used to perform the desired transition between two states of any resource.
clips/audio_599.wav|A large number of people wrongly relate resource methods toH T T P methodsi.e., GETPUTPOSTDELETE|A large number of people wrongly relate resource methods toH T T P methodsi.e., GETPUTPOSTDELETE
clips/audio_600.wav|All he emphasizes is that it should be auniform interface.|All he emphasizes is that it should be auniform interface.
clips/audio_601.wav|For example, if we decide that the application A P Is will use H T T P POST for updating a resource  rather than most people recommend H T T P PUT  its all right|For example, if we decide that the application A P Is will use H T T P POST for updating a resource  rather than most people recommend H T T P PUT  its all right
clips/audio_602.wav|Ideally, everything needed to transition the resource state shall be part of the resource representation  including all the supported methods and what form they will leave the representation.|Ideally, everything needed to transition the resource state shall be part of the resource representation  including all the supported methods and what form they will leave the representation.
clips/audio_603.wav|We should enter a REST A P I with no prior knowledge beyond the initial URI a bookmark and a set of standardized media types appropriate for the intended audience i.e., expected to be understood by any client that might use the A P I.|We should enter a REST A P I with no prior knowledge beyond the initial URI a bookmark and a set of standardized media types appropriate for the intended audience i.e., expected to be understood by any client that might use the A P I.
clips/audio_604.wav|Failure here implies that out-of-band information is driving interaction instead of hypertext.|Failure here implies that out-of-band information is driving interaction instead of hypertext.
clips/audio_605.wav|Till the time, we are honoring the six guiding principles of REST, which we can call our interface  RESTful.|Till the time, we are honoring the six guiding principles of REST, which we can call our interface  RESTful.
clips/audio_606.wav|In simple words, in the REST architectural style, data and functionality are considered resources and are accessed usingUniform Resource IdentifiersURIs.|In simple words, in the REST architectural style, data and functionality are considered resources and are accessed usingUniform Resource IdentifiersURIs.
clips/audio_607.wav|Also, the resources have to be decoupled from their representation so that clients can access the content in various formats, such as H T M L, X M L, plain text, PDF, JPEG, Jay-son, and others.|Also, the resources have to be decoupled from their representation so that clients can access the content in various formats, such as H T M L, X M L, plain text, PDF, JPEG, Jay-son, and others.
clips/audio_608.wav|Metadata about the resource is made available and used to control caching, detect transmission errors, negotiate the appropriate representation format, and perform authentication or access control.|Metadata about the resource is made available and used to control caching, detect transmission errors, negotiate the appropriate representation format, and perform authentication or access control.
clips/audio_609.wav|Hugging Face, Inc|Hugging Face, Inc
clips/audio_610.wav|is an American company incorporated under the Delaware General Corporation Law1 and based in New York City that develops computation tools for building applications using machine learning|is an American company incorporated under the Delaware General Corporation Law1 and based in New York City that develops computation tools for building applications using machine learning
clips/audio_611.wav|It is most notable for its transformers library built for natural language processing applications and its platform that allows users to share machine learning models and datasets and showcase their work.|It is most notable for its transformers library built for natural language processing applications and its platform that allows users to share machine learning models and datasets and showcase their work.
clips/audio_612.wav|The company was founded in 2016 by French entrepreneurs Clment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.2 The company was named after the U1F917  HUGGING FACE emoji.2 After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.|The company was founded in 2016 by French entrepreneurs Clment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.2 The company was named after the U1F917  HUGGING FACE emoji.2 After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.
clips/audio_613.wav|In March 2021, Hugging Face raised US40 million in a Series B funding round.3|In March 2021, Hugging Face raised US40 million in a Series B funding round.3
clips/audio_614.wav|In December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.7|In December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.7
clips/audio_615.wav|On August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports Sass or on-premises deployment.9|On August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports Sass or on-premises deployment.9
clips/audio_616.wav|In February 2023, the company announced partnership with Amazon Web Services A W S which would allow Hugging Face's products available to A W S customers to use them as the building blocks for their custom applications|In February 2023, the company announced partnership with Amazon Web Services A W S which would allow Hugging Face's products available to A W S customers to use them as the building blocks for their custom applications
clips/audio_617.wav|The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by A W S.101112|The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by A W S.101112
clips/audio_618.wav|The program, based at STATION F in Paris, will run from September twenty twenty-four to February 2025|The program, based at STATION F in Paris, will run from September twenty twenty-four to February 2025
clips/audio_619.wav|On September 23, twenty twenty-four, to further the International Decade of Indigenous Languages, Hugging Face teamed up with Meta and UNESCO to launch a new online language translator 15 built on Meta's No Language Left Behind open-source AI model, enabling free text translation across two hundred languages, including many low-resource languages.16|On September 23, twenty twenty-four, to further the International Decade of Indigenous Languages, Hugging Face teamed up with Meta and UNESCO to launch a new online language translator 15 built on Meta's No Language Left Behind open-source AI model, enabling free text translation across two hundred languages, including many low-resource languages.16
clips/audio_620.wav|The Transformers library is a Python package that contains open-source implementations of transformer models for text, image, and audio tasks|The Transformers library is a Python package that contains open-source implementations of transformer models for text, image, and audio tasks
clips/audio_621.wav|It is compatible with the Pie-torch, Ten-sor-flow and JAX deep learning libraries and includes implementations of notable models like B E R T and G P T-2.17 The library was originally called "pytorch-pretrained-bert"18 which was then renamed to "pytorch-transformers" and finally "transformers."|It is compatible with the Pie-torch, Ten-sor-flow and JAX deep learning libraries and includes implementations of notable models like B E R T and G P T-2.17 The library was originally called "pytorch-pretrained-bert"18 which was then renamed to "pytorch-transformers" and finally "transformers."
clips/audio_622.wav|A javascript version transformers.js19 have also been developed, allowing to run models directly in the browser.|A javascript version transformers.js19 have also been developed, allowing to run models directly in the browser.
clips/audio_623.wav|The Hugging Face Hub is a platform centralized web service for hosting20|The Hugging Face Hub is a platform centralized web service for hosting20
clips/audio_624.wav|In addition to Transformers and the Hugging Face Hub, the Hugging Face ecosystem contains libraries for other tasks, such as dataset processing "data sets", model evaluation "Evaluate", and machine learning demos "Gradio".21|In addition to Transformers and the Hugging Face Hub, the Hugging Face ecosystem contains libraries for other tasks, such as dataset processing "data sets", model evaluation "Evaluate", and machine learning demos "Gradio".21
clips/audio_625.wav|The safetensors format was developed around 2021 to solve problems with the pickle format in python|The safetensors format was developed around 2021 to solve problems with the pickle format in python
clips/audio_626.wav|Compared to pickle format, it allows lazy loading, and avoids security problems.22 After a security audit, it became the default format in 2023.23|Compared to pickle format, it allows lazy loading, and avoids security problems.22 After a security audit, it became the default format in 2023.23
clips/audio_627.wav|The file format|The file format
clips/audio_628.wav|International Business Machines Corporation using the trademark IBM, nicknamed Big Blue,6 is an American multinational technology company headquartered in Armonk, New York and present in over 175 countries.78 IBM is the largest industrial research organization in the world, with 19 research facilities across a dozen countries, having held the record for most annual U.S|International Business Machines Corporation using the trademark IBM, nicknamed Big Blue,6 is an American multinational technology company headquartered in Armonk, New York and present in over 175 countries.78 IBM is the largest industrial research organization in the world, with 19 research facilities across a dozen countries, having held the record for most annual U.S
clips/audio_629.wav|During the 1960s and 1970s, the IBM mainframe, exemplified by the System360, was the world's dominant computing platform, with the company producing 80 percent of computers in the U.S|During the 1960s and 1970s, the IBM mainframe, exemplified by the System360, was the world's dominant computing platform, with the company producing 80 percent of computers in the U.S
clips/audio_630.wav|As one of the world's oldest and largest technology companies, IBM has been responsible for several technological innovations, including the automated teller machine ATM, dynamic random-access memory DRAM, the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, the S Q L programming language, and the UPC barcode|As one of the world's oldest and largest technology companies, IBM has been responsible for several technological innovations, including the automated teller machine ATM, dynamic random-access memory DRAM, the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, the S Q L programming language, and the UPC barcode
clips/audio_631.wav|Pitrap patented the computing scale in 188516 Alexander Dey invented the dial recorder 188817 Herman Hollerith patented the Electric Tabulating Machine 188918 and Willard Bundy invented a time clock to record workers' arrival and departure times on a paper tape 1889.19 On June 16, 1911, their four companies were amalgamated in New York State by Charles Ranlett Flint forming a fifth company, the Computing-Tabulating-Recording Company CTR based in Endicott, New York.120 The five companies had 1,300 employees and offices and plants in Endicott and Binghamton, New York Dayton, Ohio Detroit, Michigan Washington, D.C. and Toronto, Canada.21|Pitrap patented the computing scale in 188516 Alexander Dey invented the dial recorder 188817 Herman Hollerith patented the Electric Tabulating Machine 188918 and Willard Bundy invented a time clock to record workers' arrival and departure times on a paper tape 1889.19 On June 16, 1911, their four companies were amalgamated in New York State by Charles Ranlett Flint forming a fifth company, the Computing-Tabulating-Recording Company CTR based in Endicott, New York.120 The five companies had 1,300 employees and offices and plants in Endicott and Binghamton, New York Dayton, Ohio Detroit, Michigan Washington, D.C. and Toronto, Canada.21
clips/audio_632.wav|Watson, Sr., fired from the National Cash Register Company by John Henry Patterson, called on Flint and, in 1914, was offered a position at CTR.22 Watson joined CTR as general manager and then, 11 months later, was made President when antitrust cases relating to his time at NCR were resolved.23 Having learned Patterson's pioneering business practices, Watson proceeded to put the stamp of NCR onto CTR's companies.24 He implemented sales conventions, "generous sales incentives, a focus on customer service, an insistence on well-groomed, dark-suited salesmen and had an evangelical fervor for instilling company pride and loyalty in every worker".2526 His favorite slogan, "THINK", became a mantra for each company's employees.25 During Watson's first four years, revenues reached 9million 158million today and the company's operations expanded to Europe, South America, Asia and Australia.25 Watson never liked the clumsy hyphenated name "Computing-Tabulating-Recording Company" and chose to replace it with the more expansive title "International Business Machines" which had previously been used as the name of CTR's Canadian Division27 the name was changed on February 14, 1924.28 By 1933, most of the subsidiaries had been merged into one company, IBM.29|Watson, Sr., fired from the National Cash Register Company by John Henry Patterson, called on Flint and, in 1914, was offered a position at CTR.22 Watson joined CTR as general manager and then, 11 months later, was made President when antitrust cases relating to his time at NCR were resolved.23 Having learned Patterson's pioneering business practices, Watson proceeded to put the stamp of NCR onto CTR's companies.24 He implemented sales conventions, "generous sales incentives, a focus on customer service, an insistence on well-groomed, dark-suited salesmen and had an evangelical fervor for instilling company pride and loyalty in every worker".2526 His favorite slogan, "THINK", became a mantra for each company's employees.25 During Watson's first four years, revenues reached 9million 158million today and the company's operations expanded to Europe, South America, Asia and Australia.25 Watson never liked the clumsy hyphenated name "Computing-Tabulating-Recording Company" and chose to replace it with the more expansive title "International Business Machines" which had previously been used as the name of CTR's Canadian Division27 the name was changed on February 14, 1924.28 By 1933, most of the subsidiaries had been merged into one company, IBM.29
clips/audio_633.wav|The Nazis made extensive use of Hollerith punch card and alphabetical accounting equipment and IBM's majority-owned German subsidiary, Deutsche Hollerith Maschinen GmbH Dehomag, supplied this equipment from the early 1930s|The Nazis made extensive use of Hollerith punch card and alphabetical accounting equipment and IBM's majority-owned German subsidiary, Deutsche Hollerith Maschinen GmbH Dehomag, supplied this equipment from the early 1930s
clips/audio_634.wav|This equipment was critical to Nazi efforts to categorize citizens of both Germany and other nations that fell under Nazi control through ongoing censuses|This equipment was critical to Nazi efforts to categorize citizens of both Germany and other nations that fell under Nazi control through ongoing censuses
clips/audio_635.wav|IBM built the Automatic Sequence Controlled Calculator, an electromechanical computer, during World War II|IBM built the Automatic Sequence Controlled Calculator, an electromechanical computer, during World War II
clips/audio_636.wav|IBM also developed and manufactured the Saturn V's Instrument Unit and Apollo spacecraft guidance computers.|IBM also developed and manufactured the Saturn V's Instrument Unit and Apollo spacecraft guidance computers.
clips/audio_637.wav|Together the 360 and 370 made the IBM mainframe the dominant mainframe computer and the dominant computing platform in the industry throughout this period and into the early 1980s|Together the 360 and 370 made the IBM mainframe the dominant mainframe computer and the dominant computing platform in the industry throughout this period and into the early 1980s
clips/audio_638.wav|They and the operating systems that ran on them such as OSVS1 and MVS, and the middleware built on top of those such as the CICS transaction processing monitor, had a near-monopoly-level market share and became the thing IBM was most known for during this period.32|They and the operating systems that ran on them such as OSVS1 and MVS, and the middleware built on top of those such as the CICS transaction processing monitor, had a near-monopoly-level market share and became the thing IBM was most known for during this period.32
clips/audio_639.wav|In 1969, the United States of America alleged that IBM violated the Sherman Antitrust Act by monopolizing or attempting to monopolize the general-purpose electronic digital computer system market, specifically computers designed primarily for business, and subsequently alleged that IBM violated the antitrust laws in IBM's actions directed against leasing companies and plug-compatible peripheral manufacturers|In 1969, the United States of America alleged that IBM violated the Sherman Antitrust Act by monopolizing or attempting to monopolize the general-purpose electronic digital computer system market, specifically computers designed primarily for business, and subsequently alleged that IBM violated the antitrust laws in IBM's actions directed against leasing companies and plug-compatible peripheral manufacturers
clips/audio_640.wav|Shortly after, IBM unbundled its software and services in what many observers believed was a direct result of the lawsuit, creating a competitive market for software|Shortly after, IBM unbundled its software and services in what many observers believed was a direct result of the lawsuit, creating a competitive market for software
clips/audio_641.wav|Also in 1969, IBM engineer Forrest Parry invented the magnetic stripe card that would become ubiquitous for creditdebitATM cards, driver's licenses, rapid transit cards and a multitude of other identity and access control applications|Also in 1969, IBM engineer Forrest Parry invented the magnetic stripe card that would become ubiquitous for creditdebitATM cards, driver's licenses, rapid transit cards and a multitude of other identity and access control applications
clips/audio_642.wav|In 1991 IBM began spinning off its many divisions into autonomous subsidiaries so-called "Baby Blues" in an attempt to make the company more manageable and to streamline IBM by having other investors finance those companies.3637 These included AdStar, dedicated to disk drives and other data storage products IBM Application Business Systems, dedicated to mid-range computers IBM Enterprise Systems, dedicated to mainframes Pennant Systems, dedicated to mid-range and large printers Lexmark, dedicated to small printers and more.38 Lexmark was acquired by Clayton  Dubilier in a leveraged buyout shortly after its formation.39|In 1991 IBM began spinning off its many divisions into autonomous subsidiaries so-called "Baby Blues" in an attempt to make the company more manageable and to streamline IBM by having other investors finance those companies.3637 These included AdStar, dedicated to disk drives and other data storage products IBM Application Business Systems, dedicated to mid-range computers IBM Enterprise Systems, dedicated to mainframes Pennant Systems, dedicated to mid-range and large printers Lexmark, dedicated to small printers and more.38 Lexmark was acquired by Clayton  Dubilier in a leveraged buyout shortly after its formation.39
clips/audio_643.wav|In September 1992, IBM completed the spin-off of their various non-mainframe and non-midrange, personal computer manufacturing divisions, combining them into an autonomous wholly owned subsidiary known as the IBM Personal Computer Company IBM PC Co..four oh four1 This corporate restructuring came after IBM reported a sharp drop in profit margins during the second quarter of fiscal year 1992 market analysts attributed the drop to a fierce price war in the personal computer market over the summer of 1992.42 The corporate restructuring was one of the largest and most expensive in history up to that point.43 By the summer of 1993, the IBM PC Co|In September 1992, IBM completed the spin-off of their various non-mainframe and non-midrange, personal computer manufacturing divisions, combining them into an autonomous wholly owned subsidiary known as the IBM Personal Computer Company IBM PC Co..four oh four1 This corporate restructuring came after IBM reported a sharp drop in profit margins during the second quarter of fiscal year 1992 market analysts attributed the drop to a fierce price war in the personal computer market over the summer of 1992.42 The corporate restructuring was one of the largest and most expensive in history up to that point.43 By the summer of 1993, the IBM PC Co
clips/audio_644.wav|had divided into multiple business units itself, including Ambra Computer Corporation and the IBM Power Personal Systems Group, the former an attempt to design and market "clone" computers of IBM's own architecture and the latter responsible for IBM's PowerPC-based workstations.4445|had divided into multiple business units itself, including Ambra Computer Corporation and the IBM Power Personal Systems Group, the former an attempt to design and market "clone" computers of IBM's own architecture and the latter responsible for IBM's PowerPC-based workstations.4445
clips/audio_645.wav|In 1993, IBM posted an 8billion loss  at the time the biggest in American corporate history.46 Lou Gerstner was hired as CEO from RJR Nabisco to turn the company around.47 In two hundred2 IBM acquired PwC Consulting, the consulting arm of PwC which was merged into its IBM Global Services.4849|In 1993, IBM posted an 8billion loss  at the time the biggest in American corporate history.46 Lou Gerstner was hired as CEO from RJR Nabisco to turn the company around.47 In two hundred2 IBM acquired PwC Consulting, the consulting arm of PwC which was merged into its IBM Global Services.4849
clips/audio_646.wav|On September 14, two hundred4, LG and IBM announced that their business alliance in the South Korean market would end at the end of that year|On September 14, two hundred4, LG and IBM announced that their business alliance in the South Korean market would end at the end of that year
clips/audio_647.wav|In two hundred5, the company sold all of its personal computer business to Chinese technology company Lenovo58 and, in two hundred9, it acquired software company SPSS Inc|In two hundred5, the company sold all of its personal computer business to Chinese technology company Lenovo58 and, in two hundred9, it acquired software company SPSS Inc
clips/audio_648.wav|In 2012, IBM announced it had agreed to buy Kenexa and Texas Memory Systems,59 and a year later it also acquired SoftLayer Technologies, a web hosting service, in a deal worth around 2billion.60 Also that year, the company designed a video surveillance system for Davao City.61|In 2012, IBM announced it had agreed to buy Kenexa and Texas Memory Systems,59 and a year later it also acquired SoftLayer Technologies, a web hosting service, in a deal worth around 2billion.60 Also that year, the company designed a video surveillance system for Davao City.61
clips/audio_649.wav|In 2014 IBM announced it would sell its x86 server division to Lenovo for 2.1billion.62 while continuing to offer Power ISA-based servers.63 Also that year, IBM began announcing several major partnerships with other companies, including Apple Inc.,6465 Twitter,66 Facebook,67 Tencent,68 Cisco,69 UnderArmour,70 Box,71 Microsoft,72 VMware,73 CSC,74 Macy's,75 Sesame Workshop,76 the parent company of Sesame Street, and Salesforce.com.77|In 2014 IBM announced it would sell its x86 server division to Lenovo for 2.1billion.62 while continuing to offer Power ISA-based servers.63 Also that year, IBM began announcing several major partnerships with other companies, including Apple Inc.,6465 Twitter,66 Facebook,67 Tencent,68 Cisco,69 UnderArmour,70 Box,71 Microsoft,72 VMware,73 CSC,74 Macy's,75 Sesame Workshop,76 the parent company of Sesame Street, and Salesforce.com.77
clips/audio_650.wav|In 2015, IBM announced three major acquisitions Merge Healthcare for 1 billion,79 data storage vendor Cleversafe, and all digital assets from The Weather Company, including Weather.com and the Weather Channel mobile app.8081 Also that year, IBM employees created the film A Boy and His Atom, which was the first molecule movie to tell a story|In 2015, IBM announced three major acquisitions Merge Healthcare for 1 billion,79 data storage vendor Cleversafe, and all digital assets from The Weather Company, including Weather.com and the Weather Channel mobile app.8081 Also that year, IBM employees created the film A Boy and His Atom, which was the first molecule movie to tell a story
clips/audio_651.wav|In 2016, IBM acquired video conferencing service Ustream and formed a new cloud video unit.8283 In April 2016, it posted a 14-year low in quarterly sales.84 The following month, Groupon sued IBM accusing it of patent infringement, two months after IBM accused Groupon of patent infringement in a separate lawsuit.85|In 2016, IBM acquired video conferencing service Ustream and formed a new cloud video unit.8283 In April 2016, it posted a 14-year low in quarterly sales.84 The following month, Groupon sued IBM accusing it of patent infringement, two months after IBM accused Groupon of patent infringement in a separate lawsuit.85
clips/audio_652.wav|In 2015, IBM bought the digital part of The Weather Company,86 Truven Health Analytics for 2.6billion in 2016, and in October 2018, IBM announced its intention to acquire Red Hat for 34billion,878889 which was completed on July 9, 2019.90|In 2015, IBM bought the digital part of The Weather Company,86 Truven Health Analytics for 2.6billion in 2016, and in October 2018, IBM announced its intention to acquire Red Hat for 34billion,878889 which was completed on July 9, 2019.90
clips/audio_653.wav|In 2021, IBM announced the acquisition of the enterprise software company Turbonomic for 1.5billion.101 In January 2022, IBM announced it would sell Watson Health to private equity firm Francisco Partners.102|In 2021, IBM announced the acquisition of the enterprise software company Turbonomic for 1.5billion.101 In January 2022, IBM announced it would sell Watson Health to private equity firm Francisco Partners.102
clips/audio_654.wav|In late 2022, IBM started a collaboration with new Japanese manufacturer Rapidus,105 which led GlobalFoundries to file a lawsuit against IBM the following year.106|In late 2022, IBM started a collaboration with new Japanese manufacturer Rapidus,105 which led GlobalFoundries to file a lawsuit against IBM the following year.106
clips/audio_655.wav|In 2023, IBM acquired Manta Software Inc|In 2023, IBM acquired Manta Software Inc
clips/audio_656.wav|governance capabilities for an undisclosed amount.107 On November 16, 2023, IBM suspended ads on Twitter after ads were found next to pro-Nazi content.108109|governance capabilities for an undisclosed amount.107 On November 16, 2023, IBM suspended ads on Twitter after ads were found next to pro-Nazi content.108109
clips/audio_657.wav|In December 2023, IBM announced it would acquire Software AG's StreamSets and webMethods platforms for 2.13 billion 2.33 billion.110|In December 2023, IBM announced it would acquire Software AG's StreamSets and webMethods platforms for 2.13 billion 2.33 billion.110
clips/audio_658.wav|Due to a lack of foresight by IBM,111112 the PC was not well protected by intellectual property laws|Due to a lack of foresight by IBM,111112 the PC was not well protected by intellectual property laws
clips/audio_659.wav|As a consequence, IBM quickly began losing its market dominance to emerging competitors in the PC market|As a consequence, IBM quickly began losing its market dominance to emerging competitors in the PC market
clips/audio_660.wav|Continuing a trend started in the 1990s of downsizing its operations and divesting from commodity production, IBM sold its personal computer division to the Lenovo Group in two hundred5.|Continuing a trend started in the 1990s of downsizing its operations and divesting from commodity production, IBM sold its personal computer division to the Lenovo Group in two hundred5.
clips/audio_661.wav|IBM's market capitalization was valued at over 153billion as of May twenty twenty-four.113 Despite its relative decline within the technology sector,114 IBM remains the seventh largest technology company by revenue, and 67th largest overall company by revenue in the United States|IBM's market capitalization was valued at over 153billion as of May twenty twenty-four.113 Despite its relative decline within the technology sector,114 IBM remains the seventh largest technology company by revenue, and 67th largest overall company by revenue in the United States
clips/audio_662.wav|The key trends of IBM are as at the financial year ending December 31119120|The key trends of IBM are as at the financial year ending December 31119120
clips/audio_663.wav|The company's 15-member board of directors are responsible for overall corporate management and includes the current or former CEOs of Anthem, Dow Chemical, Johnson and Johnson, Royal Dutch Shell, UPS, and Vanguard as well as the president of Cornell University and a retired U.S|The company's 15-member board of directors are responsible for overall corporate management and includes the current or former CEOs of Anthem, Dow Chemical, Johnson and Johnson, Royal Dutch Shell, UPS, and Vanguard as well as the president of Cornell University and a retired U.S
clips/audio_664.wav|IBM is headquartered in Armonk, New York, a community 37 miles 60km north of Midtown Manhattan.125 A nickname for the company is the "Colossus of Armonk".126 Its principal building, referred to as CHQ, is a 283,000-square-foot 26,300m2 glass and stone edifice on a 25-acre 10ha parcel amid a 432-acre former apple orchard the company purchased in the mid-1950s.127 There are two other IBM buildings within walking distance of CHQ the North Castle office, which previously served as IBM's headquarters and the Louis V|IBM is headquartered in Armonk, New York, a community 37 miles 60km north of Midtown Manhattan.125 A nickname for the company is the "Colossus of Armonk".126 Its principal building, referred to as CHQ, is a 283,000-square-foot 26,300m2 glass and stone edifice on a 25-acre 10ha parcel amid a 432-acre former apple orchard the company purchased in the mid-1950s.127 There are two other IBM buildings within walking distance of CHQ the North Castle office, which previously served as IBM's headquarters and the Louis V
clips/audio_665.wav|Gerstner, Jr., Center for Learning128 formerly known as IBM Learning Center ILC, a resort hotel and training center, which has 182 guest rooms, 31 meeting rooms, and various amenities.129|Gerstner, Jr., Center for Learning128 formerly known as IBM Learning Center ILC, a resort hotel and training center, which has 182 guest rooms, 31 meeting rooms, and various amenities.129
clips/audio_666.wav|In Beijing, China, IBM occupies Pangu Plaza,130 the city's seventh tallest building and overlooking Beijing National Stadium "Bird's Nest", home to the two hundred8 Summer Olympics.|In Beijing, China, IBM occupies Pangu Plaza,130 the city's seventh tallest building and overlooking Beijing National Stadium "Bird's Nest", home to the two hundred8 Summer Olympics.
clips/audio_667.wav|It has facilities in Coimbatore, Chennai, Kochi, Ahmedabad, Delhi, Kolkata, Mumbai, Pune, Gurugram, Noida, Bhubaneshwar, Surat, Visakhapatnam, Hyderabad, Bangalore and Jamshedpur.|It has facilities in Coimbatore, Chennai, Kochi, Ahmedabad, Delhi, Kolkata, Mumbai, Pune, Gurugram, Noida, Bhubaneshwar, Surat, Visakhapatnam, Hyderabad, Bangalore and Jamshedpur.
clips/audio_668.wav|Other notable buildings include the IBM Rome Software Lab Rome, Italy, Hursley House Winchester, UK, 330 North Wabash Chicago, Illinois, United States, the Cambridge Scientific Center Cambridge, MassachuseT T S, United States, the IBM Toronto Software Lab Toronto, Canada, the IBM Building, Johannesburg Johannesburg, South Africa, the IBM Building Seattle Seattle, Washington, United States, the IBM Hakozaki Facility Tokyo, Japan, the IBM Yamato Facility Yamato, Japan, the IBM Canada Head Office Building Ontario, Canada and the Watson I O T Headquarters131 Munich, Germany|Other notable buildings include the IBM Rome Software Lab Rome, Italy, Hursley House Winchester, UK, 330 North Wabash Chicago, Illinois, United States, the Cambridge Scientific Center Cambridge, MassachuseT T S, United States, the IBM Toronto Software Lab Toronto, Canada, the IBM Building, Johannesburg Johannesburg, South Africa, the IBM Building Seattle Seattle, Washington, United States, the IBM Hakozaki Facility Tokyo, Japan, the IBM Yamato Facility Yamato, Japan, the IBM Canada Head Office Building Ontario, Canada and the Watson I O T Headquarters131 Munich, Germany
clips/audio_669.wav|Van der Rohe's building in Chicago was recognized with the 1990 Honor Award from the National Building Museum.132|Van der Rohe's building in Chicago was recognized with the 1990 Honor Award from the National Building Museum.132
clips/audio_670.wav|As of 2016update, these offerings fall into the categories of cloud computing, artificial intelligence, commerce, data and analytics, Internet of things I O T,133 IT infrastructure, mobile, digital workplace134 and cybersecurity.135|As of 2016update, these offerings fall into the categories of cloud computing, artificial intelligence, commerce, data and analytics, Internet of things I O T,133 IT infrastructure, mobile, digital workplace134 and cybersecurity.135
clips/audio_671.wav|In 1990, IBM released the Power microprocessors, which were designed into many console gaming systems, including Xbox 360,136 PlayStation 3, and Nintendo's Wii U.137138 IBM Secure Blue is encryption hardware that can be built into microprocessors,139 and in 2014, the company revealed TrueNorth, a neuromorphic CMOS integrated circuit and announced a 3billion investment over the following five years to design a neural chip that mimics the human brain, with 10billion neurons and 100trillion synapses, but that uses just 1 kilowatt of power.140 In 2016, the company launched all-flash arrays designed for small and midsized companies, which includes software for data compression, provisioning, and snapshots across various systems.141|In 1990, IBM released the Power microprocessors, which were designed into many console gaming systems, including Xbox 360,136 PlayStation 3, and Nintendo's Wii U.137138 IBM Secure Blue is encryption hardware that can be built into microprocessors,139 and in 2014, the company revealed TrueNorth, a neuromorphic CMOS integrated circuit and announced a 3billion investment over the following five years to design a neural chip that mimics the human brain, with 10billion neurons and 100trillion synapses, but that uses just 1 kilowatt of power.140 In 2016, the company launched all-flash arrays designed for small and midsized companies, which includes software for data compression, provisioning, and snapshots across various systems.141
clips/audio_672.wav|IBM Cloud includes infrastructure as a service E-ass, software as a service Sass and platform as a service Pass offered through public, private and hybrid cloud delivery models|IBM Cloud includes infrastructure as a service E-ass, software as a service Sass and platform as a service Pass offered through public, private and hybrid cloud delivery models
clips/audio_673.wav|For instance, the IBM Bluemix Pass enables developers to quickly create complex websites on a pay-as-you-go model|For instance, the IBM Bluemix Pass enables developers to quickly create complex websites on a pay-as-you-go model
clips/audio_674.wav|In May 2022, IBM announced the company had signed a multi-year Strategic Collaboration Agreement with Amazon Web Services to make a wide variety of IBM software available as a service on A W S Marketplace|In May 2022, IBM announced the company had signed a multi-year Strategic Collaboration Agreement with Amazon Web Services to make a wide variety of IBM software available as a service on A W S Marketplace
clips/audio_675.wav|Additionally, the deal includes both companies making joint investments that make it easier for companies to consume IBM's offering and integrate them with A W S, including developer training and software development for select markets.146|Additionally, the deal includes both companies making joint investments that make it easier for companies to consume IBM's offering and integrate them with A W S, including developer training and software development for select markets.146
clips/audio_676.wav|IBM Watson is a technology platform that uses natural language processing and machine learning to reveal insights from large amounts of unstructured data.147 Watson was debuted in 2011 on the American game show Jeopardy!, where it competed against champions Ken Jennings and Brad Rutter in a three-game tournament and won|IBM Watson is a technology platform that uses natural language processing and machine learning to reveal insights from large amounts of unstructured data.147 Watson was debuted in 2011 on the American game show Jeopardy!, where it competed against champions Ken Jennings and Brad Rutter in a three-game tournament and won
clips/audio_677.wav|IBM also provides infrastructure for the New York City Police Department through their IBM Cognos Analytics to perform data visualizations of CompStat crime data.151|IBM also provides infrastructure for the New York City Police Department through their IBM Cognos Analytics to perform data visualizations of CompStat crime data.151
clips/audio_678.wav|In March 2020, it was announced that IBM will build the first quantum computer in Ehningen, Germany|In March 2020, it was announced that IBM will build the first quantum computer in Ehningen, Germany
clips/audio_679.wav|Watsonx has multiple services for training and fine tuning models based on confidential data.156 A year later, IBM open-sourced Granite code models and put them on Hugging Face for public use.157|Watsonx has multiple services for training and fine tuning models based on confidential data.156 A year later, IBM open-sourced Granite code models and put them on Hugging Face for public use.157
clips/audio_680.wav|Research has been part of IBM since its founding, and its organized efforts trace their roots back to 1945, when the Watson Scientific Computing Laboratory was founded at Columbia University in New York City, converting a renovated fraternity house on Manhattan's West Side into IBM's first laboratory|Research has been part of IBM since its founding, and its organized efforts trace their roots back to 1945, when the Watson Scientific Computing Laboratory was founded at Columbia University in New York City, converting a renovated fraternity house on Manhattan's West Side into IBM's first laboratory
clips/audio_681.wav|Now, IBM Research constitutes the largest industrial research organization in the world, with 12 labs on 6 continents.160 IBM Research is headquartered at the Thomas J|Now, IBM Research constitutes the largest industrial research organization in the world, with 12 labs on 6 continents.160 IBM Research is headquartered at the Thomas J
clips/audio_682.wav|IBM has been a leading proponent of the Open Source Initiative, and began supporting Li-nux in 1998.163 The company invests billions of dollars in services and software based on Li-nux through the IBM Li-nux Technology Center, which includes over 300 Li-nux kernel developers.164 IBM has also released code under different open-source licenses, such as the platform-independent software framework Eclipse worth approximately 40million at the time of the donation,165 the three-sentence International Components for Unicode ICU license, and the Java-based relational database management system RDBMS Apache Derby|IBM has been a leading proponent of the Open Source Initiative, and began supporting Li-nux in 1998.163 The company invests billions of dollars in services and software based on Li-nux through the IBM Li-nux Technology Center, which includes over 300 Li-nux kernel developers.164 IBM has also released code under different open-source licenses, such as the platform-independent software framework Eclipse worth approximately 40million at the time of the donation,165 the three-sentence International Components for Unicode ICU license, and the Java-based relational database management system RDBMS Apache Derby
clips/audio_683.wav|Famous inventions and developments by IBM include the automated teller machine ATM, dynamic random access memory DRAM, the electronic keypunch, the financial swap, the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, RISC, the SABRE airline reservation system, S Q L, the Universal Product Code UPC bar code, and the virtual machine|Famous inventions and developments by IBM include the automated teller machine ATM, dynamic random access memory DRAM, the electronic keypunch, the financial swap, the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, RISC, the SABRE airline reservation system, S Q L, the Universal Product Code UPC bar code, and the virtual machine
clips/audio_684.wav|Additionally, in 1990 company scientists used a scanning tunneling microscope to arrange 35 individual xenon atoms to spell out the company acronym, marking the first structure assembled one atom at a time.166 A major part of IBM research is the generation of patents|Additionally, in 1990 company scientists used a scanning tunneling microscope to arrange 35 individual xenon atoms to spell out the company acronym, marking the first structure assembled one atom at a time.166 A major part of IBM research is the generation of patents
clips/audio_685.wav|IBM is nicknamed Big Blue partly due to its blue logo and color scheme,174175 and also in reference to its former de facto dress code of white shirts with blue suits.174176 The company logo has undergone several changes over the years, with its current "8-bar" logo designed in 1972 by graphic designer Paul Rand.177 It was a general replacement for a 13-bar logo, since period photocopiers did not render narrow as opposed to tall stripes well|IBM is nicknamed Big Blue partly due to its blue logo and color scheme,174175 and also in reference to its former de facto dress code of white shirts with blue suits.174176 The company logo has undergone several changes over the years, with its current "8-bar" logo designed in 1972 by graphic designer Paul Rand.177 It was a general replacement for a 13-bar logo, since period photocopiers did not render narrow as opposed to tall stripes well
clips/audio_686.wav|Since 1996, IBM has been the exclusive technology partner for the Masters Tournament, one of the four major championships in professional golf, with IBM creating the first Masters.org 1996, the first course cam 1998, the first iPhone app with live streaming two hundred9, and first-ever live 4K Ultra High Definition feed in the United States for a major sporting event 2016.178 As a result, IBM CEO Ginni Rometty became the third female member of the Master's governing body, the Augusta National Golf Club.179 IBM is also a major sponsor in professional tennis, with engagements at the U.S|Since 1996, IBM has been the exclusive technology partner for the Masters Tournament, one of the four major championships in professional golf, with IBM creating the first Masters.org 1996, the first course cam 1998, the first iPhone app with live streaming two hundred9, and first-ever live 4K Ultra High Definition feed in the United States for a major sporting event 2016.178 As a result, IBM CEO Ginni Rometty became the third female member of the Master's governing body, the Augusta National Golf Club.179 IBM is also a major sponsor in professional tennis, with engagements at the U.S
clips/audio_687.wav|Open, Wimbledon, the Australian Open, and the French Open.180 The company also sponsored the Olympic Games from 1960 to two hundred0,181 and the National Football League from two hundred3 to 2012.182 In Japan, IBM employees also have an American football team complete with pro stadium, cheerleaders and televised games, competing in the Japanese X-League as the "Big Blue".183|Open, Wimbledon, the Australian Open, and the French Open.180 The company also sponsored the Olympic Games from 1960 to two hundred0,181 and the National Football League from two hundred3 to 2012.182 In Japan, IBM employees also have an American football team complete with pro stadium, cheerleaders and televised games, competing in the Japanese X-League as the "Big Blue".183
clips/audio_688.wav|In two hundred4, concerns were raised related to IBM's contribution in its early days to pollution in its original location in Endicott, New York.184185 IBM reported its total CO2e emissions direct and indirect for the twelve months ending December 31, 2020 at 621 kilotons -324 -34.3 year-on-year.186 In February 2021, IBM committed to achieve net zero greenhouse gas emissions by the year 2030.187|In two hundred4, concerns were raised related to IBM's contribution in its early days to pollution in its original location in Endicott, New York.184185 IBM reported its total CO2e emissions direct and indirect for the twelve months ending December 31, 2020 at 621 kilotons -324 -34.3 year-on-year.186 In February 2021, IBM committed to achieve net zero greenhouse gas emissions by the year 2030.187
clips/audio_689.wav|In business, former IBM employees include Apple Inc|In business, former IBM employees include Apple Inc
clips/audio_690.wav|CEO Tim Cook,190 former EDS CEO and politician Ross Perot, Microsoft chairman John W|CEO Tim Cook,190 former EDS CEO and politician Ross Perot, Microsoft chairman John W
clips/audio_691.wav|Thompson, SAP co-founder Hasso Plattner, Gartner founder Gideon Gartner, Advanced Micro Devices AMD CEO Lisa Su,191 Cadence Design Systems CEO Anirudh Devgan,192 former Citizens Financial Group CEO Ellen Alemany, former Yahoo! chairman Alfred Amoroso, former ATT CEO C|Thompson, SAP co-founder Hasso Plattner, Gartner founder Gideon Gartner, Advanced Micro Devices AMD CEO Lisa Su,191 Cadence Design Systems CEO Anirudh Devgan,192 former Citizens Financial Group CEO Ellen Alemany, former Yahoo! chairman Alfred Amoroso, former ATT CEO C
clips/audio_692.wav|Michael Armstrong, former Xerox Corporation CEOs David T|Michael Armstrong, former Xerox Corporation CEOs David T
clips/audio_693.wav|Richard Thoman,193 former Fair Isaac Corporation CEO Mark N|Richard Thoman,193 former Fair Isaac Corporation CEO Mark N
clips/audio_694.wav|Greene,194 Citrix Systems co-founder Ed Iacobucci, ASOS.com chairman Brian McBride, former Lenovo CEO Steve Ward, and former Teradata CEO Kenneth Simonds.|Greene,194 Citrix Systems co-founder Ed Iacobucci, ASOS.com chairman Brian McBride, former Lenovo CEO Steve Ward, and former Teradata CEO Kenneth Simonds.
clips/audio_695.wav|In government, Patricia Roberts Harris served as United States Secretary of Housing and Urban Development, the first African American woman to serve in the United States Cabinet.195 Samuel K|In government, Patricia Roberts Harris served as United States Secretary of Housing and Urban Development, the first African American woman to serve in the United States Cabinet.195 Samuel K
clips/audio_696.wav|Senators Mack Mattingly and Thom Tillis Wisconsin governor Scott Walker196 former U.S|Senators Mack Mattingly and Thom Tillis Wisconsin governor Scott Walker196 former U.S
clips/audio_697.wav|Ambassadors Vincent Obsitnik Slovakia, Arthur K|Ambassadors Vincent Obsitnik Slovakia, Arthur K
clips/audio_698.wav|Soviet Union and former U.S|Soviet Union and former U.S
clips/audio_699.wav|Representatives Todd Akin,197 Glenn Andrews, Robert Garcia, Katherine Harris,198 Amo Houghton, Jim Ross Lightfoot, Thomas J|Representatives Todd Akin,197 Glenn Andrews, Robert Garcia, Katherine Harris,198 Amo Houghton, Jim Ross Lightfoot, Thomas J
clips/audio_700.wav|Other former IBM employees include NASA astronaut Michael J|Other former IBM employees include NASA astronaut Michael J
clips/audio_701.wav|Massimino, Canadian astronaut and former Governor General Julie Payette, noted musician Dave Matthews,199 Harvey Mudd College president Maria Klawe, Western Governors University president emeritus Robert Mendenhall, former University of Kentucky president Lee T|Massimino, Canadian astronaut and former Governor General Julie Payette, noted musician Dave Matthews,199 Harvey Mudd College president Maria Klawe, Western Governors University president emeritus Robert Mendenhall, former University of Kentucky president Lee T
clips/audio_702.wav|Todd Jr., former University of Iowa president Bruce Harreld, NFL referee Bill Carollo,two hundred former Rangers F.C|Todd Jr., former University of Iowa president Bruce Harreld, NFL referee Bill Carollo,two hundred former Rangers F.C
clips/audio_703.wav|In its early days, a dark or gray suit, white shirt, and a "sincere" tie constituted the public uniform for IBM employees.203 During IBM's management transformation in the 1990s, CEO Louis V|In its early days, a dark or gray suit, white shirt, and a "sincere" tie constituted the public uniform for IBM employees.203 During IBM's management transformation in the 1990s, CEO Louis V
clips/audio_704.wav|relaxed these codes, normalizing the dress and behavior of IBM employees.204 The company's culture has also given to different plays on the company acronym IBM, with some saying it stands for "I've Been Moved" due to relocations and layoffs,205 others saying it stands for "I'm By Myself" pursuant to a prevalent work-from-anywhere norm,206 and others saying it stands for "I'm Being Mentored" due to the company's open door policy and encouragement for mentoring at all levels.207|relaxed these codes, normalizing the dress and behavior of IBM employees.204 The company's culture has also given to different plays on the company acronym IBM, with some saying it stands for "I've Been Moved" due to relocations and layoffs,205 others saying it stands for "I'm By Myself" pursuant to a prevalent work-from-anywhere norm,206 and others saying it stands for "I'm Being Mentored" due to the company's open door policy and encouragement for mentoring at all levels.207
clips/audio_705.wav|The company has traditionally resisted labor union organizing,208 although unions represent some IBM workers outside the United States.209|The company has traditionally resisted labor union organizing,208 although unions represent some IBM workers outside the United States.209
clips/audio_706.wav|Text-to-Speech converts text or Speech Synthesis Markup Language SSML input into audio data of natural human speech. Learn more|Text-to-Speech converts text or Speech Synthesis Markup Language SSML input into audio data of natural human speech. Learn more
clips/audio_707.wav|Quickstart Use the command line|Quickstart Use the command line
clips/audio_708.wav|Quickstart Use the client libraries|Quickstart Use the client libraries
clips/audio_709.wav|Specify regional endpoints|Specify regional endpoints
clips/audio_710.wav|Speech Synthesis Markup Language SSML|Speech Synthesis Markup Language SSML
clips/audio_711.wav|Text-to-Speech Client Libraries|Text-to-Speech Client Libraries
clips/audio_712.wav|REST A P I|REST A P I
clips/audio_713.wav|RPC A P I|RPC A P I
clips/audio_714.wav|A dataset is a structured collection of data organized and stored together for analysis or processing|A dataset is a structured collection of data organized and stored together for analysis or processing
clips/audio_715.wav|The data within a dataset is typically related in some way and taken from a single source or intended for a single project|The data within a dataset is typically related in some way and taken from a single source or intended for a single project
clips/audio_716.wav|For example, a dataset might contain a collection of business data sales figures, customer contact information, transactions, etc.|For example, a dataset might contain a collection of business data sales figures, customer contact information, transactions, etc.
clips/audio_717.wav|A dataset can include many different types of data, from numerical values to text, images or audio recordings|A dataset can include many different types of data, from numerical values to text, images or audio recordings
clips/audio_718.wav|The data within a dataset can typically be accessed individually, in combination or managed as a whole entity.|The data within a dataset can typically be accessed individually, in combination or managed as a whole entity.
clips/audio_719.wav|data sets are a fundamental tool in data analytics, data analysis and machine learning ML, providing the data upon which analysts draw insights and trends|data sets are a fundamental tool in data analytics, data analysis and machine learning ML, providing the data upon which analysts draw insights and trends
clips/audio_720.wav|They are essential to ML because selecting the suitable dataset for an ML project is one of the most crucial initial steps of successfully training and deploying an ML model.|They are essential to ML because selecting the suitable dataset for an ML project is one of the most crucial initial steps of successfully training and deploying an ML model.
clips/audio_721.wav|Your complete how-to guide to putting machine learning to work  plus use cases, code samples and notebooks.|Your complete how-to guide to putting machine learning to work  plus use cases, code samples and notebooks.
clips/audio_722.wav|Learn about ETL pipelines with this OReilly technical guide.|Learn about ETL pipelines with this OReilly technical guide.
clips/audio_723.wav|There is some debate around the word dataset and whether it should be one or two words|There is some debate around the word dataset and whether it should be one or two words
clips/audio_724.wav|Merriam-Webster lists it as one word, but other sources, such as Dictionary.com, use data set|Merriam-Webster lists it as one word, but other sources, such as Dictionary.com, use data set
clips/audio_725.wav|Databricks preference is dataset.|Databricks preference is dataset.
clips/audio_726.wav|Theres also often confusion between the terms dataset and database|Theres also often confusion between the terms dataset and database
clips/audio_727.wav|While a database and a dataset are both related terms used to describe the organization and management of data, they differ in several meaningful ways|While a database and a dataset are both related terms used to describe the organization and management of data, they differ in several meaningful ways
clips/audio_728.wav|As defined in the first section, a dataset is a collection of data used for analysis and modeling and typically organized in a structured format|As defined in the first section, a dataset is a collection of data used for analysis and modeling and typically organized in a structured format
clips/audio_729.wav|That structured format could be an Excel spreadsheet, a CSV file, a Jay-son file or other formats|That structured format could be an Excel spreadsheet, a CSV file, a Jay-son file or other formats
clips/audio_730.wav|The data in a dataset can be organized in multiple ways and created from a wide variety of sources, such as a customer poll, an experiment or an existing database|The data in a dataset can be organized in multiple ways and created from a wide variety of sources, such as a customer poll, an experiment or an existing database
clips/audio_731.wav|A dataset can be used for many purposes, including training and testing machine learning models, data visualization, research or statistical analysis|A dataset can be used for many purposes, including training and testing machine learning models, data visualization, research or statistical analysis
clips/audio_732.wav|data sets can be shared publicly or privately|data sets can be shared publicly or privately
clips/audio_733.wav|A dataset is typically smaller in size compared to a database.|A dataset is typically smaller in size compared to a database.
clips/audio_734.wav|A database is designed for long-term storage and management of large amounts of organized data that is stored electronically, allowing the data to be easily accessed, manipulated and updated|A database is designed for long-term storage and management of large amounts of organized data that is stored electronically, allowing the data to be easily accessed, manipulated and updated
clips/audio_735.wav|In other words, a database is an organized collection of data stored as multiple datasets|In other words, a database is an organized collection of data stored as multiple datasets
clips/audio_736.wav|A dataset could include numbers, text, images, audio recordings or even basic descriptions of objects|A dataset could include numbers, text, images, audio recordings or even basic descriptions of objects
clips/audio_737.wav|A dataset can be organized in various forms including tables and files|A dataset can be organized in various forms including tables and files
clips/audio_738.wav|A few examples of datasets include|A few examples of datasets include
clips/audio_739.wav|Public datasets are public data organized around a theme or topic that are accessible to the public|Public datasets are public data organized around a theme or topic that are accessible to the public
clips/audio_740.wav|Public datasets are especially valuable to data scientists because they are generally free and provide easily accessible and downloadable data they can use to train ML models.|Public datasets are especially valuable to data scientists because they are generally free and provide easily accessible and downloadable data they can use to train ML models.
clips/audio_741.wav|General Services Administration offers Data.gov, which includes more than two hundred,000 datasets and hundreds of categories.|General Services Administration offers Data.gov, which includes more than two hundred,000 datasets and hundreds of categories.
clips/audio_742.wav|Databricks also provides a variety of sample datasets made available by third parties that can be used in the Databricks Workspace|Databricks also provides a variety of sample datasets made available by third parties that can be used in the Databricks Workspace
clips/audio_743.wav|Using such datasets in coordination with AI and Machine Learning on Databricks empowers ML teams to prepare and process data, streamlines cross-team collaboration and standardizes the full ML lifecycle from experimentation to production, including for generative AI and large language models.|Using such datasets in coordination with AI and Machine Learning on Databricks empowers ML teams to prepare and process data, streamlines cross-team collaboration and standardizes the full ML lifecycle from experimentation to production, including for generative AI and large language models.
clips/audio_744.wav|There are several different ways to use datasets|There are several different ways to use datasets
clips/audio_745.wav|Data scientists use datasets to train ML models|Data scientists use datasets to train ML models
clips/audio_746.wav|However, before datasets can be used, data needs to be ingested into a data lake or a lakehouse using data engineering processes like Extract, Transform and Load ETL|However, before datasets can be used, data needs to be ingested into a data lake or a lakehouse using data engineering processes like Extract, Transform and Load ETL
clips/audio_747.wav|ETL enables engineers to extract data from different sources, transform the data into a usable and trusted resource, and load the data into the systems end users can access and use to solve business problems.|ETL enables engineers to extract data from different sources, transform the data into a usable and trusted resource, and load the data into the systems end users can access and use to solve business problems.
clips/audio_748.wav|Before datasets can be used, they must be cataloged, governed and securely stored with a governance system|Before datasets can be used, they must be cataloged, governed and securely stored with a governance system
clips/audio_749.wav|Implementing an effective data governance strategy allows organizations to make data readily available for data-driven decision-making while safeguarding data from unauthorized access and ensuring compliance with regulatory requirements.|Implementing an effective data governance strategy allows organizations to make data readily available for data-driven decision-making while safeguarding data from unauthorized access and ensuring compliance with regulatory requirements.
clips/audio_750.wav|With Unity Catalog, organizations can seamlessly govern structured and unstructured data, machine learning models, notebooks, dashboards and files on any cloud or platform|With Unity Catalog, organizations can seamlessly govern structured and unstructured data, machine learning models, notebooks, dashboards and files on any cloud or platform
clips/audio_751.wav|Most data scientists not only want to collect and analyze datasets, they also want to share them|Most data scientists not only want to collect and analyze datasets, they also want to share them
clips/audio_752.wav|Delta Sharing is an open source tool integrated within Unity Catalog that enables data scientists and analysts to easily share data and AI assets across clouds, regions and platforms to unlock new revenue streams and drive business value without relying on proprietary formats, complex ETL processes or costly data replication.|Delta Sharing is an open source tool integrated within Unity Catalog that enables data scientists and analysts to easily share data and AI assets across clouds, regions and platforms to unlock new revenue streams and drive business value without relying on proprietary formats, complex ETL processes or costly data replication.
clips/audio_753.wav|data augmentation is a statistical technique which allows maximum likelihood estimation from incomplete data.12 data augmentation has important applications in Bayesian analysis,3 and the technique is widely used in machine learning to reduce overfitting when training machine learning models,4 achieved by training models on several slightly-modified copies of existing data.|data augmentation is a statistical technique which allows maximum likelihood estimation from incomplete data.12 data augmentation has important applications in Bayesian analysis,3 and the technique is widely used in machine learning to reduce overfitting when training machine learning models,4 achieved by training models on several slightly-modified copies of existing data.
clips/audio_754.wav|Synthetic Minority Over-sampling Technique SMOTE is a method used to address imbalanced datasets in machine learning|Synthetic Minority Over-sampling Technique SMOTE is a method used to address imbalanced datasets in machine learning
clips/audio_755.wav|In such datasets, the number of samples in different classes varies significantly, leading to biased model performance|In such datasets, the number of samples in different classes varies significantly, leading to biased model performance
clips/audio_756.wav|For example, in a medical diagnosis dataset with 90 samples representing healthy individuals and only 10 samples representing individuals with a particular disease, traditional algorithms may struggle to accurately classify the minority class|For example, in a medical diagnosis dataset with 90 samples representing healthy individuals and only 10 samples representing individuals with a particular disease, traditional algorithms may struggle to accurately classify the minority class
clips/audio_757.wav|SMOTE rebalances the dataset by generating synthetic samples for the minority class|SMOTE rebalances the dataset by generating synthetic samples for the minority class
clips/audio_758.wav|This process helps increase the representation of the minority class, improving model performance.5|This process helps increase the representation of the minority class, improving model performance.5
clips/audio_759.wav|When convolutional neural networks grew larger in mid-1990s, there was a lack of data to use, especially considering that some part of the overall dataset should be spared for later testing|When convolutional neural networks grew larger in mid-1990s, there was a lack of data to use, especially considering that some part of the overall dataset should be spared for later testing
clips/audio_760.wav|It was proposed to perturb existing data with affine transformations to create new examples with the same labels,6 which were complemented by so-called elastic distortions in two hundred3,7 and the technique was widely used as of 2010s.8 data augmentation can enhance C N N performance and acts as a countermeasure against C N N profiling attacks.9|It was proposed to perturb existing data with affine transformations to create new examples with the same labels,6 which were complemented by so-called elastic distortions in two hundred3,7 and the technique was widely used as of 2010s.8 data augmentation can enhance C N N performance and acts as a countermeasure against C N N profiling attacks.9
clips/audio_761.wav|data augmentation has become fundamental in image classification, enriching training dataset diversity to improve model generalization and performance|data augmentation has become fundamental in image classification, enriching training dataset diversity to improve model generalization and performance
clips/audio_762.wav|The evolution of this practice has introduced a broad spectrum of techniques, including geometric transformations, color space adjustments, and noise injection.10|The evolution of this practice has introduced a broad spectrum of techniques, including geometric transformations, color space adjustments, and noise injection.10
clips/audio_763.wav|Geometric transformations alter the spatial properties of images to simulate different perspectives, orientations, and scales|Geometric transformations alter the spatial properties of images to simulate different perspectives, orientations, and scales
clips/audio_764.wav|Color space transformations modify the color properties of images, addressing variations in lighting, color saturation, and contrast|Color space transformations modify the color properties of images, addressing variations in lighting, color saturation, and contrast
clips/audio_765.wav|Synthetic data augmentation is of paramount importance for machine learning classification, particularly for biological data, which tend to be high dimensional and scarce|Synthetic data augmentation is of paramount importance for machine learning classification, particularly for biological data, which tend to be high dimensional and scarce
clips/audio_766.wav|noted that it is possible to use a generative adversarial network in particular, a DCG A N to perform style transfer in order to generate synthetic electromyographic signals that corresponded to those exhibited by sufferers of Parkinson's Disease.11|noted that it is possible to use a generative adversarial network in particular, a DCG A N to perform style transfer in order to generate synthetic electromyographic signals that corresponded to those exhibited by sufferers of Parkinson's Disease.11
clips/audio_767.wav|explored the idea of using deep convolutional neural networks for EEG-Based Emotion Recognition, results show that emotion recognition was improved when data augmentation was used.12|explored the idea of using deep convolutional neural networks for EEG-Based Emotion Recognition, results show that emotion recognition was improved when data augmentation was used.12
clips/audio_768.wav|Lotte13 proposed a method of "Artificial Trial Generation Based on Analogy" where three data examples|Lotte13 proposed a method of "Artificial Trial Generation Based on Analogy" where three data examples
clips/audio_770.wav|This approach was shown to improve performance of a Linear Discriminant Analysis classifier on three different datasets.|This approach was shown to improve performance of a Linear Discriminant Analysis classifier on three different datasets.
clips/audio_771.wav|For example, Freer14 observed that introducing noise into gathered data to form additional data points improved the learning ability of several models which otherwise performed relatively poorly|For example, Freer14 observed that introducing noise into gathered data to form additional data points improved the learning ability of several models which otherwise performed relatively poorly
clips/audio_772.wav|Tsinganos et al.15 studied the approaches of magnitude warping, wavelet decomposition, and synthetic surface EMG models generative approaches for hand gesture recognition, finding classification performance increases of up to 16 when augmented data was introduced during training|Tsinganos et al.15 studied the approaches of magnitude warping, wavelet decomposition, and synthetic surface EMG models generative approaches for hand gesture recognition, finding classification performance increases of up to 16 when augmented data was introduced during training
clips/audio_773.wav|More recently, data augmentation studies have begun to focus on the field of deep learning, more specifically on the ability of generative models to create artificial data which is then introduced during the classification model training process|More recently, data augmentation studies have begun to focus on the field of deep learning, more specifically on the ability of generative models to create artificial data which is then introduced during the classification model training process
clips/audio_774.wav|In 2018, Luo et al.16 observed that useful EEG signal data could be generated by Conditional Wasserstein Generative Adversarial Networks G A Ns which was then introduced to the training set in a classical train-test learning framework|In 2018, Luo et al.16 observed that useful EEG signal data could be generated by Conditional Wasserstein Generative Adversarial Networks G A Ns which was then introduced to the training set in a classical train-test learning framework
clips/audio_775.wav|The authors found classification performance was improved when such techniques were introduced.|The authors found classification performance was improved when such techniques were introduced.
clips/audio_776.wav|The prediction of mechanical signals based on data augmentation brings a new generation of technological innovations, such as new energy dispatch, 5G communication field, and robotics control engineering.17 In 2022, Yang et al.17 integrate constraints, optimization and control into a deep network framework based on data augmentation and data pruning with spatio-temporal data correlation, and improve the interpretability, safety and controllability of deep learning in real industrial projects through explicit mathematical programming equations and analytical solutions.|The prediction of mechanical signals based on data augmentation brings a new generation of technological innovations, such as new energy dispatch, 5G communication field, and robotics control engineering.17 In 2022, Yang et al.17 integrate constraints, optimization and control into a deep network framework based on data augmentation and data pruning with spatio-temporal data correlation, and improve the interpretability, safety and controllability of deep learning in real industrial projects through explicit mathematical programming equations and analytical solutions.
clips/audio_777.wav|fuh-ne-tiks is a branch of linguistics that studies how humans produce and perceive sounds or, in the case of sign languages, the equivalent aspects of sign.1 Linguists who specialize in studying the physical properties of speech are phoneticians|fuh-ne-tiks is a branch of linguistics that studies how humans produce and perceive sounds or, in the case of sign languages, the equivalent aspects of sign.1 Linguists who specialize in studying the physical properties of speech are phoneticians
clips/audio_778.wav|The field of phonetics is traditionally divided into three sub-disciplines based on the research questions involved such as how humans plan and execute movements to produce speech articulatory phonetics, how various movements affect the properties of the resulting sound acoustic phonetics or how humans convert sound waves to linguistic information auditory phonetics|The field of phonetics is traditionally divided into three sub-disciplines based on the research questions involved such as how humans plan and execute movements to produce speech articulatory phonetics, how various movements affect the properties of the resulting sound acoustic phonetics or how humans convert sound waves to linguistic information auditory phonetics
clips/audio_779.wav|Traditionally, the minimal linguistic unit of phonetics is the phonea speech sound in a language which differs from the phonological unit of phoneme the phoneme is an abstract categorization of phones and it is also defined as the smallest unit that discerns meaning between sounds in any given language.2|Traditionally, the minimal linguistic unit of phonetics is the phonea speech sound in a language which differs from the phonological unit of phoneme the phoneme is an abstract categorization of phones and it is also defined as the smallest unit that discerns meaning between sounds in any given language.2
clips/audio_780.wav|fuh-ne-tiks deals with two aspects of human speech production the ways humans make sounds and perception the way speech is understood|fuh-ne-tiks deals with two aspects of human speech production the ways humans make sounds and perception the way speech is understood
clips/audio_781.wav|Language production consists of several interdependent processes which transform a non-linguistic message into a spoken or signed linguistic signal|Language production consists of several interdependent processes which transform a non-linguistic message into a spoken or signed linguistic signal
clips/audio_782.wav|After identifying a message to be linguistically encoded, a speaker must select the individual wordsknown as lexical itemsto represent that message in a process called lexical selection|After identifying a message to be linguistically encoded, a speaker must select the individual wordsknown as lexical itemsto represent that message in a process called lexical selection
clips/audio_783.wav|During phonological encoding, the mental representation of the words are assigned their phonological content as a sequence of foh-neems to be produced|During phonological encoding, the mental representation of the words are assigned their phonological content as a sequence of foh-neems to be produced
clips/audio_784.wav|The foh-neems are specified for articulatory features which denote particular goals such as closed lips or the tongue in a particular location|The foh-neems are specified for articulatory features which denote particular goals such as closed lips or the tongue in a particular location
clips/audio_785.wav|These foh-neems are then coordinated into a sequence of muscle commands that can be sent to the muscles and when these commands are executed properly the intended sounds are produced.|These foh-neems are then coordinated into a sequence of muscle commands that can be sent to the muscles and when these commands are executed properly the intended sounds are produced.
clips/audio_786.wav|Language perception is the process by which a linguistic signal is decoded and understood by a listener|Language perception is the process by which a linguistic signal is decoded and understood by a listener
clips/audio_787.wav|To perceive speech, the continuous acoustic signal must be converted into discrete linguistic units such as foh-neems, morphemes and words|To perceive speech, the continuous acoustic signal must be converted into discrete linguistic units such as foh-neems, morphemes and words
clips/audio_788.wav|To correctly identify and categorize sounds, listeners prioritize certain aspects of the signal that can reliably distinguish between linguistic categories|To correctly identify and categorize sounds, listeners prioritize certain aspects of the signal that can reliably distinguish between linguistic categories
clips/audio_789.wav|For example, though oral languages prioritize acoustic information, the McGurk effect shows that visual information is used to distinguish ambiguous information when the acoustic cues are unreliable.|For example, though oral languages prioritize acoustic information, the McGurk effect shows that visual information is used to distinguish ambiguous information when the acoustic cues are unreliable.
clips/audio_790.wav|Modern phonetics has three branches|Modern phonetics has three branches
clips/audio_791.wav|The first known study of phonetics phonetic was undertaken by Sanskrit grammarians as early as the 6th centuryBCE.3 The Hindu scholar Pini is among the most well known of these early investigators|The first known study of phonetics phonetic was undertaken by Sanskrit grammarians as early as the 6th centuryBCE.3 The Hindu scholar Pini is among the most well known of these early investigators
clips/audio_792.wav|His four-part grammar, written c.350BCE, is influential in modern linguistics and still represents "the most complete generative grammar of any language yet written".4 His grammar formed the basis of modern linguistics and described several important phonetic principles, including voicing|His four-part grammar, written c.350BCE, is influential in modern linguistics and still represents "the most complete generative grammar of any language yet written".4 His grammar formed the basis of modern linguistics and described several important phonetic principles, including voicing
clips/audio_793.wav|The Sanskrit study of phonetics is called Shiksha, which the 1st-millennium BCE Taittiriya Upanishad defines as follows|The Sanskrit study of phonetics is called Shiksha, which the 1st-millennium BCE Taittiriya Upanishad defines as follows
clips/audio_794.wav|Advancements in phonetics after Pini and his contemporaries were limited until the modern era, save some limited investigations by Greek and Roman grammarians|Advancements in phonetics after Pini and his contemporaries were limited until the modern era, save some limited investigations by Greek and Roman grammarians
clips/audio_795.wav|In the millennia between Indic grammarians and modern phonetics, the focus shifted from the difference between spoken and written language, which was the driving force behind Pini's account, and began to focus on the physical properties of speech alone|In the millennia between Indic grammarians and modern phonetics, the focus shifted from the difference between spoken and written language, which was the driving force behind Pini's account, and began to focus on the physical properties of speech alone
clips/audio_796.wav|Sustained interest in phonetics began again around 1800 CE with the term "phonetics" being first used in the present sense in 1841.73 With new developments in medicine and the development of audio and visual recording devices, phonetic insights were able to use and review new and more detailed data|Sustained interest in phonetics began again around 1800 CE with the term "phonetics" being first used in the present sense in 1841.73 With new developments in medicine and the development of audio and visual recording devices, phonetic insights were able to use and review new and more detailed data
clips/audio_797.wav|This early period of modern phonetics included the development of an influential phonetic alphabet based on articulatory positions by Alexander Melville Bell|This early period of modern phonetics included the development of an influential phonetic alphabet based on articulatory positions by Alexander Melville Bell
clips/audio_798.wav|Before the widespread availability of audio recording equipment, phoneticians relied heavily on a tradition of practical phonetics to ensure that transcriptions and findings were able to be consistent across phoneticians|Before the widespread availability of audio recording equipment, phoneticians relied heavily on a tradition of practical phonetics to ensure that transcriptions and findings were able to be consistent across phoneticians
clips/audio_799.wav|Phoneticians were expected to learn to recognize by ear the various sounds on the International Phonetic Alphabet and the IPA still tests and certifies speakers on their ability to accurately produce the phonetic patterns of English though they have discontinued this practice for other languages.8 As a revision of his visible speech method, Melville Bell developed a description of vowels by height and backness resulting in 9 cardinal vowels.9 As part of their training in practical phonetics, phoneticians were expected to learn to produce these cardinal vowels to anchor their perception and transcription of these phones during fieldwork.8 This approach was critiqued by Peter Ladefoged in the 1960s based on experimental evidence where he found that cardinal vowels were auditory rather than articulatory targets, challenging the claim that they represented articulatory anchors by which phoneticians could judge other articulations.10|Phoneticians were expected to learn to recognize by ear the various sounds on the International Phonetic Alphabet and the IPA still tests and certifies speakers on their ability to accurately produce the phonetic patterns of English though they have discontinued this practice for other languages.8 As a revision of his visible speech method, Melville Bell developed a description of vowels by height and backness resulting in 9 cardinal vowels.9 As part of their training in practical phonetics, phoneticians were expected to learn to produce these cardinal vowels to anchor their perception and transcription of these phones during fieldwork.8 This approach was critiqued by Peter Ladefoged in the 1960s based on experimental evidence where he found that cardinal vowels were auditory rather than articulatory targets, challenging the claim that they represented articulatory anchors by which phoneticians could judge other articulations.10
clips/audio_800.wav|Language production consists of several interdependent processes which transform a nonlinguistic message into a spoken or signed linguistic signal|Language production consists of several interdependent processes which transform a nonlinguistic message into a spoken or signed linguistic signal
clips/audio_801.wav|Linguists debate whether the process of language production occurs in a series of stages serial processing or whether production processes occur in parallel|Linguists debate whether the process of language production occurs in a series of stages serial processing or whether production processes occur in parallel
clips/audio_802.wav|After identifying a message to be linguistically encoded, a speaker must select the individual wordsknown as lexical itemsto represent that message in a process called lexical selection|After identifying a message to be linguistically encoded, a speaker must select the individual wordsknown as lexical itemsto represent that message in a process called lexical selection
clips/audio_803.wav|The words are selected based on their meaning, which in linguistics is called semantic information|The words are selected based on their meaning, which in linguistics is called semantic information
clips/audio_804.wav|Lexical selection activates the word's lemma, which contains both semantic and grammatical information about the word.11a|Lexical selection activates the word's lemma, which contains both semantic and grammatical information about the word.11a
clips/audio_805.wav|In this stage of language production, the mental representation of the words are assigned their phonological content as a sequence of foh-neems to be produced|In this stage of language production, the mental representation of the words are assigned their phonological content as a sequence of foh-neems to be produced
clips/audio_806.wav|The foh-neems are specified for articulatory features which denote particular goals such as closed lips or the tongue in a particular location|The foh-neems are specified for articulatory features which denote particular goals such as closed lips or the tongue in a particular location
clips/audio_807.wav|These foh-neems are then coordinated into a sequence of muscle commands that can be sent to the muscles, and when these commands are executed properly the intended sounds are produced.13 Thus the process of production from message to sound can be summarized as the following sequencec|These foh-neems are then coordinated into a sequence of muscle commands that can be sent to the muscles, and when these commands are executed properly the intended sounds are produced.13 Thus the process of production from message to sound can be summarized as the following sequencec
clips/audio_808.wav|Because of the close connection between the position of the tongue and the resulting sound, the place of articulation is an important concept in many subdisciplines of phonetics.|Because of the close connection between the position of the tongue and the resulting sound, the place of articulation is an important concept in many subdisciplines of phonetics.
clips/audio_809.wav|For example, in English the words fought and thought are a minimal pair differing only in the organ making the construction rather than the location of the construction|For example, in English the words fought and thought are a minimal pair differing only in the organ making the construction rather than the location of the construction
clips/audio_810.wav|Coronal articulations are made with the front of the tongue, dorsal articulations are made with the back of the tongue, and radical articulations are made in the pharynx.14 These divisions are not sufficient for distinguishing and describing all speech sounds.14 For example, in English the sounds s and  are both coronal, but they are produced in different places of the mouth|Coronal articulations are made with the front of the tongue, dorsal articulations are made with the back of the tongue, and radical articulations are made in the pharynx.14 These divisions are not sufficient for distinguishing and describing all speech sounds.14 For example, in English the sounds s and  are both coronal, but they are produced in different places of the mouth
clips/audio_811.wav|Articulations in this group do not have their own symbols in the International Phonetic Alphabet, rather, they are formed by combining an apical symbol with a diacritic implicitly placing them in the coronal category.2122 They exist in a number of languages indigenous to Vanuatu such as Tangoa.|Articulations in this group do not have their own symbols in the International Phonetic Alphabet, rather, they are formed by combining an apical symbol with a diacritic implicitly placing them in the coronal category.2122 They exist in a number of languages indigenous to Vanuatu such as Tangoa.
clips/audio_812.wav|Labiodental consonants are most often fricatives while labiodental nasals are also typologically common.23 There is debate as to whether true labiodental plosives occur in any natural language,24 though a number of languages are reported to have labiodental plosives including Zulu,25 Tonga,26 and Shubi.24|Labiodental consonants are most often fricatives while labiodental nasals are also typologically common.23 There is debate as to whether true labiodental plosives occur in any natural language,24 though a number of languages are reported to have labiodental plosives including Zulu,25 Tonga,26 and Shubi.24
clips/audio_813.wav|Tongue postures using the tip of the tongue can be apical if using the top of the tongue tip, laminal if made with the blade of the tongue, or sub-apical if the tongue tip is curled back and the bottom of the tongue is used|Tongue postures using the tip of the tongue can be apical if using the top of the tongue tip, laminal if made with the blade of the tongue, or sub-apical if the tongue tip is curled back and the bottom of the tongue is used
clips/audio_814.wav|Coronals are unique as a group in that every manner of articulation is attested.2127 Australian languages are well known for the large number of coronal contrasts exhibited within and across languages in the region.28 Dental consonants are made with the tip or blade of the tongue and the upper teeth|Coronals are unique as a group in that every manner of articulation is attested.2127 Australian languages are well known for the large number of coronal contrasts exhibited within and across languages in the region.28 Dental consonants are made with the tip or blade of the tongue and the upper teeth
clips/audio_815.wav|They are divided into two groups based upon the part of the tongue used to produce them apical dental consonants are produced with the tongue tip touching the teeth interdental consonants are produced with the blade of the tongue as the tip of the tongue sticks out in front of the teeth|They are divided into two groups based upon the part of the tongue used to produce them apical dental consonants are produced with the tongue tip touching the teeth interdental consonants are produced with the blade of the tongue as the tip of the tongue sticks out in front of the teeth
clips/audio_816.wav|Alveolar consonants are made with the tip or blade of the tongue at the alveolar ridge just behind the teeth and can similarly be apical or laminal.29|Alveolar consonants are made with the tip or blade of the tongue at the alveolar ridge just behind the teeth and can similarly be apical or laminal.29
clips/audio_817.wav|Crosslinguistically, dental consonants and alveolar consonants are frequently contrasted leading to a number of generalizations of crosslinguistic patterns|Crosslinguistically, dental consonants and alveolar consonants are frequently contrasted leading to a number of generalizations of crosslinguistic patterns
clips/audio_818.wav|The different places of articulation tend to also be contrasted in the part of the tongue used to produce them most languages with dental stops have laminal dentals, while languages with apical stops usually have apical stops|The different places of articulation tend to also be contrasted in the part of the tongue used to produce them most languages with dental stops have laminal dentals, while languages with apical stops usually have apical stops
clips/audio_819.wav|Languages rarely have two consonants in the same place with a contrast in laminality, though Taa X is a counterexample to this pattern.30 If a language has only one of a dental stop or an alveolar stop, it will usually be laminal if it is a dental stop, and the stop will usually be apical if it is an alveolar stop, though for example Temne and Bulgarian31 do not follow this pattern.32 If a language has both an apical and laminal stop, then the laminal stop is more likely to be affricated like in Isoko, though Dahalo show the opposite pattern with alveolar stops being more affricated.33|Languages rarely have two consonants in the same place with a contrast in laminality, though Taa X is a counterexample to this pattern.30 If a language has only one of a dental stop or an alveolar stop, it will usually be laminal if it is a dental stop, and the stop will usually be apical if it is an alveolar stop, though for example Temne and Bulgarian31 do not follow this pattern.32 If a language has both an apical and laminal stop, then the laminal stop is more likely to be affricated like in Isoko, though Dahalo show the opposite pattern with alveolar stops being more affricated.33
clips/audio_820.wav|If the underside of the tongue tip makes contact with the roof of the mouth, it is sub-apical though apical post-alveolar sounds are also described as retroflex.34 Typical examples of sub-apical retroflex stops are commonly found in Dravidian languages, and in some languages indigenous to the southwest United States the contrastive difference between dental and alveolar stops is a slight retroflexion of the alveolar stop.35 Acoustically, retroflexion tends to affect the higher formants.35|If the underside of the tongue tip makes contact with the roof of the mouth, it is sub-apical though apical post-alveolar sounds are also described as retroflex.34 Typical examples of sub-apical retroflex stops are commonly found in Dravidian languages, and in some languages indigenous to the southwest United States the contrastive difference between dental and alveolar stops is a slight retroflexion of the alveolar stop.35 Acoustically, retroflexion tends to affect the higher formants.35
clips/audio_821.wav|Articulations taking place just behind the alveolar ridge, known as post-alveolar consonants, have been referred to using a number of different terms|Articulations taking place just behind the alveolar ridge, known as post-alveolar consonants, have been referred to using a number of different terms
clips/audio_822.wav|Apical post-alveolar consonants are often called retroflex, while laminal articulations are sometimes called palato-alveolar36 in the Australianist literature, these laminal stops are often described as 'palatal' though they are produced further forward than the palate region typically described as palatal.28 Because of individual anatomical variation, the precise articulation of palato-alveolar stops and coronals in general can vary widely within a speech community.37|Apical post-alveolar consonants are often called retroflex, while laminal articulations are sometimes called palato-alveolar36 in the Australianist literature, these laminal stops are often described as 'palatal' though they are produced further forward than the palate region typically described as palatal.28 Because of individual anatomical variation, the precise articulation of palato-alveolar stops and coronals in general can vary widely within a speech community.37
clips/audio_823.wav|They are incredibly common cross-linguistically almost all languages have a velar stop|They are incredibly common cross-linguistically almost all languages have a velar stop
clips/audio_824.wav|These variations are typically divided into front, central, and back velars in parallel with the vowel space.39 They can be hard to distinguish phonetically from palatal consonants, though are produced slightly behind the area of prototypical palatal consonants.40 Uvular consonants are made by the tongue body contacting or approaching the uvula|These variations are typically divided into front, central, and back velars in parallel with the vowel space.39 They can be hard to distinguish phonetically from palatal consonants, though are produced slightly behind the area of prototypical palatal consonants.40 Uvular consonants are made by the tongue body contacting or approaching the uvula
clips/audio_825.wav|Because the vocal folds are the source of phonation and below the oro-nasal vocal tract, a number of glottal consonants are impossible such as a voiced glottal stop|Because the vocal folds are the source of phonation and below the oro-nasal vocal tract, a number of glottal consonants are impossible such as a voiced glottal stop
clips/audio_826.wav|Three glottal consonants are possible, a voiceless glottal stop and two glottal fricatives, and all are attested in natural languages.21 Glottal stops, produced by closing the vocal folds, are notably common in the world's languages.45 While many languages use them to demarcate phrase boundaries, some languages like Arabic and Huatla Mazatec have them as contrastive foh-neems|Three glottal consonants are possible, a voiceless glottal stop and two glottal fricatives, and all are attested in natural languages.21 Glottal stops, produced by closing the vocal folds, are notably common in the world's languages.45 While many languages use them to demarcate phrase boundaries, some languages like Arabic and Huatla Mazatec have them as contrastive foh-neems
clips/audio_827.wav|Additionally, glottal stops can be realized as laryngealization of the following vowel in this language.46 Glottal stops, especially between vowels, do usually not form a complete closure|Additionally, glottal stops can be realized as laryngealization of the following vowel in this language.46 Glottal stops, especially between vowels, do usually not form a complete closure
clips/audio_828.wav|True glottal stops normally occur only when they are geminated.47|True glottal stops normally occur only when they are geminated.47
clips/audio_829.wav|The difference in pressure across the glottis required for voicing is estimated at 1  2 cm H2O 98.0665  196.133 pascals.50 The pressure differential can fall below levels required for phonation either because of an increase in pressure above the glottis superglottal pressure or a decrease in pressure below the glottis subglottal pressure|The difference in pressure across the glottis required for voicing is estimated at 1  2 cm H2O 98.0665  196.133 pascals.50 The pressure differential can fall below levels required for phonation either because of an increase in pressure above the glottis superglottal pressure or a decrease in pressure below the glottis subglottal pressure
clips/audio_830.wav|The first stage, lexical selection, provides information about lexical items required to construct the functional-level representation|The first stage, lexical selection, provides information about lexical items required to construct the functional-level representation
clips/audio_831.wav|These items are retrieved according to their specific semantic and syntactic properties, but phonological forms are not yet made available at this stage|These items are retrieved according to their specific semantic and syntactic properties, but phonological forms are not yet made available at this stage
clips/audio_832.wav|The second stage, retrieval of wordforms, provides information required for building the positional level representation.52|The second stage, retrieval of wordforms, provides information required for building the positional level representation.52
clips/audio_833.wav|For models of planning in extrinsic acoustic space, the same one-to-many mapping problem applies as well, with no unique mapping from physical or acoustic targets to the muscle movements required to achieve them|For models of planning in extrinsic acoustic space, the same one-to-many mapping problem applies as well, with no unique mapping from physical or acoustic targets to the muscle movements required to achieve them
clips/audio_834.wav|The equilibrium-point model proposes a resolution to the inverse problem by arguing that movement targets be represented as the position of the muscle pairs acting on a joint.d Importantly, muscles are modeled as springs, and the target is the equilibrium point for the modeled spring-mass system|The equilibrium-point model proposes a resolution to the inverse problem by arguing that movement targets be represented as the position of the muscle pairs acting on a joint.d Importantly, muscles are modeled as springs, and the target is the equilibrium point for the modeled spring-mass system
clips/audio_835.wav|By using springs, the equilibrium point model can easily account for compensation and response when movements are disrupted|By using springs, the equilibrium point model can easily account for compensation and response when movements are disrupted
clips/audio_836.wav|They are considered a coordinate model because they assume that these muscle positions are represented as points in space, equilibrium points, where the spring-like action of the muscles converges.5657|They are considered a coordinate model because they assume that these muscle positions are represented as points in space, equilibrium points, where the spring-like action of the muscles converges.5657
clips/audio_837.wav|The minimal unit is a gesture that represents a group of "functionally equivalent articulatory movement patterns that are actively controlled with reference to a given speech-relevant goal e.g., a bilabial closure."58 These groups represent coordinative structures or "synergies" which view movements not as individual muscle movements but as task-dependent groupings of muscles which work together as a single unit.5960 This reduces the degrees of freedom in articulation planning, a problem especially in intrinsic coordinate models, which allows for any movement that achieves the speech goal, rather than encoding the particular movements in the abstract representation|The minimal unit is a gesture that represents a group of "functionally equivalent articulatory movement patterns that are actively controlled with reference to a given speech-relevant goal e.g., a bilabial closure."58 These groups represent coordinative structures or "synergies" which view movements not as individual muscle movements but as task-dependent groupings of muscles which work together as a single unit.5960 This reduces the degrees of freedom in articulation planning, a problem especially in intrinsic coordinate models, which allows for any movement that achieves the speech goal, rather than encoding the particular movements in the abstract representation
clips/audio_838.wav|This vibration results in a periodic acoustic waveform comprising a fundamental frequency and its harmonics|This vibration results in a periodic acoustic waveform comprising a fundamental frequency and its harmonics
clips/audio_839.wav|Languages use pitch manipulation to convey lexical information in tonal languages, and many languages use pitch to mark prosodic or pragmatic information.|Languages use pitch manipulation to convey lexical information in tonal languages, and many languages use pitch to mark prosodic or pragmatic information.
clips/audio_840.wav|The normal phonation pattern used in typical speech is modal voice, where the vocal folds are held close together with moderate tension|The normal phonation pattern used in typical speech is modal voice, where the vocal folds are held close together with moderate tension
clips/audio_841.wav|Both breathy voice and whispery voice exist on a continuum loosely characterized as going from the more periodic waveform of breathy voice to the more noisy waveform of whispery voice|Both breathy voice and whispery voice exist on a continuum loosely characterized as going from the more periodic waveform of breathy voice to the more noisy waveform of whispery voice
clips/audio_842.wav|Acoustically, both tend to dampen the first formant with whispery voice showing more extreme deviations|Acoustically, both tend to dampen the first formant with whispery voice showing more extreme deviations
clips/audio_843.wav|For example, no language is known to have a phonemic voicing contrast for vowels with all known vowels canonically voiced.g Other positions of the glottis, such as breathy and creaky voice, are used in a number of languages, like Jalapa Mazatec, to contrast foh-neems while in other languages, like English, they exist allophonically.|For example, no language is known to have a phonemic voicing contrast for vowels with all known vowels canonically voiced.g Other positions of the glottis, such as breathy and creaky voice, are used in a number of languages, like Jalapa Mazatec, to contrast foh-neems while in other languages, like English, they exist allophonically.
clips/audio_844.wav|More precise measurements can be obtained through acoustic analysis of a spectrogram or spectral slice|More precise measurements can be obtained through acoustic analysis of a spectrogram or spectral slice
clips/audio_845.wav|A computational model of the unfiltered glottal signal is then fitted to the inverse filtered acoustic signal to determine the characteristics of the glottis.67 Visual analysis is also available using specialized medical equipment such as ultrasound and endoscopy.66h|A computational model of the unfiltered glottal signal is then fitted to the inverse filtered acoustic signal to determine the characteristics of the glottis.67 Visual analysis is also available using specialized medical equipment such as ultrasound and endoscopy.66h
clips/audio_846.wav|The location of the tongue during vowel production changes the frequencies at which the cavity resonates, and it is these resonancesknown as formantswhich are measured and used to characterize vowels.|The location of the tongue during vowel production changes the frequencies at which the cavity resonates, and it is these resonancesknown as formantswhich are measured and used to characterize vowels.
clips/audio_847.wav|Some languages claimed to have a three-way backness distinction include Nimboran and Norwegian.72|Some languages claimed to have a three-way backness distinction include Nimboran and Norwegian.72
clips/audio_848.wav|Sometimes more specialized tongue gestures such as rhoticity, advanced tongue root, pharyngealization, stridency and frication are required to describe a certain vowel.75|Sometimes more specialized tongue gestures such as rhoticity, advanced tongue root, pharyngealization, stridency and frication are required to describe a certain vowel.75
clips/audio_849.wav|Pressure builds up in the mouth during the stricture, which is then released as a small burst of sound when the articulators move apart|Pressure builds up in the mouth during the stricture, which is then released as a small burst of sound when the articulators move apart
clips/audio_850.wav|Trills are consonants in which the tongue or lips are set in motion by the airstream.82 The stricture is formed in such a way that the airstream causes a repeating pattern of opening and closing of the soft articulators.83 Apical trills typically consist of two or three periods of vibration.84|Trills are consonants in which the tongue or lips are set in motion by the airstream.82 The stricture is formed in such a way that the airstream causes a repeating pattern of opening and closing of the soft articulators.83 Apical trills typically consist of two or three periods of vibration.84
clips/audio_851.wav|Taps and flaps are single, rapid, usually apical gestures where the tongue is thrown against the roof of the mouth, comparable to a very rapid stop.82 These terms are sometimes used interchangeably, but some phoneticians make a distinction.85 In a tap, the tongue contacts the roof in a single motion whereas in a flap the tongue moves tangentially to the roof of the mouth, striking it in passing.|Taps and flaps are single, rapid, usually apical gestures where the tongue is thrown against the roof of the mouth, comparable to a very rapid stop.82 These terms are sometimes used interchangeably, but some phoneticians make a distinction.85 In a tap, the tongue contacts the roof in a single motion whereas in a flap the tongue moves tangentially to the roof of the mouth, striking it in passing.
clips/audio_852.wav|The release of the anterior closure is referred to as the click influx|The release of the anterior closure is referred to as the click influx
clips/audio_853.wav|The release of the posterior closure, which can be velar or uvular, is the click efflux|The release of the posterior closure, which can be velar or uvular, is the click efflux
clips/audio_854.wav|The lungs drive nearly all speech production, and their importance in phonetics is due to their creation of pressure for pulmonic sounds|The lungs drive nearly all speech production, and their importance in phonetics is due to their creation of pressure for pulmonic sounds
clips/audio_855.wav|The most common kinds of sound across languages are pulmonic egress, where air is exhaled from the lungs.89 The opposite is possible, though no language is known to have pulmonic ingressive sounds as foh-neems.90 Many languages such as Swedish use them for paralinguistic articulations such as affirmations in a number of genetically and geographically diverse languages.91 Both egressive and ingressive sounds rely on holding the vocal folds in a particular posture and using the lungs to draw air across the vocal folds so that they either vibrate voiced or do not vibrate voiceless.89 Pulmonic articulations are restricted by the volume of air able to be exhaled in a given respiratory cycle, known as the vital capacity.|The most common kinds of sound across languages are pulmonic egress, where air is exhaled from the lungs.89 The opposite is possible, though no language is known to have pulmonic ingressive sounds as foh-neems.90 Many languages such as Swedish use them for paralinguistic articulations such as affirmations in a number of genetically and geographically diverse languages.91 Both egressive and ingressive sounds rely on holding the vocal folds in a particular posture and using the lungs to draw air across the vocal folds so that they either vibrate voiced or do not vibrate voiceless.89 Pulmonic articulations are restricted by the volume of air able to be exhaled in a given respiratory cycle, known as the vital capacity.
clips/audio_856.wav|A number of thoracic muscles are used to make these adjustments|A number of thoracic muscles are used to make these adjustments
clips/audio_857.wav|During speech, the respiratory cycle is modified to accommodate both linguistic and biological needs|During speech, the respiratory cycle is modified to accommodate both linguistic and biological needs
clips/audio_858.wav|Because metabolic needs are relatively stable, the total volume of air moved in most cases of speech remains about the same as quiet tidal breathing.93 Increases in speech intensity of 18dB a loud conversation has relatively little impact on the volume of air moved|Because metabolic needs are relatively stable, the total volume of air moved in most cases of speech remains about the same as quiet tidal breathing.93 Increases in speech intensity of 18dB a loud conversation has relatively little impact on the volume of air moved
clips/audio_859.wav|The vocal tract can be modeled as a sequence of tubes, closed at one end, with varying diameters, and by using equations for acoustic resonance the acoustic effect of an articulatory posture can be derived.96 The process of inverse filtering uses this principle to analyze the source spectrum produced by the vocal folds during voicing|The vocal tract can be modeled as a sequence of tubes, closed at one end, with varying diameters, and by using equations for acoustic resonance the acoustic effect of an articulatory posture can be derived.96 The process of inverse filtering uses this principle to analyze the source spectrum produced by the vocal folds during voicing
clips/audio_860.wav|Language perception is the process by which a linguistic signal is decoded and understood by a listener.i To perceive speech, the continuous acoustic signal must be converted into discrete linguistic units such as foh-neems, morphemes, and words.98 To correctly identify and categorize sounds, listeners prioritize certain aspects of the signal that can reliably distinguish between linguistic categories.99 While certain cues are prioritized over others, many aspects of the signal can contribute to perception|Language perception is the process by which a linguistic signal is decoded and understood by a listener.i To perceive speech, the continuous acoustic signal must be converted into discrete linguistic units such as foh-neems, morphemes, and words.98 To correctly identify and categorize sounds, listeners prioritize certain aspects of the signal that can reliably distinguish between linguistic categories.99 While certain cues are prioritized over others, many aspects of the signal can contribute to perception
clips/audio_861.wav|For example, though oral languages prioritize acoustic information, the McGurk effect shows that visual information is used to distinguish ambiguous information when the acoustic cues are unreliable.100|For example, though oral languages prioritize acoustic information, the McGurk effect shows that visual information is used to distinguish ambiguous information when the acoustic cues are unreliable.100
clips/audio_862.wav|While listeners can use a variety of information to segment the speech signal, the relationship between acoustic signal and category perception is not a perfect mapping|While listeners can use a variety of information to segment the speech signal, the relationship between acoustic signal and category perception is not a perfect mapping
clips/audio_863.wav|Because of coarticulation, noisy environments, and individual differences, there is a high degree of acoustic variability within categories.101 Known as the problem of perceptual invariance, listeners are able to reliably perceive categories despite the variability in acoustic instantiation.102 To do this, listeners rapidly accommodate to new speakers and will shift their boundaries between categories to match the acoustic distinctions their conversational partner is making.103|Because of coarticulation, noisy environments, and individual differences, there is a high degree of acoustic variability within categories.101 Known as the problem of perceptual invariance, listeners are able to reliably perceive categories despite the variability in acoustic instantiation.102 To do this, listeners rapidly accommodate to new speakers and will shift their boundaries between categories to match the acoustic distinctions their conversational partner is making.103
clips/audio_864.wav|The vibration of the ear drum is transmitted by the ossiclesthree small bones of the middle earto the cochlea.104 The cochlea is a spiral-shaped, fluid-filled tube divided lengthwise by the organ of Corti which contains the basilar membrane|The vibration of the ear drum is transmitted by the ossiclesthree small bones of the middle earto the cochlea.104 The cochlea is a spiral-shaped, fluid-filled tube divided lengthwise by the organ of Corti which contains the basilar membrane
clips/audio_865.wav|The basilar membrane increases in thickness as it travels through the cochlea causing different frequencies to resonate at different locations|The basilar membrane increases in thickness as it travels through the cochlea causing different frequencies to resonate at different locations
clips/audio_866.wav|This tonotopic design allows for the ear to analyze sound in a manner similar to a Fourier transform.105|This tonotopic design allows for the ear to analyze sound in a manner similar to a Fourier transform.105
clips/audio_867.wav|The differential vibration of the basilar causes the hair cells within the organ of Corti to move|The differential vibration of the basilar causes the hair cells within the organ of Corti to move
clips/audio_868.wav|In this way, the patterns of oscillations on the basilar membrane are converted to spatiotemporal patterns of firings which transmit information about the sound to the brainstem.107|In this way, the patterns of oscillations on the basilar membrane are converted to spatiotemporal patterns of firings which transmit information about the sound to the brainstem.107
clips/audio_869.wav|Besides consonants and vowels, phonetics also describes the properties of speech that are not localized to segments but greater units of speech, such as syllables and phrases|Besides consonants and vowels, phonetics also describes the properties of speech that are not localized to segments but greater units of speech, such as syllables and phrases
clips/audio_870.wav|Prosody includes auditory characteristics such as pitch, speech rate, duration, and loudness|Prosody includes auditory characteristics such as pitch, speech rate, duration, and loudness
clips/audio_871.wav|Early theories of speech perception such as motor theory attempted to solve the problem of perceptual invariance by arguing that speech perception and production were closely linked|Early theories of speech perception such as motor theory attempted to solve the problem of perceptual invariance by arguing that speech perception and production were closely linked
clips/audio_872.wav|In its strongest form, motor theory argues that speech perception requires the listener to access the articulatory representation of sounds109 to properly categorize a sound, a listener reverse engineers the articulation which would produce that sound and by identifying these gestures is able to retrieve the intended linguistic category.110 While findings such as the McGurk effect and case studies from patients with neurological injuries have provided support for motor theory, further experiments have not supported the strong form of motor theory, though there is some support for weaker forms of motor theory which claim a non-deterministic relationship between production and perception.110111112|In its strongest form, motor theory argues that speech perception requires the listener to access the articulatory representation of sounds109 to properly categorize a sound, a listener reverse engineers the articulation which would produce that sound and by identifying these gestures is able to retrieve the intended linguistic category.110 While findings such as the McGurk effect and case studies from patients with neurological injuries have provided support for motor theory, further experiments have not supported the strong form of motor theory, though there is some support for weaker forms of motor theory which claim a non-deterministic relationship between production and perception.110111112
clips/audio_873.wav|Successor theories of speech perception place the focus on acoustic cues to sound categories and can be grouped into two broad categories abstractionist theories and episodic theories.113 In abstractionist theories, speech perception involves the identification of an idealized lexical object based on a signal reduced to its necessary components and normalizing the signal to counteract speaker variability|Successor theories of speech perception place the focus on acoustic cues to sound categories and can be grouped into two broad categories abstractionist theories and episodic theories.113 In abstractionist theories, speech perception involves the identification of an idealized lexical object based on a signal reduced to its necessary components and normalizing the signal to counteract speaker variability
clips/audio_874.wav|The problem of perceptual invariance is explained by episodic theories as an issue of familiarity normalization is a byproduct of exposure to more variable distributions rather than a discrete process as abstractionist theories claim.113|The problem of perceptual invariance is explained by episodic theories as an issue of familiarity normalization is a byproduct of exposure to more variable distributions rather than a discrete process as abstractionist theories claim.113
clips/audio_875.wav|Acoustic phonetics deals with the acoustic properties of speech sounds|Acoustic phonetics deals with the acoustic properties of speech sounds
clips/audio_876.wav|The ear transforms this movement into neural signals that the brain registers as sound|The ear transforms this movement into neural signals that the brain registers as sound
clips/audio_877.wav|Acoustic waveforms are records that measure these pressure fluctuations.114|Acoustic waveforms are records that measure these pressure fluctuations.114
clips/audio_878.wav|Articulatory phonetics deals with the ways in which speech sounds are made.|Articulatory phonetics deals with the ways in which speech sounds are made.
clips/audio_879.wav|Auditory phonetics studies how humans perceive speech sounds|Auditory phonetics studies how humans perceive speech sounds
clips/audio_880.wav|Human languages use many different sounds and to compare them linguists must be able to describe sounds in a way that is language independent|Human languages use many different sounds and to compare them linguists must be able to describe sounds in a way that is language independent
clips/audio_881.wav|Speech sounds can be described in a number of ways|Speech sounds can be described in a number of ways
clips/audio_882.wav|Because the acoustics are a consequence of the articulation, both methods of description are sufficient to distinguish sounds with the choice between systems dependent on the phonetic feature being investigated.|Because the acoustics are a consequence of the articulation, both methods of description are sufficient to distinguish sounds with the choice between systems dependent on the phonetic feature being investigated.
clips/audio_883.wav|The respiratory organs used to create and modify airflow are divided into three regions the vocal tract supralaryngeal, the larynx, and the subglottal system|The respiratory organs used to create and modify airflow are divided into three regions the vocal tract supralaryngeal, the larynx, and the subglottal system
clips/audio_884.wav|Vowels that are articulated with a stable quality are called monophthongs a combination of two separate vowels in the same syllable is a diphthong.118 In the IPA, the vowels are represented on a trapezoid shape representing the human mouth the vertical axis representing the mouth from floor to roof and the horizontal axis represents the front-back dimension.119|Vowels that are articulated with a stable quality are called monophthongs a combination of two separate vowels in the same syllable is a diphthong.118 In the IPA, the vowels are represented on a trapezoid shape representing the human mouth the vertical axis representing the mouth from floor to roof and the horizontal axis represents the front-back dimension.119
clips/audio_885.wav|The most widely known system of phonetic transcription, the International Phonetic Alphabet IPA, provides a standardized set of symbols for oral phones.120121 The standardized nature of the IPA enables its users to transcribe accurately and consistently the phones of different languages, dialects, and idiolects.120122123 The IPA is a useful tool not only for the study of phonetics but also for language teaching, professional acting, and speech pathology.122|The most widely known system of phonetic transcription, the International Phonetic Alphabet IPA, provides a standardized set of symbols for oral phones.120121 The standardized nature of the IPA enables its users to transcribe accurately and consistently the phones of different languages, dialects, and idiolects.120122123 The IPA is a useful tool not only for the study of phonetics but also for language teaching, professional acting, and speech pathology.122
clips/audio_886.wav|While no sign language has a standardized writing system, linguists have developed their own notation systems that describe the handshape, location and movement|While no sign language has a standardized writing system, linguists have developed their own notation systems that describe the handshape, location and movement
clips/audio_887.wav|The Hamburg Notation System HamNoSys is similar to the IPA in that it allows for varying levels of detail|The Hamburg Notation System HamNoSys is similar to the IPA in that it allows for varying levels of detail
clips/audio_888.wav|Due to requiring less energy, distal movements are generally easier to produce|Due to requiring less energy, distal movements are generally easier to produce
clips/audio_889.wav|Due to universal neurological limitations, two-handed signs generally have the same kind of articulation in both hands this is referred to as the Symmetry Condition.125 The second universal constraint is the Dominance Condition, which holds that when two handshapes are involved, one hand will remain stationary and have a more limited set of handshapes compared to the dominant, moving hand.127 Additionally, it is common for one hand in a two-handed sign to be dropped during informal conversations, a process referred to as weak drop.125 Just like words in spoken languages, coarticulation may cause signs to influence each other's form|Due to universal neurological limitations, two-handed signs generally have the same kind of articulation in both hands this is referred to as the Symmetry Condition.125 The second universal constraint is the Dominance Condition, which holds that when two handshapes are involved, one hand will remain stationary and have a more limited set of handshapes compared to the dominant, moving hand.127 Additionally, it is common for one hand in a two-handed sign to be dropped during informal conversations, a process referred to as weak drop.125 Just like words in spoken languages, coarticulation may cause signs to influence each other's form
clips/audio_890.wav|FastA P I framework, high performance, easy to learn, fast to code, ready for production|FastA P I framework, high performance, easy to learn, fast to code, ready for production
clips/audio_891.wav|FastA P I is a modern, fast high-performance, web framework for building A P Is with Python based on standard Python type hints.|FastA P I is a modern, fast high-performance, web framework for building A P Is with Python based on standard Python type hints.
clips/audio_892.wav| estimation based on tests on an internal development team, building production applications.| estimation based on tests on an internal development team, building production applications.
clips/audio_893.wav|"... I'm using FastA P I a ton these days|"... I'm using FastA P I a ton these days
clips/audio_894.wav|"We adopted the FastA P I library to spawn a REST server that can be queried to obtain predictions|"We adopted the FastA P I library to spawn a REST server that can be queried to obtain predictions
clips/audio_895.wav|"Netflix is pleased to announce the open-source release of our crisis management orchestration framework Dispatch! built with FastA P I"|"Netflix is pleased to announce the open-source release of our crisis management orchestration framework Dispatch! built with FastA P I"
clips/audio_896.wav|"Im over the moon excited about FastA P I|"Im over the moon excited about FastA P I
clips/audio_897.wav|"Honestly, what you've built looks super solid and polished|"Honestly, what you've built looks super solid and polished
clips/audio_898.wav|In many ways, it's what I wanted Hug to be - it's really inspiring to see someone build that."|In many ways, it's what I wanted Hug to be - it's really inspiring to see someone build that."
clips/audio_899.wav|"If you're looking to learn one modern framework for building REST A P Is, check out FastA P I ... It's fast, easy to use and easy to learn ..."|"If you're looking to learn one modern framework for building REST A P Is, check out FastA P I ... It's fast, easy to use and easy to learn ..."
clips/audio_900.wav|"We've switched over to FastA P I for our A P Is ... I think you'll like it ..."|"We've switched over to FastA P I for our A P Is ... I think you'll like it ..."
clips/audio_901.wav|"If anyone is looking to build a production Python A P I, I would highly recommend FastA P I|"If anyone is looking to build a production Python A P I, I would highly recommend FastA P I
clips/audio_902.wav|It is beautifully designed, simple to use and highly scalable, it has become a key component in our A P I first development strategy and is driving many automations and services such as our Virtual TAC Engineer."|It is beautifully designed, simple to use and highly scalable, it has become a key component in our A P I first development strategy and is driving many automations and services such as our Virtual TAC Engineer."
clips/audio_903.wav|If you are building a C L I app to be used in the terminal instead of a web A P I, check out Typer.|If you are building a C L I app to be used in the terminal instead of a web A P I, check out Typer.
clips/audio_904.wav|Typer is FastA P I's little sibling|Typer is FastA P I's little sibling
clips/audio_905.wav|And it's intended to be the FastA P I of C L Is|And it's intended to be the FastA P I of C L Is
clips/audio_906.wav|FastA P I stands on the shoulders of giants|FastA P I stands on the shoulders of giants
clips/audio_907.wav|Create and activate a virtual environment and then install FastA P I|Create and activate a virtual environment and then install FastA P I
clips/audio_908.wav|Note Make sure you put "fastA P I standard" in quotes to ensure it works in all terminals.|Note Make sure you put "fastA P I standard" in quotes to ensure it works in all terminals.
clips/audio_909.wav|The command fastapi dev reads your main.py file, detects the FastA P I app in it, and starts a server using Uvicorn.|The command fastapi dev reads your main.py file, detects the FastA P I app in it, and starts a server using Uvicorn.
clips/audio_910.wav|By default, fastapi dev will start with auto-reload enabled for local development.|By default, fastapi dev will start with auto-reload enabled for local development.
clips/audio_911.wav|You can read more about it in the FastA P I C L I docs.|You can read more about it in the FastA P I C L I docs.
clips/audio_912.wav|You will see the Jay-son response as|You will see the Jay-son response as
clips/audio_913.wav|You already created an A P I that|You already created an A P I that
clips/audio_914.wav|You will see the automatic interactive A P I documentation provided by Swagger user interface|You will see the automatic interactive A P I documentation provided by Swagger user interface
clips/audio_915.wav|Declare the body using standard Python types, thanks to Pydantic.|Declare the body using standard Python types, thanks to Pydantic.
clips/audio_916.wav|The fastapi dev server should reload automatically.|The fastapi dev server should reload automatically.
clips/audio_917.wav|You do that with standard modern Python types.|You do that with standard modern Python types.
clips/audio_918.wav|Just standard Python.|Just standard Python.
clips/audio_919.wav|Coming back to the previous code example, FastA P I will|Coming back to the previous code example, FastA P I will
clips/audio_920.wav|For a more complete example including more features, see the Tutorial - User Guide.|For a more complete example including more features, see the Tutorial - User Guide.
clips/audio_921.wav|Spoiler alert the tutorial - user guide includes|Spoiler alert the tutorial - user guide includes
clips/audio_922.wav|Independent TechEmpower benchmarks show FastA P I applications running under Uvicorn as one of the fastest Python frameworks available, only below Starlette and Uvicorn themselves used internally by FastA P I|Independent TechEmpower benchmarks show FastA P I applications running under Uvicorn as one of the fastest Python frameworks available, only below Starlette and Uvicorn themselves used internally by FastA P I
clips/audio_923.wav|FastA P I depends on Pydantic and Starlette.|FastA P I depends on Pydantic and Starlette.
clips/audio_924.wav|When you install FastA P I with pip install "fastA P I standard" it comes the standard group of optional dependencies|When you install FastA P I with pip install "fastA P I standard" it comes the standard group of optional dependencies
clips/audio_925.wav|Used by FastA P I  Starlette|Used by FastA P I  Starlette
clips/audio_926.wav|If you don't want to include the standard optional dependencies, you can install with pip install fastapi instead of pip install "fastA P I standard".|If you don't want to include the standard optional dependencies, you can install with pip install fastapi instead of pip install "fastA P I standard".
clips/audio_927.wav|Additional optional FastA P I dependencies|Additional optional FastA P I dependencies
clips/audio_928.wav|Web3 applications rely on a process called tokenization|Web3 applications rely on a process called tokenization
clips/audio_929.wav|In this case, tokenization is a digitization process to make assets more accessible|In this case, tokenization is a digitization process to make assets more accessible
clips/audio_930.wav|AI models and new modes of payments also use a process called tokenization, both of which have little to do with Web3 tokenizationor each other, for that matter|AI models and new modes of payments also use a process called tokenization, both of which have little to do with Web3 tokenizationor each other, for that matter
clips/audio_931.wav|In payments, tokenization is used for cybersecurity and to obfuscate the identity of the payment itself, essentially to prevent fraud|In payments, tokenization is used for cybersecurity and to obfuscate the identity of the payment itself, essentially to prevent fraud
clips/audio_932.wav|For a detailed description of tokenization in AI, see sidebar, How does tokenization work in AI?|For a detailed description of tokenization in AI, see sidebar, How does tokenization work in AI?
clips/audio_933.wav|toh-kuh-nuh-zay-shun in AI is used to break down data for easier pattern detection|toh-kuh-nuh-zay-shun in AI is used to break down data for easier pattern detection
clips/audio_934.wav|deep learningmodels trained on vast quantities of unstructured, unlabeled data are called foundation models|deep learningmodels trained on vast quantities of unstructured, unlabeled data are called foundation models
clips/audio_935.wav|Trained via a process called fine-tuning, these models can not only process massive amounts of unstructured text but also learn the relationships between sentences, words, or even portions of words|Trained via a process called fine-tuning, these models can not only process massive amounts of unstructured text but also learn the relationships between sentences, words, or even portions of words
clips/audio_936.wav|This in turn enables them to generate natural-language text or perform summarization or other knowledge-extraction tasks|This in turn enables them to generate natural-language text or perform summarization or other knowledge-extraction tasks
clips/audio_937.wav|Heres how tokenization makes this possible|Heres how tokenization makes this possible
clips/audio_938.wav|There are a number of tokenization techniques commonly used in LLMs|There are a number of tokenization techniques commonly used in LLMs
clips/audio_939.wav|The type of tokenization used depends on what the model needs to accomplish|The type of tokenization used depends on what the model needs to accomplish
clips/audio_940.wav|Different tokenization methods may also be combined to achieve the required results|Different tokenization methods may also be combined to achieve the required results
clips/audio_941.wav|McKinsey analysis indicates that tokenized market capitalization could reach around 2 trillionby 2030 excluding cryptocurrencies like Bitcoin and stablecoins like Tether|McKinsey analysis indicates that tokenized market capitalization could reach around 2 trillionby 2030 excluding cryptocurrencies like Bitcoin and stablecoins like Tether
clips/audio_942.wav|Specifically, we expect that organizations working with certain asset classes will be the quickest adopters these include cash and deposits, bonds and exchange-traded notes, mutual funds and exchange-traded funds, as well as loans and securitization|Specifically, we expect that organizations working with certain asset classes will be the quickest adopters these include cash and deposits, bonds and exchange-traded notes, mutual funds and exchange-traded funds, as well as loans and securitization
clips/audio_943.wav|Larry Fink, the chairman and CEO of BlackRock, said in January twenty twenty-four We believe the next step going forward will be the tokenization of financial assets, and that means every stock, every bond  will be on one general ledger.|Larry Fink, the chairman and CEO of BlackRock, said in January twenty twenty-four We believe the next step going forward will be the tokenization of financial assets, and that means every stock, every bond  will be on one general ledger.
clips/audio_944.wav|In general, tokenization is the process of issuing a digital, unique, and anonymous representation of a real thing|In general, tokenization is the process of issuing a digital, unique, and anonymous representation of a real thing
clips/audio_945.wav|Tokens can represent assets, including physical assets like real estate or art, financial assets like equities or bonds, intangible assets like intellectual property, or even identity and data|Tokens can represent assets, including physical assets like real estate or art, financial assets like equities or bonds, intangible assets like intellectual property, or even identity and data
clips/audio_946.wav|Web3 tokenization can create several types of tokens|Web3 tokenization can create several types of tokens
clips/audio_947.wav|As noted earlier, AI also uses a concept called tokenization, which is quite different from Web3 tokens despite their shared name|As noted earlier, AI also uses a concept called tokenization, which is quite different from Web3 tokens despite their shared name
clips/audio_948.wav|For a more detailed explanation of what tokenization means in an AI context, see sidebar, How does tokenization work in AI?|For a more detailed explanation of what tokenization means in an AI context, see sidebar, How does tokenization work in AI?
clips/audio_949.wav|The benefits of Web3 tokenization for financial institutions include the following|The benefits of Web3 tokenization for financial institutions include the following
clips/audio_950.wav|These, in turn, can mean increased efficiency, liquidity, and new revenue opportunities|These, in turn, can mean increased efficiency, liquidity, and new revenue opportunities
clips/audio_951.wav|Financial-services incumbents like BlackRock, WisdomTree, and Franklin Templeton, as well as Web3 natives Ondo Finance, Superstate, and Maple Finance, are increasingly adopting tokenized money market funds|Financial-services incumbents like BlackRock, WisdomTree, and Franklin Templeton, as well as Web3 natives Ondo Finance, Superstate, and Maple Finance, are increasingly adopting tokenized money market funds
clips/audio_952.wav|As weve seen, Web3 is a new type of internet, built on new types of technology|As weve seen, Web3 is a new type of internet, built on new types of technology
clips/audio_953.wav|As well see, these technologies come together to support a variety of breakthroughs related to tokenization.|As well see, these technologies come together to support a variety of breakthroughs related to tokenization.
clips/audio_954.wav|Some industry leaders believe tokenization stands to transformthe structure of financial services and capital markets because it lets asset holders reap the benefits of blockchain, such as 247 operations and data availability|Some industry leaders believe tokenization stands to transformthe structure of financial services and capital markets because it lets asset holders reap the benefits of blockchain, such as 247 operations and data availability
clips/audio_955.wav|Blockchain also offers faster transaction settlement and a higher degree of automation via embedded code that only gets activated if certain conditions are met|Blockchain also offers faster transaction settlement and a higher degree of automation via embedded code that only gets activated if certain conditions are met
clips/audio_956.wav|While yet to be tested at scale, tokenizations potential benefits include the following|While yet to be tested at scale, tokenizations potential benefits include the following
clips/audio_957.wav|Theres been hype around digital-asset tokenization for years, since its introduction back in 2017|Theres been hype around digital-asset tokenization for years, since its introduction back in 2017
clips/audio_958.wav|We are, though, seeing some slow movement as of mid-2023, US-based fintech infrastructure firm Broadridge was facilitatingmore than 1 trillion monthly on its distributed ledger platform|We are, though, seeing some slow movement as of mid-2023, US-based fintech infrastructure firm Broadridge was facilitatingmore than 1 trillion monthly on its distributed ledger platform
clips/audio_959.wav|There are four typical steps involved in asset tokenization|There are four typical steps involved in asset tokenization
clips/audio_960.wav|First released in 1985 as an extension of the C programming language, it has since expanded significantly over time as of 1997update, C has object-oriented, generic, and functional features, in addition to facilities for low-level memory manipulation for systems like microcomputers or to make operating systems like Li-nux or Windows|First released in 1985 as an extension of the C programming language, it has since expanded significantly over time as of 1997update, C has object-oriented, generic, and functional features, in addition to facilities for low-level memory manipulation for systems like microcomputers or to make operating systems like Li-nux or Windows
clips/audio_961.wav|It is usually implemented as a compiled language, and many vendors provide C compilers, including the Free Software Foundation, LLVM, Microsoft, Intel, Embarcadero, Oracle, and IBM.14|It is usually implemented as a compiled language, and many vendors provide C compilers, including the Free Software Foundation, LLVM, Microsoft, Intel, Embarcadero, Oracle, and IBM.14
clips/audio_962.wav|C was designed with systems programming and embedded, resource-constrained software and large systems in mind, with performance, efficiency, and flexibility of use as its design highlights.15 C has also been found useful in many other contexts, with key strengths being software infrastructure and resource-constrained applications,15 including desktop applications, video games, servers e.g., e-commerce, web search, or databases, and performance-critical applications e.g., telephone switches or space probes.16|C was designed with systems programming and embedded, resource-constrained software and large systems in mind, with performance, efficiency, and flexibility of use as its design highlights.15 C has also been found useful in many other contexts, with key strengths being software infrastructure and resource-constrained applications,15 including desktop applications, video games, servers e.g., e-commerce, web search, or databases, and performance-critical applications e.g., telephone switches or space probes.16
clips/audio_963.wav|C is standardized by the International Organization for Standardization ISO, with the latest standard version ratified and published by ISO in December 2020 as ISOIEC 148822020 informally known as C20.17 The C programming language was initially standardized in 1998 as ISOIEC 148821998, which was then amended by the C03, C11, C14, and C17 standards|C is standardized by the International Organization for Standardization ISO, with the latest standard version ratified and published by ISO in December 2020 as ISOIEC 148822020 informally known as C20.17 The C programming language was initially standardized in 1998 as ISOIEC 148821998, which was then amended by the C03, C11, C14, and C17 standards
clips/audio_964.wav|Before the initial standardization in 1998, C was developed by Stroustrup at Bell Labs since 1979 as an extension of the C language he wanted an efficient and flexible language similar to C that also provided high-level features for program organization.18 Since 2012, C has been on a three-year release schedule19 with C23 as the next planned standard.20|Before the initial standardization in 1998, C was developed by Stroustrup at Bell Labs since 1979 as an extension of the C language he wanted an efficient and flexible language similar to C that also provided high-level features for program organization.18 Since 2012, C has been on a three-year release schedule19 with C23 as the next planned standard.20
clips/audio_965.wav|In 1979, Bjarne Stroustrup, a Danish computer scientist, began work on "C with Classes", the predecessor to C.21 The motivation for creating a new language originated from Stroustrup's experience in programming for his PhD thesis|In 1979, Bjarne Stroustrup, a Danish computer scientist, began work on "C with Classes", the predecessor to C.21 The motivation for creating a new language originated from Stroustrup's experience in programming for his PhD thesis
clips/audio_966.wav|Stroustrup found that Simula had features that were very helpful for large software development, but the language was too slow for practical use, while BCPL was fast but too low-level to be suitable for large software development|Stroustrup found that Simula had features that were very helpful for large software development, but the language was too slow for practical use, while BCPL was fast but too low-level to be suitable for large software development
clips/audio_967.wav|Remembering his PhD experience, Stroustrup set out to enhance the C language with Simula-like features.22 C was chosen because it was general-purpose, fast, portable, and widely used|Remembering his PhD experience, Stroustrup set out to enhance the C language with Simula-like features.22 C was chosen because it was general-purpose, fast, portable, and widely used
clips/audio_968.wav|In 1989, C 2.0 was released, followed by the updated second edition of The C Programming Language in 1991.25 New features in 2.0 included multiple inheritance, abstract classes, static member functions, const member functions, and protected members|In 1989, C 2.0 was released, followed by the updated second edition of The C Programming Language in 1991.25 New features in 2.0 included multiple inheritance, abstract classes, static member functions, const member functions, and protected members
clips/audio_969.wav|After a minor C14 update released in December 2014, various new additions were introduced in C17.26 After becoming finalized in February 2020,27 a draft of the C20 standard was approved on 4 September 2020, and officially published on 15 December 2020.2829|After a minor C14 update released in December 2014, various new additions were introduced in C17.26 After becoming finalized in February 2020,27 a draft of the C20 standard was approved on 4 September 2020, and officially published on 15 December 2020.2829
clips/audio_970.wav|As of December2022update, C ranked third on the TIOBE index, surpassing Java for the first time in the history of the index|As of December2022update, C ranked third on the TIOBE index, surpassing Java for the first time in the history of the index
clips/audio_971.wav|It ranks third, after Python and C.31|It ranks third, after Python and C.31
clips/audio_972.wav|According to Stroustrup, "the name signifies the evolutionary nature of the changes from C."32 This name is credited to Rick Mascitti mid-198323 and was first used in December 1983|According to Stroustrup, "the name signifies the evolutionary nature of the changes from C."32 This name is credited to Rick Mascitti mid-198323 and was first used in December 1983
clips/audio_973.wav|When Mascitti was questioned informally in 1992 about the naming, he indicated that it was given in a tongue-in-cheek spirit|When Mascitti was questioned informally in 1992 about the naming, he indicated that it was given in a tongue-in-cheek spirit
clips/audio_974.wav|During C's development period, the language had been referred to as "new C" and "C with Classes"2333 before acquiring its final name.|During C's development period, the language had been referred to as "new C" and "C with Classes"2333 before acquiring its final name.
clips/audio_975.wav|Throughout C's life, its development and evolution has been guided by a set of principles22|Throughout C's life, its development and evolution has been guided by a set of principles22
clips/audio_976.wav|In 1998, the ISO working group standardized C for the first time as ISOIEC 148821998, which is informally known as C98|In 1998, the ISO working group standardized C for the first time as ISOIEC 148821998, which is informally known as C98
clips/audio_977.wav|The next major revision of the standard was informally referred to as "C0x", but it was not released until 2011.39 C11 148822011 included many additions to both the core language and the standard library.36|The next major revision of the standard was informally referred to as "C0x", but it was not released until 2011.39 C11 148822011 included many additions to both the core language and the standard library.36
clips/audio_978.wav|After C14, a major revision C17, informally known as C1z, was completed by the ISO C committee in mid July 2017 and was approved and published in December 2017.42|After C14, a major revision C17, informally known as C1z, was completed by the ISO C committee in mid July 2017 and was approved and published in December 2017.42
clips/audio_979.wav|Stroustrup describes C as "a light-weight abstraction programming language designed for building and using efficient and elegant abstractions"15 and "offering both hardware access and abstraction is the basis of C|Stroustrup describes C as "a light-weight abstraction programming language designed for building and using efficient and elegant abstractions"15 and "offering both hardware access and abstraction is the basis of C
clips/audio_980.wav|Doing it efficiently is what distinguishes it from other languages."60|Doing it efficiently is what distinguishes it from other languages."60
clips/audio_981.wav|A hello world program that conforms to the C standard is also a valid C hello word program|A hello world program that conforms to the C standard is also a valid C hello word program
clips/audio_982.wav|The exact order of creation is not specified by the standard though there are some rules defined below to allow implementations some freedom in how to organize their implementation|The exact order of creation is not specified by the standard though there are some rules defined below to allow implementations some freedom in how to organize their implementation
clips/audio_983.wav|More formally, objects of this type have a lifespan that "shall last for the duration of the program".64|More formally, objects of this type have a lifespan that "shall last for the duration of the program".64
clips/audio_984.wav|First, "static initialization" is performed, and only after all static initialization is performed, "dynamic initialization" is performed|First, "static initialization" is performed, and only after all static initialization is performed, "dynamic initialization" is performed
clips/audio_985.wav|Member variables are created when the parent object is created|Member variables are created when the parent object is created
clips/audio_986.wav|Array members are initialized from 0 to the last member of the array in order|Array members are initialized from 0 to the last member of the array in order
clips/audio_987.wav|Member variables are destroyed when the parent object is destroyed in the reverse order of creation|Member variables are destroyed when the parent object is destroyed in the reverse order of creation
clips/audio_988.wav|If the parent is an "automatic object" then it will be destroyed when it goes out of scope which triggers the destruction of all its members.|If the parent is an "automatic object" then it will be destroyed when it goes out of scope which triggers the destruction of all its members.
clips/audio_989.wav|The C Core Guidelines advise against using new directly for creating dynamic objects in favor of smart pointers through make_uniqueT for single ownership and make_sharedT for reference-counted multiple ownership,68 which were introduced in C11.|The C Core Guidelines advise against using new directly for creating dynamic objects in favor of smart pointers through make_uniqueT for single ownership and make_sharedT for reference-counted multiple ownership,68 which were introduced in C11.
clips/audio_990.wav|Templates are aware of the semantics and type system of their companion language, as well as all compile-time type definitions, and can perform high-level operations including programmatic flow control based on evaluation of strictly type-checked parameters|Templates are aware of the semantics and type system of their companion language, as well as all compile-time type definitions, and can perform high-level operations including programmatic flow control based on evaluation of strictly type-checked parameters
clips/audio_991.wav|Macros are capable of conditional control over compilation based on predetermined criteria, but cannot instantiate new types, recurse, or perform type evaluation and in effect are limited to pre-compilation text-substitution and text-inclusionexclusion|Macros are capable of conditional control over compilation based on predetermined criteria, but cannot instantiate new types, recurse, or perform type evaluation and in effect are limited to pre-compilation text-substitution and text-inclusionexclusion
clips/audio_992.wav|In other words, macros can control compilation flow based on pre-defined symbols but cannot, unlike templates, independently instantiate new symbols|In other words, macros can control compilation flow based on pre-defined symbols but cannot, unlike templates, independently instantiate new symbols
clips/audio_993.wav|In addition, templates are a compile-time mechanism in C that is Turing-complete, meaning that any computation expressible by a computer program can be computed, in some form, by a template metaprogram before runtime.|In addition, templates are a compile-time mechanism in C that is Turing-complete, meaning that any computation expressible by a computer program can be computed, in some form, by a template metaprogram before runtime.
clips/audio_994.wav|After instantiation, the resulting code is equivalent to code written specifically for the passed arguments|After instantiation, the resulting code is equivalent to code written specifically for the passed arguments
clips/audio_995.wav|In this manner, templates provide a way to decouple generic, broadly applicable aspects of functions and classes encoded in templates from specific aspects encoded in template parameters without sacrificing performance due to abstraction.|In this manner, templates provide a way to decouple generic, broadly applicable aspects of functions and classes encoded in templates from specific aspects encoded in template parameters without sacrificing performance due to abstraction.
clips/audio_996.wav|One distinguishing feature of C classes compared to classes in other programming languages is support for deterministic destructors, which in turn provide support for the Resource Acquisition is Initialization RAII concept.|One distinguishing feature of C classes compared to classes in other programming languages is support for deterministic destructors, which in turn provide support for the Resource Acquisition is Initialization RAII concept.
clips/audio_997.wav|Encapsulation is the hiding of information to ensure that data structures and operators are used as intended and to make the usage model more obvious to the developer|Encapsulation is the hiding of information to ensure that data structures and operators are used as intended and to make the usage model more obvious to the developer
clips/audio_998.wav|Within a class, members can be declared as either public, protected, or private to explicitly enforce encapsulation|Within a class, members can be declared as either public, protected, or private to explicitly enforce encapsulation
clips/audio_999.wav|A public member of the class is accessible to any function|A public member of the class is accessible to any function
clips/audio_1000.wav|A private member is accessible only to functions that are members of that class and to functions and classes explicitly granted access permission by the class "friends"|A private member is accessible only to functions that are members of that class and to functions and classes explicitly granted access permission by the class "friends"
clips/audio_1001.wav|A protected member is accessible to members of classes that inherit from the class in addition to the class itself and any friends.|A protected member is accessible to members of classes that inherit from the class in addition to the class itself and any friends.
clips/audio_1002.wav|C supports this principle via member functions and friend functions, but it does not enforce it|C supports this principle via member functions and friend functions, but it does not enforce it
clips/audio_1003.wav|Inheritance allows one data type to acquire properties of other data types|Inheritance allows one data type to acquire properties of other data types
clips/audio_1004.wav|This access specifier determines whether unrelated and derived classes can access the inherited public and protected members of the base class|This access specifier determines whether unrelated and derived classes can access the inherited public and protected members of the base class
clips/audio_1005.wav|The other two forms are much less frequently used|The other two forms are much less frequently used
clips/audio_1006.wav|Virtual inheritance ensures that only one instance of a base class exists in the inheritance graph, avoiding some of the ambiguity problems of multiple inheritance.|Virtual inheritance ensures that only one instance of a base class exists in the inheritance graph, avoiding some of the ambiguity problems of multiple inheritance.
clips/audio_1007.wav|Some other languages, such as C or Java, accomplish something similar although more limited by allowing inheritance of multiple interfaces while restricting the number of base classes to one interfaces, unlike classes, provide only declarations of member functions, no implementation or member data|Some other languages, such as C or Java, accomplish something similar although more limited by allowing inheritance of multiple interfaces while restricting the number of base classes to one interfaces, unlike classes, provide only declarations of member functions, no implementation or member data
clips/audio_1008.wav|The member functions of such an abstract base class are normally explicitly defined in the derived class, not inherited implicitly|The member functions of such an abstract base class are normally explicitly defined in the derived class, not inherited implicitly
clips/audio_1009.wav|C virtual inheritance exhibits an ambiguity resolution feature called dominance.|C virtual inheritance exhibits an ambiguity resolution feature called dominance.
clips/audio_1010.wav|Almost all operators can be overloaded for user-defined types, with a few notable exceptions such as member access|Almost all operators can be overloaded for user-defined types, with a few notable exceptions such as member access
clips/audio_1011.wav|The rich set of overloadable operators is central to making user-defined types in C seem like built-in types.|The rich set of overloadable operators is central to making user-defined types in C seem like built-in types.
clips/audio_1012.wav|Overloading an operator does not change the precedence of calculations involving the operator, nor does it change the number of operands that the operator uses any operand may however be ignored by the operator, though it will be evaluated prior to execution|Overloading an operator does not change the precedence of calculations involving the operator, nor does it change the number of operands that the operator uses any operand may however be ignored by the operator, though it will be evaluated prior to execution
clips/audio_1013.wav|Overloaded "" and "" operators lose their short-circuit evaluation property.|Overloaded "" and "" operators lose their short-circuit evaluation property.
clips/audio_1014.wav|Compile-time polymorphism does not allow for certain run-time decisions, while runtime polymorphism typically incurs a performance penalty.|Compile-time polymorphism does not allow for certain run-time decisions, while runtime polymorphism typically incurs a performance penalty.
clips/audio_1015.wav|The functions are distinguished by the number or types of their formal parameters|The functions are distinguished by the number or types of their formal parameters
clips/audio_1016.wav|The type returned by the function is not used to distinguish overloaded functions and differing return types would result in a compile-time error message.|The type returned by the function is not used to distinguish overloaded functions and differing return types would result in a compile-time error message.
clips/audio_1017.wav|In many cases, specifying default arguments in a single function declaration is preferable to providing overloaded function definitions with different numbers of parameters.|In many cases, specifying default arguments in a single function declaration is preferable to providing overloaded function definitions with different numbers of parameters.
clips/audio_1018.wav|In particular, through the curiously recurring template pattern, it is possible to implement a form of static polymorphism that closely mimics the syntax for overriding virtual functions|In particular, through the curiously recurring template pattern, it is possible to implement a form of static polymorphism that closely mimics the syntax for overriding virtual functions
clips/audio_1019.wav|Upcasting, conversion to a more general type, can always be checkedperformed at compile-time via static_cast, as ancestral classes are specified in the derived class's interface, visible to all callers. dynamic_cast relies on run-time type information RTTI, metadata in the program that enables differentiating types and their relationships|Upcasting, conversion to a more general type, can always be checkedperformed at compile-time via static_cast, as ancestral classes are specified in the derived class's interface, visible to all callers. dynamic_cast relies on run-time type information RTTI, metadata in the program that enables differentiating types and their relationships
clips/audio_1020.wav|A given function is overridden when there exists no difference in the number or type of parameters between two or more definitions of that function|A given function is overridden when there exists no difference in the number or type of parameters between two or more definitions of that function
clips/audio_1021.wav|Virtual member functions or methods72 allow the most specific implementation of the function to be called, according to the actual run-time type of the object|Virtual member functions or methods72 allow the most specific implementation of the function to be called, according to the actual run-time type of the object
clips/audio_1022.wav|In addition to standard member functions, operator overloads and destructors can be virtual|In addition to standard member functions, operator overloads and destructors can be virtual
clips/audio_1023.wav|A member function can also be made "pure virtual" by appending it with  0 after the closing parenthesis and before the semicolon|A member function can also be made "pure virtual" by appending it with  0 after the closing parenthesis and before the semicolon
clips/audio_1024.wav|A program that attempts to create an object of a class with a pure virtual member function or inherited pure virtual member function is ill-formed.|A program that attempts to create an object of a class with a pure virtual member function or inherited pure virtual member function is ill-formed.
clips/audio_1025.wav|C provides support for anonymous functions, also known as lambda expressions, with the following form|C provides support for anonymous functions, also known as lambda expressions, with the following form
clips/audio_1026.wav|Since C20, the keyword template is optional for template parameters of lambda expressions|Since C20, the keyword template is optional for template parameters of lambda expressions
clips/audio_1027.wav|If the lambda takes no parameters, and no return type or other specifiers are used, the  can be omitted that is,|If the lambda takes no parameters, and no return type or other specifiers are used, the  can be omitted that is,
clips/audio_1028.wav|The return type of a lambda expression can be automatically inferred, if possible e.g.|The return type of a lambda expression can be automatically inferred, if possible e.g.
clips/audio_1029.wav|Such lambda expressions are defined in the standard as syntactic sugar for an unnamed function object.|Such lambda expressions are defined in the standard as syntactic sugar for an unnamed function object.
clips/audio_1030.wav|Exception handling is used to communicate the existence of a runtime problem or error from where it was detected to where the issue can be handled.73 It permits this to be done in a uniform manner and separately from the main code, while detecting all errors.74 Should an error occur, an exception is thrown raised, which is then caught by the nearest suitable exception handler|Exception handling is used to communicate the existence of a runtime problem or error from where it was detected to where the issue can be handled.73 It permits this to be done in a uniform manner and separately from the main code, while detecting all errors.74 Should an error occur, an exception is thrown raised, which is then caught by the nearest suitable exception handler
clips/audio_1031.wav|The exception causes the current scope to be exited, and also each outer scope propagation until a suitable handler is found, calling in turn the destructors of any objects in these exited scopes.75 At the same time, an exception is presented as an object carrying the data about the detected problem.76|The exception causes the current scope to be exited, and also each outer scope propagation until a suitable handler is found, calling in turn the destructors of any objects in these exited scopes.75 At the same time, an exception is presented as an object carrying the data about the detected problem.76
clips/audio_1032.wav|Some C style guides, such as Google's,77 LLVM's,78 and Qt's,79 forbid the usage of exceptions.|Some C style guides, such as Google's,77 LLVM's,78 and Qt's,79 forbid the usage of exceptions.
clips/audio_1033.wav|One such example is a critical component of an embedded system, where every operation must be guaranteed to complete within a specified amount of time|One such example is a critical component of an embedded system, where every operation must be guaranteed to complete within a specified amount of time
clips/audio_1034.wav|This cannot be determined with exceptions as no tools exist to determine the maximum time required for an exception to be handled.81|This cannot be determined with exceptions as no tools exist to determine the maximum time required for an exception to be handled.81
clips/audio_1035.wav|Also as with structs, the C enum keyword is combined with a typedef, so that instead of naming the type enum name, simply name it name|Also as with structs, the C enum keyword is combined with a typedef, so that instead of naming the type enum name, simply name it name
clips/audio_1036.wav|Another feature of scoped enumerations is that the enumerators do not leak, so usage requires prefixing with the name of the enumeration e.g., ColorRed for the first enumerator in the example below, unless a using enum declaration introduced in C20 has been used to bring the enumerators into the current scope|Another feature of scoped enumerations is that the enumerators do not leak, so usage requires prefixing with the name of the enumeration e.g., ColorRed for the first enumerator in the example below, unless a using enum declaration introduced in C20 has been used to bring the enumerators into the current scope
clips/audio_1037.wav|C programmers expect the latter on every major implementation of C it includes aggregate types vectors, lists, maps, sets, queues, stacks, arrays, tuples, algorithms find, for_each, binary_search, random_shuffle, etc., inputoutput facilities iostream, for reading from and writing to the console and files, filesystem library, localisation support, smart pointers for automatic memory management, regular expression support, multi-threading library, atomics support allowing a variable to be read or written to by at most one thread at a time without any external synchronisation, time utilities measurement, getting current time, etc., a system for converting error reporting that does not use C exceptions into C exceptions, a random number generator, and a slightly modified version of the C standard library to make it comply with the C type system.|C programmers expect the latter on every major implementation of C it includes aggregate types vectors, lists, maps, sets, queues, stacks, arrays, tuples, algorithms find, for_each, binary_search, random_shuffle, etc., inputoutput facilities iostream, for reading from and writing to the console and files, filesystem library, localisation support, smart pointers for automatic memory management, regular expression support, multi-threading library, atomics support allowing a variable to be read or written to by at most one thread at a time without any external synchronisation, time utilities measurement, getting current time, etc., a system for converting error reporting that does not use C exceptions into C exceptions, a random number generator, and a slightly modified version of the C standard library to make it comply with the C type system.
clips/audio_1038.wav|Useful tools provided by the STL include containers as the collections of objects such as vectors and lists, iterators that provide array-like access to containers, and algorithms that perform operations such as searching and sorting.|Useful tools provided by the STL include containers as the collections of objects such as vectors and lists, iterators that provide array-like access to containers, and algorithms that perform operations such as searching and sorting.
clips/audio_1039.wav|When he started with C, he finally found a language where it was possible to create generic algorithms e.g., STL sort that perform even better than, for example, the C standard library qsort, thanks to C features like using inlining and compile-time binding instead of function pointers|When he started with C, he finally found a language where it was possible to create generic algorithms e.g., STL sort that perform even better than, for example, the C standard library qsort, thanks to C features like using inlining and compile-time binding instead of function pointers
clips/audio_1040.wav|The standard does not refer to it as "STL", as it is merely a part of the standard library, but the term is still widely used to distinguish it from the rest of the standard library inputoutput streams, internationalization, diagnostics, the C library subset, etc..82|The standard does not refer to it as "STL", as it is merely a part of the standard library, but the term is still widely used to distinguish it from the rest of the standard library inputoutput streams, internationalization, diagnostics, the C library subset, etc..82
clips/audio_1041.wav|Most C compilers, and all major ones, provide a standards-conforming implementation of the C standard library.|Most C compilers, and all major ones, provide a standards-conforming implementation of the C standard library.
clips/audio_1042.wav|The C Core Guidelines83 are an initiative led by Bjarne Stroustrup, the inventor of C, and Herb Sutter, the convener and chair of the C ISO Working Group, to help programmers write 'Modern C' by using best practices for the language standards C11 and newer, and to help developers of compilers and static checking tools to create rules for catching bad programming practices.|The C Core Guidelines83 are an initiative led by Bjarne Stroustrup, the inventor of C, and Herb Sutter, the convener and chair of the C ISO Working Group, to help programmers write 'Modern C' by using best practices for the language standards C11 and newer, and to help developers of compilers and static checking tools to create rules for catching bad programming practices.
clips/audio_1043.wav|The Core Guidelines were announced84 in the opening keynote at CPPCon 2015.|The Core Guidelines were announced84 in the opening keynote at CPPCon 2015.
clips/audio_1044.wav|The Guidelines are accompanied by the Guideline Support Library GSL,85 a header only library of types and functions to implement the Core Guidelines and static checker tools for enforcing Guideline rules.86|The Guidelines are accompanied by the Guideline Support Library GSL,85 a header only library of types and functions to implement the Core Guidelines and static checker tools for enforcing Guideline rules.86
clips/audio_1045.wav|On the other hand, C99 introduced a number of new features that C did not support that were incompatible or redundant in C, such as variable-length arrays, native complex-number types however, the stdcomplex class in the C standard library provides similar functionality, although not code-compatible, designated initializers, compound literals, and the restrict keyword.89 Some of the C99-introduced features were included in the subsequent version of the C standard, C11 out of those which were not redundant.909192 However, the C11 standard introduces new incompatibilities, such as disallowing assignment of a string literal to a character pointer, which remains valid C.|On the other hand, C99 introduced a number of new features that C did not support that were incompatible or redundant in C, such as variable-length arrays, native complex-number types however, the stdcomplex class in the C standard library provides similar functionality, although not code-compatible, designated initializers, compound literals, and the restrict keyword.89 Some of the C99-introduced features were included in the subsequent version of the C standard, C11 out of those which were not redundant.909192 However, the C11 standard introduces new incompatibilities, such as disallowing assignment of a string literal to a character pointer, which remains valid C.
clips/audio_1046.wav|One of the most often criticized points of C is its perceived complexity as a language, with the criticism that a large number of non-orthogonal features in practice necessitates restricting code to a subset of C, thus eschewing the readability benefits of common style and idioms|One of the most often criticized points of C is its perceived complexity as a language, with the criticism that a large number of non-orthogonal features in practice necessitates restricting code to a subset of C, thus eschewing the readability benefits of common style and idioms
clips/audio_1047.wav|And it's obviously built by a committee. Stroustrup campaigned for years and years and years, way beyond any sort of technical contributions he made to the language, to get it adopted and used|And it's obviously built by a committee. Stroustrup campaigned for years and years and years, way beyond any sort of technical contributions he made to the language, to get it adopted and used
clips/audio_1048.wav|C has been enormously influential|C has been enormously influential
clips/audio_1049.wav|Structured Query Language S Q L pronounced S-Q-L historically "sequel"45 is a domain-specific language used to manage data, especially in a relational database management system RDBMS|Structured Query Language S Q L pronounced S-Q-L historically "sequel"45 is a domain-specific language used to manage data, especially in a relational database management system RDBMS
clips/audio_1050.wav|Introduced in the 1970s, S Q L offered two main advantages over older readwrite A P Is such as ISAM or VSAM|Introduced in the 1970s, S Q L offered two main advantages over older readwrite A P Is such as ISAM or VSAM
clips/audio_1051.wav|Originally based upon relational algebra and tuple relational calculus, S Q L consists of many types of statements,6 which may be informally classed as sublanguages, commonly Data query Language DQL, Data Definition Language DDL, Data Control Language DCL, and Data Manipulation Language DML.7|Originally based upon relational algebra and tuple relational calculus, S Q L consists of many types of statements,6 which may be informally classed as sublanguages, commonly Data query Language DQL, Data Definition Language DDL, Data Control Language DCL, and Data Manipulation Language DML.7
clips/audio_1052.wav|The scope of S Q L includes data query, data manipulation insert, update, and delete, data definition schema creation and modification, and data access control|The scope of S Q L includes data query, data manipulation insert, update, and delete, data definition schema creation and modification, and data access control
clips/audio_1053.wav|Although S Q L is essentially a declarative language 4GL, it also includes procedural elements.|Although S Q L is essentially a declarative language 4GL, it also includes procedural elements.
clips/audio_1054.wav|S Q L was one of the first commercial languages to use Edgar F|S Q L was one of the first commercial languages to use Edgar F
clips/audio_1055.wav|The model was described in his influential 1970 paper, "A Relational Model of Data for Large Shared Data Banks".8  Despite not entirely adhering to the relational model as described by Codd, S Q L became the most widely used database language.910|The model was described in his influential 1970 paper, "A Relational Model of Data for Large Shared Data Banks".8  Despite not entirely adhering to the relational model as described by Codd, S Q L became the most widely used database language.910
clips/audio_1056.wav|S Q L became a standard of the American National Standards Institute ANSI in 1986 and of the International Organization for Standardization ISO in 1987.11 Since then, the standard has been revised multiple times to include a larger set of features and incorporate common extensions|S Q L became a standard of the American National Standards Institute ANSI in 1986 and of the International Organization for Standardization ISO in 1987.11 Since then, the standard has been revised multiple times to include a larger set of features and incorporate common extensions
clips/audio_1057.wav|Despite the existence of standards, virtually no implementations in existence adhere to it fully, and most S Q L code requires at least some changes before being ported to different database systems.|Despite the existence of standards, virtually no implementations in existence adhere to it fully, and most S Q L code requires at least some changes before being ported to different database systems.
clips/audio_1058.wav|S Q L was initially developed at IBM by Donald D|S Q L was initially developed at IBM by Donald D
clips/audio_1059.wav|Chamberlin and Raymond F|Chamberlin and Raymond F
clips/audio_1060.wav|Chamberlin and Boyce's first attempt at a relational database language was SQUARE Specifying Queries in A Relational Environment, but it was difficult to use due to subscriptsuperscript notation|Chamberlin and Boyce's first attempt at a relational database language was SQUARE Specifying Queries in A Relational Environment, but it was difficult to use due to subscriptsuperscript notation
clips/audio_1061.wav|After moving to the San Jose Research Laboratory in 1973, they began work on a sequel to SQUARE.12 The original name SEQUEL,  which is widely regarded as a pun on QUEL, the query language of Ingres,14 was later changed to S Q L dropping the vowels because "SEQUEL" was a trademark of the UK-based Hawker Siddeley Dynamics Engineering Limited company.15  The label S Q L later became the acronym for Structured Query Language.|After moving to the San Jose Research Laboratory in 1973, they began work on a sequel to SQUARE.12 The original name SEQUEL,  which is widely regarded as a pun on QUEL, the query language of Ingres,14 was later changed to S Q L dropping the vowels because "SEQUEL" was a trademark of the UK-based Hawker Siddeley Dynamics Engineering Limited company.15  The label S Q L later became the acronym for Structured Query Language.
clips/audio_1062.wav|After testing S Q L at customer test sites to determine the usefulness and practicality of the system, IBM began developing commercial products based on their System R prototype, including System38, S Q LDS, and IBM Db2, which were commercially available in 1979, 1981, and 1983, respectively.16|After testing S Q L at customer test sites to determine the usefulness and practicality of the system, IBM began developing commercial products based on their System R prototype, including System38, S Q LDS, and IBM Db2, which were commercially available in 1979, 1981, and 1983, respectively.16
clips/audio_1063.wav|now Oracle Corporation saw the potential of the concepts described by Codd, Chamberlin, and Boyce, and developed their own S Q L-based RDBMS with aspirations of selling it to the U.S|now Oracle Corporation saw the potential of the concepts described by Codd, Chamberlin, and Boyce, and developed their own S Q L-based RDBMS with aspirations of selling it to the U.S
clips/audio_1064.wav|In June 1979, Relational Software introduced one of the first commercially available implementations of S Q L, Oracle V2 Version2 for VAX computers.|In June 1979, Relational Software introduced one of the first commercially available implementations of S Q L, Oracle V2 Version2 for VAX computers.
clips/audio_1065.wav|By 1986, ANSI and ISO standard groups officially adopted the standard "Database Language S Q L" language definition|By 1986, ANSI and ISO standard groups officially adopted the standard "Database Language S Q L" language definition
clips/audio_1066.wav|The S Q L language is subdivided into several language elements, including|The S Q L language is subdivided into several language elements, including
clips/audio_1067.wav|S Q L is designed for a specific purpose to query data contained in a relational database|S Q L is designed for a specific purpose to query data contained in a relational database
clips/audio_1068.wav|S Q L is a set-based, declarative programming language, not an imperative programming language like C or BASIC|S Q L is a set-based, declarative programming language, not an imperative programming language like C or BASIC
clips/audio_1069.wav|However, extensions to Standard S Q L add procedural programming language functionality, such as control-of-flow constructs.|However, extensions to Standard S Q L add procedural programming language functionality, such as control-of-flow constructs.
clips/audio_1070.wav|In addition to the standard S Q LPSM extensions and proprietary S Q L extensions, procedural and object-oriented programmability is available on many S Q L platforms via DBMS integration with other languages|In addition to the standard S Q LPSM extensions and proprietary S Q L extensions, procedural and object-oriented programmability is available on many S Q L platforms via DBMS integration with other languages
clips/audio_1071.wav|The S Q L standard defines S Q LJRT extensions S Q L Routines and Types for the Java Programming Language to support Java code in S Q L databases|The S Q L standard defines S Q LJRT extensions S Q L Routines and Types for the Java Programming Language to support Java code in S Q L databases
clips/audio_1072.wav|Microsoft S Q L Server two hundred5 uses the S Q LCLR S Q L Server Common Language Runtime to host managed .NET assemblies in the database, while prior versions of S Q L Server were restricted to unmanaged extended stored procedures primarily written in C|Microsoft S Q L Server two hundred5 uses the S Q LCLR S Q L Server Common Language Runtime to host managed .NET assemblies in the database, while prior versions of S Q L Server were restricted to unmanaged extended stored procedures primarily written in C
clips/audio_1073.wav|PostgreS Q L lets users write functions in a wide variety of languagesincluding Perl, Python, Tcl, Java-Script PLV8 and C.19|PostgreS Q L lets users write functions in a wide variety of languagesincluding Perl, Python, Tcl, Java-Script PLV8 and C.19
clips/audio_1074.wav|S Q L implementations are incompatible between vendors and do not necessarily completely follow standards|S Q L implementations are incompatible between vendors and do not necessarily completely follow standards
clips/audio_1075.wav|PostgreS Q L20 and Mimer S Q L21 strive for standards compliance, though PostgreS Q L does not adhere to the standard in all cases|PostgreS Q L20 and Mimer S Q L21 strive for standards compliance, though PostgreS Q L does not adhere to the standard in all cases
clips/audio_1076.wav|For example, the folding of unquoted names to lower case in PostgreS Q L is incompatible with the S Q L standard,22 which says that unquoted names should be folded to upper case.23 Thus, according to the standard, Foo should be equivalent to FOO, not foo.|For example, the folding of unquoted names to lower case in PostgreS Q L is incompatible with the S Q L standard,22 which says that unquoted names should be folded to upper case.23 Thus, according to the standard, Foo should be equivalent to FOO, not foo.
clips/audio_1077.wav|Popular implementations of S Q L commonly omit support for basic features of Standard S Q L, such as the DATE or TIME data types|Popular implementations of S Q L commonly omit support for basic features of Standard S Q L, such as the DATE or TIME data types
clips/audio_1078.wav|The most obvious such examples, and incidentally the most popular commercial and proprietary S Q L DBMSs, are Oracle whose DATE behaves as DATETIME,2425 and lacks a TIME type26 and MS S Q L Server before the two hundred8 version|The most obvious such examples, and incidentally the most popular commercial and proprietary S Q L DBMSs, are Oracle whose DATE behaves as DATETIME,2425 and lacks a TIME type26 and MS S Q L Server before the two hundred8 version
clips/audio_1079.wav|As a result, S Q L code can rarely be ported between database systems without modifications.|As a result, S Q L code can rarely be ported between database systems without modifications.
clips/audio_1080.wav|S Q L was adopted as a standard by the ANSI in 1986 as S Q L-8628 and the ISO in 1987.11 It is maintained by ISOIEC JTC 1, Information technology, Subcommittee SC 32, Data management and interchange.|S Q L was adopted as a standard by the ANSI in 1986 as S Q L-8628 and the ISO in 1987.11 It is maintained by ISOIEC JTC 1, Information technology, Subcommittee SC 32, Data management and interchange.
clips/audio_1081.wav|Until 1996, the National Institute of Standards and Technology NIST data-management standards program certified S Q L DBMS compliance with the S Q L standard|Until 1996, the National Institute of Standards and Technology NIST data-management standards program certified S Q L DBMS compliance with the S Q L standard
clips/audio_1082.wav|The original standard declared that the official pronunciation for "S Q L" was an initialism skjul "ess cue el".9 Regardless, many English-speaking database professionals including Donald Chamberlin himself30 use the acronym-like pronunciation of sikwl "sequel",31 mirroring the language's prerelease development name, "SEQUEL".131530 The S Q L standard has gone through a number of revisions|The original standard declared that the official pronunciation for "S Q L" was an initialism skjul "ess cue el".9 Regardless, many English-speaking database professionals including Donald Chamberlin himself30 use the acronym-like pronunciation of sikwl "sequel",31 mirroring the language's prerelease development name, "SEQUEL".131530 The S Q L standard has gone through a number of revisions
clips/audio_1083.wav|ISOIEC 9075 is complemented by ISOIEC 13249 S Q L Multimedia and Application Packages and some Technical reports.|ISOIEC 9075 is complemented by ISOIEC 13249 S Q L Multimedia and Application Packages and some Technical reports.
clips/audio_1084.wav|A distinction should be made between alternatives to S Q L as a language, and alternatives to the relational model itself|A distinction should be made between alternatives to S Q L as a language, and alternatives to the relational model itself
clips/audio_1085.wav|Below are proposed relational alternatives to the S Q L language|Below are proposed relational alternatives to the S Q L language
clips/audio_1086.wav|See navigational database and NoS Q L for alternatives to the relational model.|See navigational database and NoS Q L for alternatives to the relational model.
clips/audio_1087.wav|DRDA enables network-connected relational databases to cooperate to fulfill S Q L requests.4142|DRDA enables network-connected relational databases to cooperate to fulfill S Q L requests.4142
clips/audio_1088.wav|An interactive user or program can issue S Q L statements to a local RDB and receive tables of data and status indicators in reply from remote RDBs|An interactive user or program can issue S Q L statements to a local RDB and receive tables of data and status indicators in reply from remote RDBs
clips/audio_1089.wav|S Q L statements can also be compiled and stored in remote RDBs as packages and then invoked by package name|S Q L statements can also be compiled and stored in remote RDBs as packages and then invoked by package name
clips/audio_1090.wav|Distributed S Q L processing ala DRDA is distinctive from contemporary distributed S Q L databases.|Distributed S Q L processing ala DRDA is distinctive from contemporary distributed S Q L databases.
clips/audio_1091.wav|S Q L deviates in several ways from its theoretical foundation, the relational model and its tuple calculus|S Q L deviates in several ways from its theoretical foundation, the relational model and its tuple calculus
clips/audio_1092.wav|In that model, a table is a set of tuples, while in S Q L, tables and query results are lists of rows the same row may occur multiple times, and the order of rows can be employed in queries e.g., in the LIMIT clause. Critics argue that S Q L should be replaced with a language that returns strictly to the original foundation for example, see The Third Manifesto by Hugh Darwen and C.J|In that model, a table is a set of tuples, while in S Q L, tables and query results are lists of rows the same row may occur multiple times, and the order of rows can be employed in queries e.g., in the LIMIT clause. Critics argue that S Q L should be replaced with a language that returns strictly to the original foundation for example, see The Third Manifesto by Hugh Darwen and C.J
clips/audio_1093.wav|The lack of sum types has been described as a roadblock to full use of S Q L's user-defined types|The lack of sum types has been described as a roadblock to full use of S Q L's user-defined types
clips/audio_1094.wav|Jay-son support, for example, needed to be added by a new standard in 2016.43|Jay-son support, for example, needed to be added by a new standard in 2016.43
clips/audio_1095.wav|The concept of Nulls enforces the 3-valued-logic in S Q L, which is a concrete implementation of the general 3-valued logic.12|The concept of Nulls enforces the 3-valued-logic in S Q L, which is a concrete implementation of the general 3-valued logic.12
clips/audio_1096.wav|Another popular criticism is that it allows duplicate rows, making integration with languages such as Python, whose data types might make accurately representing the data difficult,12 in terms of parsing and by the absence of modularity|Another popular criticism is that it allows duplicate rows, making integration with languages such as Python, whose data types might make accurately representing the data difficult,12 in terms of parsing and by the absence of modularity
clips/audio_1097.wav|In a sense similar to objectrelational impedance mismatch, a mismatch occurs between the declarative S Q L language and the procedural languages in which S Q L is typically embedded.citation needed|In a sense similar to objectrelational impedance mismatch, a mismatch occurs between the declarative S Q L language and the procedural languages in which S Q L is typically embedded.citation needed
clips/audio_1098.wav|The S Q L standard defines three kinds of data types chapter 4.1.1 of S Q LFoundation|The S Q L standard defines three kinds of data types chapter 4.1.1 of S Q LFoundation
clips/audio_1099.wav|Oh-Auth short for open authorization12 is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords.34 This mechanism is used by companies such as Amazon,5 Google, Meta Platforms, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.|Oh-Auth short for open authorization12 is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords.34 This mechanism is used by companies such as Amazon,5 Google, Meta Platforms, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.
clips/audio_1100.wav|Generally, the Oh-Auth protocol provides a way for resource owners to provide a client application with secure delegated access to server resources|Generally, the Oh-Auth protocol provides a way for resource owners to provide a client application with secure delegated access to server resources
clips/audio_1101.wav|Designed specifically to work with Hypertext Transfer Protocol H T T P, Oh-Auth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner|Designed specifically to work with Hypertext Transfer Protocol H T T P, Oh-Auth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner
clips/audio_1102.wav|Oh-Auth began in November two hundred6 when Blaine Cook was developing the Twitter OpenID implementation|Oh-Auth began in November two hundred6 when Blaine Cook was developing the Twitter OpenID implementation
clips/audio_1103.wav|Meanwhile, Ma.gnolia needed a solution to allow its members with OpenIDs to authorize Dashboard Widgets to access their service|Meanwhile, Ma.gnolia needed a solution to allow its members with OpenIDs to authorize Dashboard Widgets to access their service
clips/audio_1104.wav|Cook, Chris Messina and Larry Halff from Magnolia met with David Recordon to discuss using OpenID with the Twitter and Magnolia A P Is to delegate authentication|Cook, Chris Messina and Larry Halff from Magnolia met with David Recordon to discuss using OpenID with the Twitter and Magnolia A P Is to delegate authentication
clips/audio_1105.wav|They concluded that there were no open standards for A P I access delegation.6|They concluded that there were no open standards for A P I access delegation.6
clips/audio_1106.wav|The Oh-Auth discussion group was created in April two hundred7, for a small group of implementers to write the draft proposal for an open protocol|The Oh-Auth discussion group was created in April two hundred7, for a small group of implementers to write the draft proposal for an open protocol
clips/audio_1107.wav|DeWitt Clinton from Google learned of the Oh-Auth project, and expressed his interest in supporting the effort|DeWitt Clinton from Google learned of the Oh-Auth project, and expressed his interest in supporting the effort
clips/audio_1108.wav|Eran Hammer joined and coordinated the many Oh-Auth contributions creating a more formal specification|Eran Hammer joined and coordinated the many Oh-Auth contributions creating a more formal specification
clips/audio_1109.wav|On 4 December two hundred7, the Oh-Auth Core 1.0 final draft was released.7|On 4 December two hundred7, the Oh-Auth Core 1.0 final draft was released.7
clips/audio_1110.wav|At the 73rd Internet Engineering Task Force IETF meeting in Minneapolis in November two hundred8, an Oh-Auth BoF was held to discuss bringing the protocol into the IETF for further standardization work|At the 73rd Internet Engineering Task Force IETF meeting in Minneapolis in November two hundred8, an Oh-Auth BoF was held to discuss bringing the protocol into the IETF for further standardization work
clips/audio_1111.wav|The event was well attended and there was wide support for formally chartering an Oh-Auth working group within the IETF.|The event was well attended and there was wide support for formally chartering an Oh-Auth working group within the IETF.
clips/audio_1112.wav|The Oh-Auth 1.0 protocol was published as RFC 5849, an informational Request for Comments, in April 2010|The Oh-Auth 1.0 protocol was published as RFC 5849, an informational Request for Comments, in April 2010
clips/audio_1113.wav|Since 31 August 2010, all third party Twitter applications have been required to use Oh-Auth.8|Since 31 August 2010, all third party Twitter applications have been required to use Oh-Auth.8
clips/audio_1114.wav|The Oh-Auth 2.0 framework was published considering additional use cases and extensibility requirements gathered from the wider IETF community|The Oh-Auth 2.0 framework was published considering additional use cases and extensibility requirements gathered from the wider IETF community
clips/audio_1115.wav|Albeit being built on the Oh-Auth 1.0 deployment experience, Oh-Auth 2.0 is not backwards compatible with Oh-Auth 1.0|Albeit being built on the Oh-Auth 1.0 deployment experience, Oh-Auth 2.0 is not backwards compatible with Oh-Auth 1.0
clips/audio_1116.wav|Oh-Auth 2.0 was published as RFC 6749 and the Bearer Token Usageclarification needed as RFC 6750, both standards track Requests for Comments, in October 2012.29|Oh-Auth 2.0 was published as RFC 6749 and the Bearer Token Usageclarification needed as RFC 6750, both standards track Requests for Comments, in October 2012.29
clips/audio_1117.wav|The Oh-Auth 2.1 Authorization Framework is in draft stage and consolidates the functionality in the RFCs Oh-Auth 2.0, Oh-Auth 2.0 for Native Apps, Proof Key for Code Exchange, Oh-Auth 2.0 for Browser-Based Apps, Oh-Auth Security Best Current and Bearer Token Usage.10|The Oh-Auth 2.1 Authorization Framework is in draft stage and consolidates the functionality in the RFCs Oh-Auth 2.0, Oh-Auth 2.0 for Native Apps, Proof Key for Code Exchange, Oh-Auth 2.0 for Browser-Based Apps, Oh-Auth Security Best Current and Bearer Token Usage.10
clips/audio_1118.wav|It affects the Oh-Auth authorization flow also known as "3-legged Oh-Auth" in Oh-Auth Core 1.0 Section 6.11 Version 1.0a of the Oh-Auth Core protocol was issued to address this issue.12|It affects the Oh-Auth authorization flow also known as "3-legged Oh-Auth" in Oh-Auth Core 1.0 Section 6.11 Version 1.0a of the Oh-Auth Core protocol was issued to address this issue.12
clips/audio_1119.wav|In January 2013, the Internet Engineering Task Force published a threat model for Oh-Auth 2.0.13 Among the threats outlined is one called "Open Redirector" in early 2014, a variant of this was described under the name "Covert Redirect" by Wang Jing.14151617|In January 2013, the Internet Engineering Task Force published a threat model for Oh-Auth 2.0.13 Among the threats outlined is one called "Open Redirector" in early 2014, a variant of this was described under the name "Covert Redirect" by Wang Jing.14151617
clips/audio_1120.wav|Oh-Auth 2.0 has been analyzed using formal web protocol analysis|Oh-Auth 2.0 has been analyzed using formal web protocol analysis
clips/audio_1121.wav|This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server AS Mix-Up Attack.18 This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for Oh-Auth 2.0.19 Assuming a fix against the AS Mix-Up Attack in place, the security of Oh-Auth 2.0 has been proven under strong attacker models using formal analysis.18|This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server AS Mix-Up Attack.18 This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for Oh-Auth 2.0.19 Assuming a fix against the AS Mix-Up Attack in place, the security of Oh-Auth 2.0 has been proven under strong attacker models using formal analysis.18
clips/audio_1122.wav|One implementation of Oh-Auth 2.0 with numerous security flaws has been exposed.20|One implementation of Oh-Auth 2.0 with numerous security flaws has been exposed.20
clips/audio_1123.wav|In April and May 2017, about one million users of Gmail less than 0.1 of users as of May 2017 were targeted by an Oh-Auth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs.21 Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called "Google Apps" to access their "email account, contacts and online documents".21 Within "approximately one hour",21 the phishing attack was stopped by Google, who advised those who had given "Google Apps" access to their email to revoke such access and change their passwords.|In April and May 2017, about one million users of Gmail less than 0.1 of users as of May 2017 were targeted by an Oh-Auth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs.21 Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called "Google Apps" to access their "email account, contacts and online documents".21 Within "approximately one hour",21 the phishing attack was stopped by Google, who advised those who had given "Google Apps" access to their email to revoke such access and change their passwords.
clips/audio_1124.wav|In the draft of Oh-Auth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds ofOh-Auth clients, including web applications and other confidentialclients in order to prevent malicious browser extensions from performing Oh-Auth 2.0 code injection attacks.10|In the draft of Oh-Auth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds ofOh-Auth clients, including web applications and other confidentialclients in order to prevent malicious browser extensions from performing Oh-Auth 2.0 code injection attacks.10
clips/audio_1125.wav|Oh-Auth framework specifies several grant types for different use cases|Oh-Auth framework specifies several grant types for different use cases
clips/audio_1126.wav|Some of the most common Oh-Auth grant types are22|Some of the most common Oh-Auth grant types are22
clips/audio_1127.wav|Facebook's Graph A P I only supports Oh-Auth 2.0.23 Google supports Oh-Auth 2.0 as the recommended authorization mechanism for all of its A P Is.24 Microsoft also supports Oh-Auth 2.0 for various A P Is and its Azure Active Directory service,25 which is used to secure many Microsoft and third party A P Is.|Facebook's Graph A P I only supports Oh-Auth 2.0.23 Google supports Oh-Auth 2.0 as the recommended authorization mechanism for all of its A P Is.24 Microsoft also supports Oh-Auth 2.0 for various A P Is and its Azure Active Directory service,25 which is used to secure many Microsoft and third party A P Is.
clips/audio_1128.wav|Oh-Auth can be used as an authorizing mechanism to access secured RSSAtom feeds|Oh-Auth can be used as an authorizing mechanism to access secured RSSAtom feeds
clips/audio_1129.wav|Access to RSSATOM feeds that require authentication has always been an issue|Access to RSSATOM feeds that require authentication has always been an issue
clips/audio_1130.wav|Instead, three-legged Oh-Auth would have been used to authorize that RSS client to access the feed from the Google Site.|Instead, three-legged Oh-Auth would have been used to authorize that RSS client to access the feed from the Google Site.
clips/audio_1131.wav|Oh-Auth is a service that is complementary to and distinct from OpenID|Oh-Auth is a service that is complementary to and distinct from OpenID
clips/audio_1132.wav|Oh-Auth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization|Oh-Auth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization
clips/audio_1133.wav|However, Oh-Auth is directly related to OpenID Connect OIDC, since OIDC is an authentication layer built on top of Oh-Auth 2.0|However, Oh-Auth is directly related to OpenID Connect OIDC, since OIDC is an authentication layer built on top of Oh-Auth 2.0
clips/audio_1134.wav|Oh-Auth is also unrelated to XACML, which is an authorization policy standard|Oh-Auth is also unrelated to XACML, which is an authorization policy standard
clips/audio_1135.wav|Oh-Auth can be used in conjunction with XACML, where Oh-Auth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies e.g., managers can view documents in their region.|Oh-Auth can be used in conjunction with XACML, where Oh-Auth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies e.g., managers can view documents in their region.
clips/audio_1136.wav|Oh-Auth is an authorization protocol, rather than an authentication protocol|Oh-Auth is an authorization protocol, rather than an authentication protocol
clips/audio_1137.wav|Using Oh-Auth on its own as an authentication method may be referred to as pseudo-authentication.26 The following diagrams highlight the differences between using OpenID specifically designed as an authentication protocol and Oh-Auth for authorization.|Using Oh-Auth on its own as an authentication method may be referred to as pseudo-authentication.26 The following diagrams highlight the differences between using OpenID specifically designed as an authentication protocol and Oh-Auth for authorization.
clips/audio_1138.wav|The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity while in the Oh-Auth authorization use case, the identity provider is also an A P I provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's A P Is, on the user's behalf|The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity while in the Oh-Auth authorization use case, the identity provider is also an A P I provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's A P Is, on the user's behalf
clips/audio_1139.wav|The access token acts as a kind of "valet key" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those A P Is.|The access token acts as a kind of "valet key" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those A P Is.
clips/audio_1140.wav|Because the identity provider typically but not always authenticates the user as part of the process of granting an Oh-Auth access token, it is tempting to view a successful Oh-Auth access token request as an authentication method itself|Because the identity provider typically but not always authenticates the user as part of the process of granting an Oh-Auth access token, it is tempting to view a successful Oh-Auth access token request as an authentication method itself
clips/audio_1141.wav|However, because Oh-Auth was not designed with this use case in mind, making this assumption can lead to major security flaws.27|However, because Oh-Auth was not designed with this use case in mind, making this assumption can lead to major security flaws.27
clips/audio_1142.wav|XACML and Oh-Auth can be combined to deliver a more comprehensive approach to authorization|XACML and Oh-Auth can be combined to deliver a more comprehensive approach to authorization
clips/audio_1143.wav|Oh-Auth does not provide a policy language with which to define access control policies|Oh-Auth does not provide a policy language with which to define access control policies
clips/audio_1144.wav|Where Oh-Auth focuses on delegated access I, the user, grant Twitter access to my Facebook wall, and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context who, what, where, when, how|Where Oh-Auth focuses on delegated access I, the user, grant Twitter access to my Facebook wall, and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context who, what, where, when, how
clips/audio_1145.wav|XACML provides more fine-grained access control than Oh-Auth does|XACML provides more fine-grained access control than Oh-Auth does
clips/audio_1146.wav|Oh-Auth is limited in granularity to the coarse functionality the scopes exposed by the target service|Oh-Auth is limited in granularity to the coarse functionality the scopes exposed by the target service
clips/audio_1147.wav|As a result, it often makes sense to combine Oh-Auth and XACML together where Oh-Auth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.|As a result, it often makes sense to combine Oh-Auth and XACML together where Oh-Auth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.
clips/audio_1148.wav|Lastly, XACML can work transparently across multiple stacks A P Is, web SSO, ESBs, home-grown apps, databases...|Lastly, XACML can work transparently across multiple stacks A P Is, web SSO, ESBs, home-grown apps, databases...
clips/audio_1149.wav|Oh-Auth focuses exclusively on H T T P-based apps.|Oh-Auth focuses exclusively on H T T P-based apps.
clips/audio_1150.wav|Eran Hammer resigned from his role of lead author for the Oh-Auth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012|Eran Hammer resigned from his role of lead author for the Oh-Auth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012
clips/audio_1151.wav|"What is now offered is a blueprint for an authorization protocol", he noted, "that is the enterprise way", providing a "whole new frontier to sell consulting services and integration solutions".28 In comparing Oh-Auth 2.0 with Oh-Auth 1.0, Hammer points out that it has become "more complex, less interoperable, less useful, more incomplete, and most importantly, less secure"|"What is now offered is a blueprint for an authorization protocol", he noted, "that is the enterprise way", providing a "whole new frontier to sell consulting services and integration solutions".28 In comparing Oh-Auth 2.0 with Oh-Auth 1.0, Hammer points out that it has become "more complex, less interoperable, less useful, more incomplete, and most importantly, less secure"
clips/audio_1152.wav|David Harris, author of the email client Pegasus Mail, has criticised Oh-Auth 2.0 as "an absolute dog's breakfast", requiring developers to write custom modules specific to each service Gmail, Microsoft Mail services, etc., and to register specifically with them.29|David Harris, author of the email client Pegasus Mail, has criticised Oh-Auth 2.0 as "an absolute dog's breakfast", requiring developers to write custom modules specific to each service Gmail, Microsoft Mail services, etc., and to register specifically with them.29
