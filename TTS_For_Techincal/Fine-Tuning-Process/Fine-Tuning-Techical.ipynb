{"cells":[{"cell_type":"markdown","metadata":{},"source":["# FINE-TUNING XTTS-v2 #"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Your Dataset:\n","\n","\n","### Dataset:\n","The dataset is generated using scrapping Techincal Blogs and Documentation by pre-processing the scrapped data in order to achieve clear and concise pronounciation,accuracy etc.\n","\n","### Preparing your own Data:\n","Simply discard any audio that is significantly worse quality than the rest. Examples of unpromising source audio include: constant background noise (e.g., coughing, clapping, laughter), excessive clipping in waveform view of Audacity, poor quality recording with constant whine/noise/etc. .\n","\n","### Making an LJSpeech Style Dataset:\n","The format for LJSpeech is a dir that contains two things: a metadata.csv file and a dir called 'wavs' that contains your voice recordings. Each line of the metadata.csv file includes:\n","\n","1. The name of an audio file\n","2. The text for that file. E.g., \"Jane eyre by Charlotte Bronte. Chapter 1.\"\n","3. The normalised text. E.g., \"Jane eyre by Charlotte Bronte. Chapter one.\"\n","\n","\n","\n","### Note on Model Performance:\n","Some degree of repetition/mushy mouth sounds seems to be inherent to the model. Even the pre-trained voices that comes packaged with TTS suffer from this problem to a small extent. There are two ways I'm aware of to improve your performance (these are already covered in other parts of this/my other notebook, but I'm putting it here again since it's pretty important):\n","\n","1. Improve the quality of your training data. Cull problematic items. Get more training data if your dataset is really small.\n","2. The model does not generalise well to unseen sequence lengths. If you only fine-tune on 10s long audio clips and then try to produce a 1s clip at inference time, it will probably struggle. \n","Make sure you have a good distribution of training lengths. Note that when you try to generate audio from a long text string, *this program is automatically splitting that long string of text into several shorter strings*, because the model cannot generate sequences of arbitrary length. If you are suffering from garbled/repetitious outputs, then I recommend putting some print statements in the 'split_sentence\" function in TTS.tts.layers.xtts.tokenizer. This will show you how your long text is being split up. If you see that your bad outputs are only occuring when the model is trying to generate audio for very short sequences or very long sequences, then you know what needs to be addressed. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:36:50.639432Z","iopub.status.busy":"2024-10-12T06:36:50.638706Z","iopub.status.idle":"2024-10-12T06:38:48.015973Z","shell.execute_reply":"2024-10-12T06:38:48.014970Z","shell.execute_reply.started":"2024-10-12T06:36:50.639389Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/coqui-ai/TTS\n","  Cloning https://github.com/coqui-ai/TTS to /tmp/pip-req-build-bqvkm00r\n","  Running command git clone --filter=blob:none --quiet https://github.com/coqui-ai/TTS /tmp/pip-req-build-bqvkm00r\n","  Resolved https://github.com/coqui-ai/TTS to commit dbf1a08a0d4e47fdad6172e433eeb34bc6b13b4e\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: cython>=0.29.30 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.0.10)\n","Requirement already satisfied: scipy>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (1.14.1)\n","Requirement already satisfied: torch>=2.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2.4.0)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2.4.0)\n","Requirement already satisfied: soundfile>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.12.1)\n","Requirement already satisfied: librosa>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.10.2.post1)\n","Collecting scikit-learn>=1.3.0 (from TTS==0.22.0)\n","  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting inflect>=5.6.0 (from TTS==0.22.0)\n","  Downloading inflect-7.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (4.66.4)\n","Collecting anyascii>=0.3.0 (from TTS==0.22.0)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: pyyaml>=6.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (6.0.2)\n","Requirement already satisfied: fsspec>=2023.6.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2024.6.1)\n","Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.9.5)\n","Collecting packaging>=23.1 (from TTS==0.22.0)\n","  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Collecting mutagen==1.47.0 (from TTS==0.22.0)\n","  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: flask>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.0.3)\n","Collecting pysbd>=0.3.4 (from TTS==0.22.0)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Collecting umap-learn>=0.5.1 (from TTS==0.22.0)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n","Collecting pandas<2.0,>=1.4 (from TTS==0.22.0)\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.7.5)\n","Collecting trainer>=0.0.36 (from TTS==0.22.0)\n","  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n","Collecting coqpit>=0.0.16 (from TTS==0.22.0)\n","  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.42.1)\n","Collecting pypinyin (from TTS==0.22.0)\n","  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting hangul-romanize (from TTS==0.22.0)\n","  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut-2.2.3.tar.gz (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jamo (from TTS==0.22.0)\n","  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.2.4)\n","Collecting g2pkk>=0.1.1 (from TTS==0.22.0)\n","  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n","Collecting bangla (from TTS==0.22.0)\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n","Collecting bnnumerizer (from TTS==0.22.0)\n","  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting bnunicodenormalizer (from TTS==0.22.0)\n","  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n","Collecting einops>=0.6.0 (from TTS==0.22.0)\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: transformers>=4.33.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (4.45.1)\n","Collecting encodec>=0.1.1 (from TTS==0.22.0)\n","  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting unidecode>=1.3.2 (from TTS==0.22.0)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n","Collecting num2words (from TTS==0.22.0)\n","  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: spacy>=3 in /opt/conda/lib/python3.10/site-packages (from spacy[ja]>=3->TTS==0.22.0) (3.7.6)\n","Collecting numpy==1.22.0 (from TTS==0.22.0)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numba>=0.57.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.60.0)\n","Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.15.0)\n","Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n","Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n","Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (4.0.3)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (3.0.4)\n","Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (1.8.2)\n","Requirement already satisfied: more-itertools>=8.5.0 in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS==0.22.0) (10.3.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS==0.22.0) (4.3.0)\n","Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (3.0.1)\n","INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n","Collecting librosa>=0.10.0 (from TTS==0.22.0)\n","  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n","  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (5.1.1)\n","Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.0.8)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (2.9.0.post0)\n","Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->TTS==0.22.0) (0.6.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.57.0->TTS==0.22.0) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0,>=1.4->TTS==0.22.0) (2024.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->TTS==0.22.0) (3.5.0)\n","INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n","Collecting scipy>=1.11.2 (from TTS==0.22.0)\n","  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.0->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.9.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (70.0.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.4.1)\n","Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS==0.22.0)\n","  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS==0.22.0)\n","  Downloading SudachiDict_core-20240716-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS==0.22.0) (3.15.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS==0.22.0) (1.13.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.36->TTS==0.22.0) (5.9.3)\n","Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.36->TTS==0.22.0) (2.16.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.20.0)\n","Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS==0.22.0)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS==0.22.0) (2.22)\n","Collecting tzlocal (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS==0.22.0) (2.1.5)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.2.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.10.0->TTS==0.22.0) (3.11.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (13.7.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (7.0.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1->TTS==0.22.0) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.62.2)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.20.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (0.7.2)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.18.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.2)\n","Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n","Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n","Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n","Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n","Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n","Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n","Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SudachiDict_core-20240716-py3-none-any.whl (72.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: TTS, gruut, encodec, bnnumerizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n","  Building wheel for TTS (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for TTS: filename=TTS-0.22.0-cp310-cp310-linux_x86_64.whl size=904085 sha256=0649db863922b4b6ac5f8eb2e9a08d464bf22bd6c3cb6f01acce46333f9c2fcc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2vp153k7/wheels/45/77/39/42afe730577d15c3bd85ce6db4c0dbb8fcf06e021a8b68bf62\n","  Building wheel for gruut (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75791 sha256=3bd9f6391846ae3b4527561979384bbc392fea52d42fc73c0a628eee34033a93\n","  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n","  Building wheel for encodec (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=dd368849af1a59409e318bbd77af11fa43ffc64f774fce0a833b9bd392627e38\n","  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n","  Building wheel for bnnumerizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=0724eb04a5001e65d5b30d222b4e42816f8acd034d4eea2bbdd536eab9e631b9\n","  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n","  Building wheel for gruut-ipa (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=3719d492bcd8bf316b80fedc536d910ea13b306119a77c81a17c1631743a8294\n","  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n","  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498315 sha256=2a18901973eda9662db0674c4b6d7c2b506ad1356b62aea169c839dd5b88160b\n","  Stored in directory: /root/.cache/pip/wheels/83/80/5f/775b357ae61d7cb68793327c7470d848715cbc60bb373af8dd\n","  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=450bc2727ff6a514efe77a63fe9388a514a94073b1c86199e93267fbd7d14fab\n","  Stored in directory: /root/.cache/pip/wheels/64/8d/b7/d484d224facd899ed188e00374f25dd3f19d1a3f53da6517bd\n","  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=c9155fc884d007173ef365d7f658ef9f7c36eb00df9d2f895e5d5908bcb6f987\n","  Stored in directory: /root/.cache/pip/wheels/ab/bd/96/5ddde14e8e6932a96f12c5ab5de62b619d39e2507d7daf5188\n","  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968768 sha256=9b7f043a4a397f6ea44041e71d504526f8301cd03cb31d9477d4e8a7a2c8430c\n","  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n","Successfully built TTS gruut encodec bnnumerizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n","Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, bnunicodenormalizer, bnnumerizer, bangla, unidecode, tzlocal, sudachidict-core, python-crfsuite, pysbd, pypinyin, packaging, numpy, num2words, networkx, mutagen, jsonlines, gruut-ipa, einops, coqpit, anyascii, scipy, pandas, inflect, g2pkk, dateparser, trainer, scikit-learn, gruut, pynndescent, librosa, encodec, umap-learn, TTS\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.3\n","    Uninstalling networkx-3.3:\n","      Successfully uninstalled networkx-3.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.14.1\n","    Uninstalling scipy-1.14.1:\n","      Successfully uninstalled scipy-1.14.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.10.2.post1\n","    Uninstalling librosa-0.10.2.post1:\n","      Successfully uninstalled librosa-0.10.2.post1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.8.3 requires cubinlinker, which is not installed.\n","cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires ptxcompiler, which is not installed.\n","cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\n","albucore 0.0.17 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n","albumentations 1.4.17 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n","apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n","arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","bayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.22.0 which is incompatible.\n","beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\n","bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\n","bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\n","cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.22.0 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","cudf 24.8.3 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-cuda 24.8.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.8.3 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n","dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\n","dipy 1.9.0 requires numpy>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\n","jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","mne 1.8.0 requires numpy<3,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.22.0 which is incompatible.\n","pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","pylibraft 24.8.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","raft-dask 24.8.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","rmm 24.8.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n","tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n","tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n","ucx-py 0.39.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","ucxx 0.39.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n","xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n","xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 einops-0.8.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 inflect-7.4.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 mutagen-1.47.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 packaging-24.1 pandas-1.5.3 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 scikit-learn-1.5.2 scipy-1.11.4 sudachidict-core-20240716 sudachipy-0.6.8 trainer-0.0.36 tzlocal-5.2 umap-learn-0.5.6 unidecode-1.3.8\n"]}],"source":["!pip install git+https://github.com/coqui-ai/TTS"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:38:59.020339Z","iopub.status.busy":"2024-10-12T06:38:59.019649Z","iopub.status.idle":"2024-10-12T06:39:23.266311Z","shell.execute_reply":"2024-10-12T06:39:23.265145Z","shell.execute_reply.started":"2024-10-12T06:38:59.020298Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.37.1\n","  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (0.25.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (1.22.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (2.32.3)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.1)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (2024.8.30)\n","Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.0\n","    Uninstalling tokenizers-0.20.0:\n","      Successfully uninstalled tokenizers-0.20.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.45.1\n","    Uninstalling transformers-4.45.1:\n","      Successfully uninstalled transformers-4.45.1\n","Successfully installed tokenizers-0.15.2 transformers-4.37.1\n"]}],"source":["!pip install transformers==4.37.1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T13:39:41.540234Z","iopub.status.busy":"2024-04-22T13:39:41.539854Z","iopub.status.idle":"2024-04-22T13:39:41.54496Z","shell.execute_reply":"2024-04-22T13:39:41.543875Z","shell.execute_reply.started":"2024-04-22T13:39:41.540197Z"},"trusted":true},"outputs":[],"source":["###updated training zone####"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:39:56.460542Z","iopub.status.busy":"2024-10-12T06:39:56.460149Z","iopub.status.idle":"2024-10-12T06:39:56.466644Z","shell.execute_reply":"2024-10-12T06:39:56.465412Z","shell.execute_reply.started":"2024-10-12T06:39:56.460504Z"},"trusted":true},"outputs":[],"source":["from trainer import Trainer, TrainerArgs\n","#from trainer.logging.wandb_logger import WandbLogger\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n","from TTS.utils.manage import ModelManager\n","\n","import sys\n","import os\n","import wandb"]},{"cell_type":"markdown","metadata":{},"source":["### Monkey Patching for wandb (!!!) ###\n","\n","XTTS-v2 uses tensorboard for logging by default. Officially wandb is supported, but it breaks things when I've used it (after a few epochs creating massive amounts of artifact files). For this reason I've monkey patched the offending method so that no artifacts are added.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:39:59.899855Z","iopub.status.busy":"2024-10-12T06:39:59.898983Z","iopub.status.idle":"2024-10-12T06:39:59.905244Z","shell.execute_reply":"2024-10-12T06:39:59.904167Z","shell.execute_reply.started":"2024-10-12T06:39:59.899813Z"},"trusted":true},"outputs":[],"source":["from trainer.logging.wandb_logger import WandbLogger"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:01.380011Z","iopub.status.busy":"2024-10-12T06:40:01.379274Z","iopub.status.idle":"2024-10-12T06:40:01.384760Z","shell.execute_reply":"2024-10-12T06:40:01.383787Z","shell.execute_reply.started":"2024-10-12T06:40:01.379972Z"},"trusted":true},"outputs":[],"source":["def add_artifact(self, file_or_dir, name, artifact_type, aliases=None):\n","    ###instead of adding artifact, do nothing###\n","    print(f\"========Ignoring artifact: {name} {file_or_dir}========\")\n","    return\n","\n","\n","WandbLogger.add_artifact = add_artifact"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:03.180369Z","iopub.status.busy":"2024-10-12T06:40:03.179533Z","iopub.status.idle":"2024-10-12T06:40:03.184682Z","shell.execute_reply":"2024-10-12T06:40:03.183728Z","shell.execute_reply.started":"2024-10-12T06:40:03.180325Z"},"trusted":true},"outputs":[],"source":["# Logging parameters\n","RUN_NAME = \"kaggletest\"\n","PROJECT_NAME = \"gore\" \n","DASHBOARD_LOGGER = \"wandb\" \n","LOGGER_URI = None"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:05.779663Z","iopub.status.busy":"2024-10-12T06:40:05.779285Z","iopub.status.idle":"2024-10-12T06:40:05.784495Z","shell.execute_reply":"2024-10-12T06:40:05.783569Z","shell.execute_reply.started":"2024-10-12T06:40:05.779626Z"},"trusted":true},"outputs":[],"source":["OUT_PATH = '/kaggle/working/run/'\n","os.makedirs(OUT_PATH, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Retreive the base model files. "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:07.422883Z","iopub.status.busy":"2024-10-12T06:40:07.422355Z","iopub.status.idle":"2024-10-12T06:40:47.408536Z","shell.execute_reply":"2024-10-12T06:40:47.407785Z","shell.execute_reply.started":"2024-10-12T06:40:07.422832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" > Downloading DVAE files!\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0.00/1.07k [00:00<?, ?iB/s]\n","100%|██████████| 1.07k/1.07k [00:00<00:00, 3.23kiB/s]\n","\n","  2%|▏         | 3.45M/211M [00:00<00:06, 34.5MiB/s]\u001b[A\n","  4%|▍         | 8.18M/211M [00:00<00:04, 42.0MiB/s]\u001b[A\n","  6%|▋         | 13.2M/211M [00:00<00:04, 45.7MiB/s]\u001b[A\n","  9%|▉         | 18.7M/211M [00:00<00:03, 49.6MiB/s]\u001b[A\n"," 12%|█▏        | 24.3M/211M [00:00<00:03, 51.8MiB/s]\u001b[A\n"," 14%|█▍        | 29.9M/211M [00:00<00:03, 53.3MiB/s]\u001b[A\n"," 17%|█▋        | 35.5M/211M [00:00<00:03, 54.2MiB/s]\u001b[A\n"," 19%|█▉        | 41.0M/211M [00:00<00:03, 54.5MiB/s]\u001b[A\n"," 22%|██▏       | 46.5M/211M [00:00<00:03, 54.1MiB/s]\u001b[A\n"," 25%|██▍       | 51.9M/211M [00:01<00:02, 54.0MiB/s]\u001b[A\n"," 27%|██▋       | 57.3M/211M [00:01<00:02, 53.8MiB/s]\u001b[A\n"," 30%|██▉       | 62.7M/211M [00:01<00:02, 53.8MiB/s]\u001b[A\n"," 32%|███▏      | 68.1M/211M [00:01<00:02, 54.0MiB/s]\u001b[A\n"," 35%|███▍      | 73.5M/211M [00:01<00:02, 54.0MiB/s]\u001b[A\n"," 38%|███▊      | 78.9M/211M [00:01<00:02, 54.1MiB/s]\u001b[A\n"," 40%|████      | 84.4M/211M [00:01<00:02, 53.9MiB/s]\u001b[A\n"," 43%|████▎     | 89.7M/211M [00:01<00:02, 53.9MiB/s]\u001b[A\n"," 45%|████▌     | 95.1M/211M [00:01<00:02, 53.8MiB/s]\u001b[A\n"," 48%|████▊     | 101M/211M [00:01<00:02, 54.0MiB/s] \u001b[A\n"," 50%|█████     | 106M/211M [00:02<00:01, 54.3MiB/s]\u001b[A\n"," 53%|█████▎    | 112M/211M [00:02<00:01, 54.5MiB/s]\u001b[A\n"," 56%|█████▌    | 117M/211M [00:02<00:01, 54.3MiB/s]\u001b[A\n"," 58%|█████▊    | 122M/211M [00:02<00:01, 54.4MiB/s]\u001b[A\n"," 61%|██████    | 128M/211M [00:02<00:01, 54.4MiB/s]\u001b[A\n"," 63%|██████▎   | 133M/211M [00:02<00:01, 54.4MiB/s]\u001b[A\n"," 66%|██████▌   | 139M/211M [00:02<00:01, 54.4MiB/s]\u001b[A\n"," 69%|██████▊   | 144M/211M [00:02<00:01, 54.5MiB/s]\u001b[A\n"," 71%|███████   | 150M/211M [00:02<00:01, 54.2MiB/s]\u001b[A\n"," 74%|███████▎  | 155M/211M [00:02<00:01, 54.4MiB/s]\u001b[A\n"," 76%|███████▋  | 161M/211M [00:03<00:00, 52.9MiB/s]\u001b[A\n"," 79%|███████▉  | 166M/211M [00:03<00:00, 53.4MiB/s]\u001b[A\n"," 81%|████████▏ | 171M/211M [00:03<00:00, 53.5MiB/s]\u001b[A\n"," 84%|████████▍ | 177M/211M [00:03<00:00, 53.9MiB/s]\u001b[A\n"," 87%|████████▋ | 182M/211M [00:03<00:00, 54.2MiB/s]\u001b[A\n"," 89%|████████▉ | 188M/211M [00:03<00:00, 53.4MiB/s]\u001b[A\n"," 92%|█████████▏| 193M/211M [00:03<00:00, 52.9MiB/s]\u001b[A\n"," 94%|█████████▍| 199M/211M [00:03<00:00, 52.2MiB/s]\u001b[A\n"," 97%|█████████▋| 204M/211M [00:03<00:00, 52.4MiB/s]\u001b[A\n"," 99%|█████████▉| 209M/211M [00:03<00:00, 53.5MiB/s]\u001b[A"]},{"name":"stdout","output_type":"stream","text":[" > Downloading XTTS v2.0 files!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 211M/211M [00:04<00:00, 51.2MiB/s]\n"," 30%|██▉       | 108k/361k [00:00<00:00, 913kiB/s]\n","100%|██████████| 361k/361k [00:00<00:00, 842kiB/s]\n","\n","  0%|          | 1.52M/1.87G [00:00<02:02, 15.2MiB/s]\u001b[A\n","  0%|          | 5.78M/1.87G [00:00<00:59, 31.3MiB/s]\u001b[A\n","  1%|          | 11.1M/1.87G [00:00<00:44, 41.3MiB/s]\u001b[A\n","  1%|          | 16.5M/1.87G [00:00<00:39, 46.4MiB/s]\u001b[A\n","  1%|          | 21.9M/1.87G [00:00<00:37, 48.9MiB/s]\u001b[A\n","  1%|▏         | 27.2M/1.87G [00:00<00:36, 50.5MiB/s]\u001b[A\n","  2%|▏         | 32.5M/1.87G [00:00<00:35, 51.2MiB/s]\u001b[A\n","  2%|▏         | 37.9M/1.87G [00:00<00:35, 52.1MiB/s]\u001b[A\n","  2%|▏         | 43.4M/1.87G [00:00<00:34, 52.9MiB/s]\u001b[A\n","  3%|▎         | 48.7M/1.87G [00:01<00:34, 52.5MiB/s]\u001b[A\n","  3%|▎         | 54.2M/1.87G [00:01<00:33, 53.6MiB/s]\u001b[A\n","  3%|▎         | 59.6M/1.87G [00:01<00:33, 53.5MiB/s]\u001b[A\n","  3%|▎         | 65.0M/1.87G [00:01<00:33, 53.8MiB/s]\u001b[A\n","  4%|▍         | 70.5M/1.87G [00:01<00:33, 54.0MiB/s]\u001b[A\n","  4%|▍         | 75.9M/1.87G [00:01<00:33, 54.2MiB/s]\u001b[A\n","  4%|▍         | 81.4M/1.87G [00:01<00:32, 54.4MiB/s]\u001b[A\n","  5%|▍         | 87.0M/1.87G [00:01<00:32, 54.8MiB/s]\u001b[A\n","  5%|▍         | 92.6M/1.87G [00:01<00:32, 55.3MiB/s]\u001b[A\n","  5%|▌         | 98.2M/1.87G [00:01<00:31, 55.5MiB/s]\u001b[A\n","  6%|▌         | 104M/1.87G [00:02<00:32, 55.0MiB/s] \u001b[A\n","  6%|▌         | 109M/1.87G [00:02<00:31, 55.3MiB/s]\u001b[A\n","  6%|▌         | 115M/1.87G [00:02<00:31, 55.1MiB/s]\u001b[A\n","  6%|▋         | 121M/1.87G [00:02<00:31, 55.5MiB/s]\u001b[A\n","  7%|▋         | 126M/1.87G [00:02<00:31, 55.7MiB/s]\u001b[A\n","  7%|▋         | 132M/1.87G [00:02<00:31, 55.7MiB/s]\u001b[A\n","  7%|▋         | 137M/1.87G [00:02<00:30, 55.9MiB/s]\u001b[A\n","  8%|▊         | 143M/1.87G [00:02<00:30, 55.8MiB/s]\u001b[A\n","  8%|▊         | 149M/1.87G [00:02<00:30, 56.0MiB/s]\u001b[A\n","  8%|▊         | 154M/1.87G [00:02<00:30, 56.2MiB/s]\u001b[A\n","  9%|▊         | 160M/1.87G [00:03<00:30, 56.0MiB/s]\u001b[A\n","  9%|▉         | 166M/1.87G [00:03<00:30, 55.8MiB/s]\u001b[A\n","  9%|▉         | 171M/1.87G [00:03<00:30, 55.7MiB/s]\u001b[A\n","  9%|▉         | 177M/1.87G [00:03<00:30, 55.9MiB/s]\u001b[A\n"," 10%|▉         | 182M/1.87G [00:03<00:30, 56.2MiB/s]\u001b[A\n"," 10%|█         | 188M/1.87G [00:03<00:30, 55.3MiB/s]\u001b[A\n"," 10%|█         | 194M/1.87G [00:03<00:30, 54.4MiB/s]\u001b[A\n"," 11%|█         | 199M/1.87G [00:03<00:30, 54.9MiB/s]\u001b[A\n"," 11%|█         | 205M/1.87G [00:03<00:30, 55.3MiB/s]\u001b[A\n"," 11%|█▏        | 210M/1.87G [00:03<00:29, 55.7MiB/s]\u001b[A\n"," 12%|█▏        | 216M/1.87G [00:04<00:29, 55.3MiB/s]\u001b[A\n"," 12%|█▏        | 222M/1.87G [00:04<00:29, 55.6MiB/s]\u001b[A\n"," 12%|█▏        | 227M/1.87G [00:04<00:29, 55.7MiB/s]\u001b[A\n"," 12%|█▏        | 233M/1.87G [00:04<00:29, 55.7MiB/s]\u001b[A\n"," 13%|█▎        | 238M/1.87G [00:04<00:29, 55.2MiB/s]\u001b[A\n"," 13%|█▎        | 244M/1.87G [00:04<00:29, 55.1MiB/s]\u001b[A\n"," 13%|█▎        | 249M/1.87G [00:04<00:29, 55.0MiB/s]\u001b[A\n"," 14%|█▎        | 255M/1.87G [00:04<00:29, 55.4MiB/s]\u001b[A\n"," 14%|█▍        | 261M/1.87G [00:04<00:28, 55.8MiB/s]\u001b[A\n"," 14%|█▍        | 266M/1.87G [00:04<00:28, 56.1MiB/s]\u001b[A\n"," 15%|█▍        | 272M/1.87G [00:05<00:28, 55.9MiB/s]\u001b[A\n"," 15%|█▍        | 278M/1.87G [00:05<00:28, 55.8MiB/s]\u001b[A\n"," 15%|█▌        | 283M/1.87G [00:05<00:28, 55.8MiB/s]\u001b[A\n"," 15%|█▌        | 289M/1.87G [00:05<00:28, 56.0MiB/s]\u001b[A\n"," 16%|█▌        | 295M/1.87G [00:05<00:27, 56.2MiB/s]\u001b[A\n"," 16%|█▌        | 300M/1.87G [00:05<00:28, 55.5MiB/s]\u001b[A\n"," 16%|█▋        | 306M/1.87G [00:05<00:28, 54.9MiB/s]\u001b[A\n"," 17%|█▋        | 311M/1.87G [00:05<00:29, 52.7MiB/s]\u001b[A\n"," 17%|█▋        | 317M/1.87G [00:05<00:28, 53.5MiB/s]\u001b[A\n"," 17%|█▋        | 322M/1.87G [00:05<00:28, 54.4MiB/s]\u001b[A\n"," 18%|█▊        | 328M/1.87G [00:06<00:28, 54.7MiB/s]\u001b[A\n"," 18%|█▊        | 333M/1.87G [00:06<00:28, 54.3MiB/s]\u001b[A\n"," 18%|█▊        | 339M/1.87G [00:06<00:28, 53.8MiB/s]\u001b[A\n"," 18%|█▊        | 344M/1.87G [00:06<00:28, 54.2MiB/s]\u001b[A\n"," 19%|█▊        | 350M/1.87G [00:06<00:27, 54.3MiB/s]\u001b[A\n"," 19%|█▉        | 356M/1.87G [00:06<00:27, 54.9MiB/s]\u001b[A\n"," 19%|█▉        | 361M/1.87G [00:06<00:27, 55.4MiB/s]\u001b[A\n"," 20%|█▉        | 367M/1.87G [00:06<00:27, 55.5MiB/s]\u001b[A\n"," 20%|█▉        | 372M/1.87G [00:06<00:26, 55.9MiB/s]\u001b[A\n"," 20%|██        | 378M/1.87G [00:06<00:26, 56.1MiB/s]\u001b[A\n"," 21%|██        | 384M/1.87G [00:07<00:26, 56.1MiB/s]\u001b[A\n"," 21%|██        | 389M/1.87G [00:07<00:26, 56.1MiB/s]\u001b[A\n"," 21%|██        | 395M/1.87G [00:07<00:26, 55.9MiB/s]\u001b[A\n"," 21%|██▏       | 401M/1.87G [00:07<00:26, 56.1MiB/s]\u001b[A\n"," 22%|██▏       | 406M/1.87G [00:07<00:25, 56.3MiB/s]\u001b[A\n"," 22%|██▏       | 412M/1.87G [00:07<00:25, 56.5MiB/s]\u001b[A\n"," 22%|██▏       | 418M/1.87G [00:07<00:25, 56.5MiB/s]\u001b[A\n"," 23%|██▎       | 423M/1.87G [00:07<00:25, 56.6MiB/s]\u001b[A\n"," 23%|██▎       | 429M/1.87G [00:07<00:25, 56.7MiB/s]\u001b[A\n"," 23%|██▎       | 435M/1.87G [00:07<00:25, 56.8MiB/s]\u001b[A\n"," 24%|██▎       | 440M/1.87G [00:08<00:25, 56.4MiB/s]\u001b[A\n"," 24%|██▍       | 446M/1.87G [00:08<00:25, 55.9MiB/s]\u001b[A\n"," 24%|██▍       | 452M/1.87G [00:08<00:25, 55.0MiB/s]\u001b[A\n"," 24%|██▍       | 457M/1.87G [00:08<00:25, 54.6MiB/s]\u001b[A\n"," 25%|██▍       | 463M/1.87G [00:08<00:25, 54.4MiB/s]\u001b[A\n"," 25%|██▌       | 468M/1.87G [00:08<00:25, 54.4MiB/s]\u001b[A\n"," 25%|██▌       | 473M/1.87G [00:08<00:26, 53.2MiB/s]\u001b[A\n"," 26%|██▌       | 479M/1.87G [00:08<00:25, 53.5MiB/s]\u001b[A\n"," 26%|██▌       | 484M/1.87G [00:08<00:25, 53.7MiB/s]\u001b[A\n"," 26%|██▌       | 490M/1.87G [00:08<00:25, 53.8MiB/s]\u001b[A\n"," 27%|██▋       | 495M/1.87G [00:09<00:25, 53.9MiB/s]\u001b[A\n"," 27%|██▋       | 501M/1.87G [00:09<00:24, 54.8MiB/s]\u001b[A\n"," 27%|██▋       | 506M/1.87G [00:09<00:24, 55.2MiB/s]\u001b[A\n"," 27%|██▋       | 512M/1.87G [00:09<00:24, 55.7MiB/s]\u001b[A\n"," 28%|██▊       | 518M/1.87G [00:09<00:24, 56.1MiB/s]\u001b[A\n"," 28%|██▊       | 523M/1.87G [00:09<00:23, 56.2MiB/s]\u001b[A\n"," 28%|██▊       | 529M/1.87G [00:09<00:23, 56.4MiB/s]\u001b[A\n"," 29%|██▊       | 535M/1.87G [00:09<00:23, 56.5MiB/s]\u001b[A\n"," 29%|██▉       | 540M/1.87G [00:09<00:23, 56.6MiB/s]\u001b[A\n"," 29%|██▉       | 546M/1.87G [00:09<00:24, 55.1MiB/s]\u001b[A\n"," 30%|██▉       | 552M/1.87G [00:10<00:24, 54.8MiB/s]\u001b[A\n"," 30%|██▉       | 557M/1.87G [00:10<00:23, 54.8MiB/s]\u001b[A\n"," 30%|███       | 563M/1.87G [00:10<00:23, 54.5MiB/s]\u001b[A\n"," 30%|███       | 568M/1.87G [00:10<00:23, 54.4MiB/s]\u001b[A\n"," 31%|███       | 574M/1.87G [00:10<00:23, 54.4MiB/s]\u001b[A\n"," 31%|███       | 579M/1.87G [00:10<00:23, 54.5MiB/s]\u001b[A\n"," 31%|███▏      | 584M/1.87G [00:10<00:23, 54.5MiB/s]\u001b[A\n"," 32%|███▏      | 590M/1.87G [00:10<00:23, 53.9MiB/s]\u001b[A\n"," 32%|███▏      | 595M/1.87G [00:10<00:23, 53.4MiB/s]\u001b[A\n"," 32%|███▏      | 601M/1.87G [00:11<00:23, 53.2MiB/s]\u001b[A\n"," 32%|███▏      | 606M/1.87G [00:11<00:23, 53.9MiB/s]\u001b[A\n"," 33%|███▎      | 612M/1.87G [00:11<00:22, 54.6MiB/s]\u001b[A\n"," 33%|███▎      | 617M/1.87G [00:11<00:22, 54.7MiB/s]\u001b[A\n"," 33%|███▎      | 623M/1.87G [00:11<00:22, 55.1MiB/s]\u001b[A\n"," 34%|███▎      | 628M/1.87G [00:11<00:22, 55.3MiB/s]\u001b[A\n"," 34%|███▍      | 634M/1.87G [00:11<00:22, 55.4MiB/s]\u001b[A\n"," 34%|███▍      | 640M/1.87G [00:11<00:22, 55.5MiB/s]\u001b[A\n"," 35%|███▍      | 645M/1.87G [00:11<00:21, 55.6MiB/s]\u001b[A\n"," 35%|███▍      | 651M/1.87G [00:11<00:22, 55.0MiB/s]\u001b[A\n"," 35%|███▌      | 656M/1.87G [00:12<00:22, 54.5MiB/s]\u001b[A\n"," 35%|███▌      | 662M/1.87G [00:12<00:22, 54.1MiB/s]\u001b[A\n"," 36%|███▌      | 667M/1.87G [00:12<00:22, 53.4MiB/s]\u001b[A\n"," 36%|███▌      | 672M/1.87G [00:12<00:22, 53.2MiB/s]\u001b[A\n"," 36%|███▋      | 678M/1.87G [00:12<00:22, 53.3MiB/s]\u001b[A\n"," 37%|███▋      | 683M/1.87G [00:12<00:22, 53.5MiB/s]\u001b[A\n"," 37%|███▋      | 689M/1.87G [00:12<00:22, 53.4MiB/s]\u001b[A\n"," 37%|███▋      | 694M/1.87G [00:12<00:21, 54.0MiB/s]\u001b[A\n"," 37%|███▋      | 700M/1.87G [00:12<00:21, 54.7MiB/s]\u001b[A\n"," 38%|███▊      | 705M/1.87G [00:12<00:21, 55.3MiB/s]\u001b[A\n"," 38%|███▊      | 711M/1.87G [00:13<00:20, 55.6MiB/s]\u001b[A\n"," 38%|███▊      | 717M/1.87G [00:13<00:20, 55.8MiB/s]\u001b[A\n"," 39%|███▊      | 722M/1.87G [00:13<00:20, 55.9MiB/s]\u001b[A\n"," 39%|███▉      | 728M/1.87G [00:13<00:20, 55.8MiB/s]\u001b[A\n"," 39%|███▉      | 734M/1.87G [00:13<00:20, 56.0MiB/s]\u001b[A\n"," 40%|███▉      | 739M/1.87G [00:13<00:20, 56.1MiB/s]\u001b[A\n"," 40%|███▉      | 745M/1.87G [00:13<00:20, 56.1MiB/s]\u001b[A\n"," 40%|████      | 750M/1.87G [00:13<00:19, 56.2MiB/s]\u001b[A\n"," 40%|████      | 756M/1.87G [00:13<00:19, 56.3MiB/s]\u001b[A\n"," 41%|████      | 762M/1.87G [00:13<00:19, 56.1MiB/s]\u001b[A\n"," 41%|████      | 767M/1.87G [00:14<00:19, 56.0MiB/s]\u001b[A\n"," 41%|████▏     | 773M/1.87G [00:14<00:19, 56.2MiB/s]\u001b[A\n"," 42%|████▏     | 779M/1.87G [00:14<00:19, 56.2MiB/s]\u001b[A\n"," 42%|████▏     | 784M/1.87G [00:14<00:28, 37.9MiB/s]\u001b[A\n"," 42%|████▏     | 790M/1.87G [00:14<00:26, 41.3MiB/s]\u001b[A\n"," 43%|████▎     | 795M/1.87G [00:14<00:24, 44.2MiB/s]\u001b[A\n"," 43%|████▎     | 800M/1.87G [00:14<00:22, 46.6MiB/s]\u001b[A\n"," 43%|████▎     | 806M/1.87G [00:14<00:21, 48.6MiB/s]\u001b[A\n"," 43%|████▎     | 811M/1.87G [00:14<00:21, 50.1MiB/s]\u001b[A\n"," 44%|████▎     | 817M/1.87G [00:15<00:20, 51.2MiB/s]\u001b[A\n"," 44%|████▍     | 822M/1.87G [00:15<00:20, 51.9MiB/s]\u001b[A\n"," 44%|████▍     | 827M/1.87G [00:15<00:19, 52.5MiB/s]\u001b[A\n"," 45%|████▍     | 833M/1.87G [00:15<00:19, 53.1MiB/s]\u001b[A\n"," 45%|████▍     | 838M/1.87G [00:15<00:19, 53.0MiB/s]\u001b[A\n"," 45%|████▌     | 843M/1.87G [00:15<00:19, 53.1MiB/s]\u001b[A\n"," 45%|████▌     | 849M/1.87G [00:15<00:19, 51.0MiB/s]\u001b[A\n"," 46%|████▌     | 854M/1.87G [00:15<00:19, 52.5MiB/s]\u001b[A\n"," 46%|████▌     | 860M/1.87G [00:15<00:18, 53.7MiB/s]\u001b[A\n"," 46%|████▋     | 866M/1.87G [00:16<00:18, 54.5MiB/s]\u001b[A\n"," 47%|████▋     | 871M/1.87G [00:16<00:18, 55.0MiB/s]\u001b[A\n"," 47%|████▋     | 877M/1.87G [00:16<00:17, 55.5MiB/s]\u001b[A\n"," 47%|████▋     | 883M/1.87G [00:16<00:17, 55.6MiB/s]\u001b[A\n"," 48%|████▊     | 888M/1.87G [00:16<00:17, 55.9MiB/s]\u001b[A\n"," 48%|████▊     | 894M/1.87G [00:16<00:17, 56.0MiB/s]\u001b[A\n"," 48%|████▊     | 900M/1.87G [00:16<00:17, 56.2MiB/s]\u001b[A\n"," 48%|████▊     | 905M/1.87G [00:16<00:17, 56.2MiB/s]\u001b[A\n"," 49%|████▉     | 911M/1.87G [00:16<00:17, 56.3MiB/s]\u001b[A\n"," 49%|████▉     | 917M/1.87G [00:16<00:16, 56.4MiB/s]\u001b[A\n"," 49%|████▉     | 922M/1.87G [00:17<00:16, 56.5MiB/s]\u001b[A\n"," 50%|████▉     | 928M/1.87G [00:17<00:16, 56.3MiB/s]\u001b[A\n"," 50%|████▉     | 933M/1.87G [00:17<00:16, 56.4MiB/s]\u001b[A\n"," 50%|█████     | 939M/1.87G [00:17<00:16, 55.0MiB/s]\u001b[A\n"," 51%|█████     | 945M/1.87G [00:17<00:16, 55.4MiB/s]\u001b[A\n"," 51%|█████     | 950M/1.87G [00:17<00:16, 55.0MiB/s]\u001b[A\n"," 51%|█████     | 956M/1.87G [00:17<00:16, 54.8MiB/s]\u001b[A\n"," 51%|█████▏    | 961M/1.87G [00:17<00:16, 54.6MiB/s]\u001b[A\n"," 52%|█████▏    | 967M/1.87G [00:17<00:16, 54.6MiB/s]\u001b[A\n"," 52%|█████▏    | 972M/1.87G [00:17<00:16, 54.1MiB/s]\u001b[A\n"," 52%|█████▏    | 978M/1.87G [00:18<00:16, 54.5MiB/s]\u001b[A\n"," 53%|█████▎    | 983M/1.87G [00:18<00:16, 54.7MiB/s]\u001b[A\n"," 53%|█████▎    | 989M/1.87G [00:18<00:16, 54.4MiB/s]\u001b[A\n"," 53%|█████▎    | 994M/1.87G [00:18<00:16, 54.0MiB/s]\u001b[A\n"," 54%|█████▎    | 1.00G/1.87G [00:18<00:16, 53.7MiB/s]\u001b[A\n"," 54%|█████▍    | 1.00G/1.87G [00:18<00:16, 53.6MiB/s]\u001b[A\n"," 54%|█████▍    | 1.01G/1.87G [00:18<00:16, 53.5MiB/s]\u001b[A\n"," 54%|█████▍    | 1.02G/1.87G [00:18<00:15, 53.4MiB/s]\u001b[A\n"," 55%|█████▍    | 1.02G/1.87G [00:18<00:15, 53.3MiB/s]\u001b[A\n"," 55%|█████▍    | 1.03G/1.87G [00:18<00:16, 51.8MiB/s]\u001b[A\n"," 55%|█████▌    | 1.03G/1.87G [00:19<00:15, 53.1MiB/s]\u001b[A\n"," 56%|█████▌    | 1.04G/1.87G [00:19<00:15, 53.7MiB/s]\u001b[A\n"," 56%|█████▌    | 1.04G/1.87G [00:19<00:15, 54.0MiB/s]\u001b[A\n"," 56%|█████▌    | 1.05G/1.87G [00:19<00:15, 54.2MiB/s]\u001b[A\n"," 56%|█████▋    | 1.05G/1.87G [00:19<00:14, 54.3MiB/s]\u001b[A\n"," 57%|█████▋    | 1.06G/1.87G [00:19<00:14, 54.4MiB/s]\u001b[A\n"," 57%|█████▋    | 1.06G/1.87G [00:19<00:14, 54.6MiB/s]\u001b[A\n"," 57%|█████▋    | 1.07G/1.87G [00:19<00:14, 54.8MiB/s]\u001b[A\n"," 58%|█████▊    | 1.08G/1.87G [00:19<00:14, 54.8MiB/s]\u001b[A\n"," 58%|█████▊    | 1.08G/1.87G [00:19<00:14, 55.0MiB/s]\u001b[A\n"," 58%|█████▊    | 1.09G/1.87G [00:20<00:14, 54.9MiB/s]\u001b[A\n"," 58%|█████▊    | 1.09G/1.87G [00:20<00:14, 54.9MiB/s]\u001b[A\n"," 59%|█████▉    | 1.10G/1.87G [00:20<00:14, 54.8MiB/s]\u001b[A\n"," 59%|█████▉    | 1.10G/1.87G [00:20<00:14, 54.6MiB/s]\u001b[A\n"," 59%|█████▉    | 1.11G/1.87G [00:20<00:13, 54.9MiB/s]\u001b[A\n"," 60%|█████▉    | 1.11G/1.87G [00:20<00:13, 55.1MiB/s]\u001b[A\n"," 60%|█████▉    | 1.12G/1.87G [00:20<00:13, 55.5MiB/s]\u001b[A\n"," 60%|██████    | 1.13G/1.87G [00:20<00:13, 55.6MiB/s]\u001b[A\n"," 61%|██████    | 1.13G/1.87G [00:20<00:13, 53.4MiB/s]\u001b[A\n"," 61%|██████    | 1.14G/1.87G [00:20<00:13, 52.9MiB/s]\u001b[A\n"," 61%|██████    | 1.14G/1.87G [00:21<00:14, 51.0MiB/s]\u001b[A\n"," 61%|██████▏   | 1.15G/1.87G [00:21<00:13, 52.0MiB/s]\u001b[A\n"," 62%|██████▏   | 1.15G/1.87G [00:21<00:13, 53.1MiB/s]\u001b[A\n"," 62%|██████▏   | 1.16G/1.87G [00:21<00:13, 54.2MiB/s]\u001b[A\n"," 62%|██████▏   | 1.16G/1.87G [00:21<00:12, 54.9MiB/s]\u001b[A\n"," 63%|██████▎   | 1.17G/1.87G [00:21<00:12, 55.3MiB/s]\u001b[A\n"," 63%|██████▎   | 1.18G/1.87G [00:21<00:12, 55.5MiB/s]\u001b[A\n"," 63%|██████▎   | 1.18G/1.87G [00:21<00:12, 55.9MiB/s]\u001b[A\n"," 64%|██████▎   | 1.19G/1.87G [00:21<00:12, 55.3MiB/s]\u001b[A\n"," 64%|██████▍   | 1.19G/1.87G [00:21<00:12, 55.0MiB/s]\u001b[A\n"," 64%|██████▍   | 1.20G/1.87G [00:22<00:12, 54.6MiB/s]\u001b[A\n"," 64%|██████▍   | 1.20G/1.87G [00:22<00:12, 54.5MiB/s]\u001b[A\n"," 65%|██████▍   | 1.21G/1.87G [00:22<00:12, 54.3MiB/s]\u001b[A\n"," 65%|██████▍   | 1.21G/1.87G [00:22<00:12, 54.2MiB/s]\u001b[A\n"," 65%|██████▌   | 1.22G/1.87G [00:22<00:11, 54.1MiB/s]\u001b[A\n"," 66%|██████▌   | 1.23G/1.87G [00:22<00:11, 54.8MiB/s]\u001b[A\n"," 66%|██████▌   | 1.23G/1.87G [00:22<00:11, 55.1MiB/s]\u001b[A\n"," 66%|██████▌   | 1.24G/1.87G [00:22<00:11, 55.6MiB/s]\u001b[A\n"," 66%|██████▋   | 1.24G/1.87G [00:22<00:11, 56.0MiB/s]\u001b[A\n"," 67%|██████▋   | 1.25G/1.87G [00:22<00:11, 56.2MiB/s]\u001b[A\n"," 67%|██████▋   | 1.25G/1.87G [00:23<00:10, 55.9MiB/s]\u001b[A\n"," 67%|██████▋   | 1.26G/1.87G [00:23<00:10, 55.5MiB/s]\u001b[A\n"," 68%|██████▊   | 1.26G/1.87G [00:23<00:10, 55.5MiB/s]\u001b[A\n"," 68%|██████▊   | 1.27G/1.87G [00:23<00:10, 55.8MiB/s]\u001b[A\n"," 68%|██████▊   | 1.28G/1.87G [00:23<00:10, 56.0MiB/s]\u001b[A\n"," 69%|██████▊   | 1.28G/1.87G [00:23<00:10, 56.2MiB/s]\u001b[A\n"," 69%|██████▉   | 1.29G/1.87G [00:23<00:10, 56.1MiB/s]\u001b[A\n"," 69%|██████▉   | 1.29G/1.87G [00:23<00:10, 56.4MiB/s]\u001b[A\n"," 70%|██████▉   | 1.30G/1.87G [00:23<00:10, 56.2MiB/s]\u001b[A\n"," 70%|██████▉   | 1.30G/1.87G [00:24<00:10, 54.6MiB/s]\u001b[A\n"," 70%|███████   | 1.31G/1.87G [00:24<00:10, 53.4MiB/s]\u001b[A\n"," 70%|███████   | 1.32G/1.87G [00:24<00:10, 53.9MiB/s]\u001b[A\n"," 71%|███████   | 1.32G/1.87G [00:24<00:10, 52.9MiB/s]\u001b[A\n"," 71%|███████   | 1.33G/1.87G [00:24<00:10, 53.3MiB/s]\u001b[A\n"," 71%|███████▏  | 1.33G/1.87G [00:24<00:10, 53.5MiB/s]\u001b[A\n"," 72%|███████▏  | 1.34G/1.87G [00:24<00:09, 53.7MiB/s]\u001b[A\n"," 72%|███████▏  | 1.34G/1.87G [00:24<00:09, 53.8MiB/s]\u001b[A\n"," 72%|███████▏  | 1.35G/1.87G [00:24<00:09, 53.8MiB/s]\u001b[A\n"," 72%|███████▏  | 1.35G/1.87G [00:24<00:09, 54.0MiB/s]\u001b[A\n"," 73%|███████▎  | 1.36G/1.87G [00:25<00:09, 54.5MiB/s]\u001b[A\n"," 73%|███████▎  | 1.36G/1.87G [00:25<00:13, 36.9MiB/s]\u001b[A\n"," 73%|███████▎  | 1.37G/1.87G [00:25<00:12, 39.8MiB/s]\u001b[A\n"," 74%|███████▎  | 1.37G/1.87G [00:25<00:11, 42.8MiB/s]\u001b[A\n"," 74%|███████▍  | 1.38G/1.87G [00:25<00:10, 45.0MiB/s]\u001b[A\n"," 74%|███████▍  | 1.38G/1.87G [00:25<00:10, 44.9MiB/s]\u001b[A\n"," 74%|███████▍  | 1.39G/1.87G [00:25<00:10, 46.5MiB/s]\u001b[A\n"," 75%|███████▍  | 1.39G/1.87G [00:25<00:09, 49.2MiB/s]\u001b[A\n"," 75%|███████▍  | 1.40G/1.87G [00:25<00:09, 50.8MiB/s]\u001b[A\n"," 75%|███████▌  | 1.41G/1.87G [00:26<00:08, 52.4MiB/s]\u001b[A\n"," 76%|███████▌  | 1.41G/1.87G [00:26<00:08, 51.0MiB/s]\u001b[A\n"," 76%|███████▌  | 1.42G/1.87G [00:26<00:08, 52.2MiB/s]\u001b[A\n"," 76%|███████▌  | 1.42G/1.87G [00:26<00:08, 52.8MiB/s]\u001b[A\n"," 76%|███████▋  | 1.43G/1.87G [00:26<00:08, 53.0MiB/s]\u001b[A\n"," 77%|███████▋  | 1.43G/1.87G [00:26<00:08, 53.7MiB/s]\u001b[A\n"," 77%|███████▋  | 1.44G/1.87G [00:26<00:07, 53.9MiB/s]\u001b[A\n"," 77%|███████▋  | 1.44G/1.87G [00:26<00:07, 54.2MiB/s]\u001b[A\n"," 78%|███████▊  | 1.45G/1.87G [00:26<00:07, 54.4MiB/s]\u001b[A\n"," 78%|███████▊  | 1.46G/1.87G [00:26<00:07, 54.6MiB/s]\u001b[A\n"," 78%|███████▊  | 1.46G/1.87G [00:27<00:07, 54.5MiB/s]\u001b[A\n"," 78%|███████▊  | 1.47G/1.87G [00:27<00:07, 53.8MiB/s]\u001b[A\n"," 79%|███████▉  | 1.47G/1.87G [00:27<00:07, 53.2MiB/s]\u001b[A\n"," 79%|███████▉  | 1.48G/1.87G [00:27<00:07, 53.0MiB/s]\u001b[A\n"," 79%|███████▉  | 1.48G/1.87G [00:27<00:07, 53.3MiB/s]\u001b[A\n"," 80%|███████▉  | 1.49G/1.87G [00:27<00:07, 53.3MiB/s]\u001b[A\n"," 80%|███████▉  | 1.49G/1.87G [00:27<00:07, 53.3MiB/s]\u001b[A\n"," 80%|████████  | 1.50G/1.87G [00:27<00:06, 53.6MiB/s]\u001b[A\n"," 81%|████████  | 1.50G/1.87G [00:27<00:06, 54.0MiB/s]\u001b[A\n"," 81%|████████  | 1.51G/1.87G [00:28<00:06, 54.1MiB/s]\u001b[A\n"," 81%|████████  | 1.51G/1.87G [00:28<00:06, 53.6MiB/s]\u001b[A\n"," 81%|████████▏ | 1.52G/1.87G [00:28<00:06, 53.9MiB/s]\u001b[A\n"," 82%|████████▏ | 1.53G/1.87G [00:28<00:06, 53.9MiB/s]\u001b[A\n"," 82%|████████▏ | 1.53G/1.87G [00:28<00:06, 54.1MiB/s]\u001b[A\n"," 82%|████████▏ | 1.54G/1.87G [00:28<00:06, 54.3MiB/s]\u001b[A\n"," 83%|████████▎ | 1.54G/1.87G [00:28<00:05, 54.4MiB/s]\u001b[A\n"," 83%|████████▎ | 1.55G/1.87G [00:28<00:05, 54.5MiB/s]\u001b[A\n"," 83%|████████▎ | 1.55G/1.87G [00:28<00:05, 54.5MiB/s]\u001b[A\n"," 83%|████████▎ | 1.56G/1.87G [00:28<00:05, 54.5MiB/s]\u001b[A\n"," 84%|████████▎ | 1.56G/1.87G [00:29<00:05, 54.6MiB/s]\u001b[A\n"," 84%|████████▍ | 1.57G/1.87G [00:29<00:05, 54.5MiB/s]\u001b[A\n"," 84%|████████▍ | 1.57G/1.87G [00:29<00:05, 54.6MiB/s]\u001b[A\n"," 85%|████████▍ | 1.58G/1.87G [00:29<00:05, 54.1MiB/s]\u001b[A\n"," 85%|████████▍ | 1.59G/1.87G [00:29<00:05, 54.1MiB/s]\u001b[A\n"," 85%|████████▌ | 1.59G/1.87G [00:29<00:05, 54.2MiB/s]\u001b[A\n"," 85%|████████▌ | 1.60G/1.87G [00:29<00:05, 54.0MiB/s]\u001b[A\n"," 86%|████████▌ | 1.60G/1.87G [00:29<00:04, 53.8MiB/s]\u001b[A\n"," 86%|████████▌ | 1.61G/1.87G [00:29<00:04, 53.8MiB/s]\u001b[A\n"," 86%|████████▋ | 1.61G/1.87G [00:29<00:04, 53.8MiB/s]\u001b[A\n"," 87%|████████▋ | 1.62G/1.87G [00:30<00:04, 53.7MiB/s]\u001b[A\n"," 87%|████████▋ | 1.62G/1.87G [00:30<00:04, 53.8MiB/s]\u001b[A\n"," 87%|████████▋ | 1.63G/1.87G [00:30<00:04, 53.4MiB/s]\u001b[A\n"," 87%|████████▋ | 1.63G/1.87G [00:30<00:04, 53.6MiB/s]\u001b[A\n"," 88%|████████▊ | 1.64G/1.87G [00:30<00:04, 53.5MiB/s]\u001b[A\n"," 88%|████████▊ | 1.64G/1.87G [00:30<00:04, 53.4MiB/s]\u001b[A\n"," 88%|████████▊ | 1.65G/1.87G [00:30<00:04, 53.2MiB/s]\u001b[A\n"," 89%|████████▊ | 1.66G/1.87G [00:30<00:03, 53.3MiB/s]\u001b[A\n"," 89%|████████▉ | 1.66G/1.87G [00:30<00:03, 53.2MiB/s]\u001b[A\n"," 89%|████████▉ | 1.67G/1.87G [00:30<00:03, 53.2MiB/s]\u001b[A\n"," 89%|████████▉ | 1.67G/1.87G [00:31<00:03, 53.7MiB/s]\u001b[A\n"," 90%|████████▉ | 1.68G/1.87G [00:31<00:03, 53.7MiB/s]\u001b[A\n"," 90%|█████████ | 1.68G/1.87G [00:31<00:03, 53.8MiB/s]\u001b[A\n"," 90%|█████████ | 1.69G/1.87G [00:31<00:03, 53.8MiB/s]\u001b[A\n"," 91%|█████████ | 1.69G/1.87G [00:31<00:03, 53.5MiB/s]\u001b[A\n"," 91%|█████████ | 1.70G/1.87G [00:31<00:03, 53.7MiB/s]\u001b[A\n"," 91%|█████████ | 1.70G/1.87G [00:31<00:03, 54.0MiB/s]\u001b[A\n"," 92%|█████████▏| 1.71G/1.87G [00:31<00:02, 54.3MiB/s]\u001b[A\n"," 92%|█████████▏| 1.71G/1.87G [00:31<00:02, 54.0MiB/s]\u001b[A\n"," 92%|█████████▏| 1.72G/1.87G [00:31<00:02, 54.3MiB/s]\u001b[A\n"," 92%|█████████▏| 1.73G/1.87G [00:32<00:02, 54.2MiB/s]\u001b[A\n"," 93%|█████████▎| 1.73G/1.87G [00:32<00:02, 52.8MiB/s]\u001b[A\n"," 93%|█████████▎| 1.74G/1.87G [00:32<00:02, 52.6MiB/s]\u001b[A\n"," 93%|█████████▎| 1.74G/1.87G [00:32<00:02, 51.5MiB/s]\u001b[A\n"," 94%|█████████▎| 1.75G/1.87G [00:32<00:02, 52.6MiB/s]\u001b[A\n"," 94%|█████████▍| 1.75G/1.87G [00:32<00:02, 53.0MiB/s]\u001b[A\n"," 94%|█████████▍| 1.76G/1.87G [00:32<00:02, 53.6MiB/s]\u001b[A\n"," 94%|█████████▍| 1.76G/1.87G [00:32<00:01, 53.9MiB/s]\u001b[A\n"," 95%|█████████▍| 1.77G/1.87G [00:32<00:01, 53.8MiB/s]\u001b[A\n"," 95%|█████████▌| 1.77G/1.87G [00:32<00:01, 53.8MiB/s]\u001b[A\n"," 95%|█████████▌| 1.78G/1.87G [00:33<00:01, 53.9MiB/s]\u001b[A\n"," 96%|█████████▌| 1.79G/1.87G [00:33<00:01, 53.9MiB/s]\u001b[A\n"," 96%|█████████▌| 1.79G/1.87G [00:33<00:01, 54.1MiB/s]\u001b[A\n"," 96%|█████████▌| 1.80G/1.87G [00:33<00:01, 54.2MiB/s]\u001b[A\n"," 96%|█████████▋| 1.80G/1.87G [00:33<00:01, 54.3MiB/s]\u001b[A\n"," 97%|█████████▋| 1.81G/1.87G [00:33<00:01, 54.5MiB/s]\u001b[A\n"," 97%|█████████▋| 1.81G/1.87G [00:33<00:01, 54.4MiB/s]\u001b[A\n"," 97%|█████████▋| 1.82G/1.87G [00:33<00:00, 54.0MiB/s]\u001b[A\n"," 98%|█████████▊| 1.82G/1.87G [00:33<00:00, 54.1MiB/s]\u001b[A\n"," 98%|█████████▊| 1.83G/1.87G [00:33<00:00, 53.8MiB/s]\u001b[A\n"," 98%|█████████▊| 1.83G/1.87G [00:34<00:00, 53.6MiB/s]\u001b[A\n"," 98%|█████████▊| 1.84G/1.87G [00:34<00:00, 53.8MiB/s]\u001b[A\n"," 99%|█████████▉| 1.85G/1.87G [00:34<00:00, 53.7MiB/s]\u001b[A\n"," 99%|█████████▉| 1.85G/1.87G [00:34<00:00, 53.7MiB/s]\u001b[A\n"," 99%|█████████▉| 1.86G/1.87G [00:34<00:00, 53.9MiB/s]\u001b[A\n","100%|█████████▉| 1.86G/1.87G [00:34<00:00, 54.2MiB/s]\u001b[A\n","100%|█████████▉| 1.87G/1.87G [00:34<00:00, 55.0MiB/s]\u001b[A"]}],"source":["# Define the path where XTTS v2.0.1 files will be downloaded\n","CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n","os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n","\n","# DVAE files\n","DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n","MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n","\n","# Set the path to the downloaded files\n","DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n","MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n","\n","# download DVAE files if needed\n","if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n","    print(\" > Downloading DVAE files!\")\n","    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n","\n","# Download XTTS v2.0 checkpoint if needed\n","TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n","XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n","\n","# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n","TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n","XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n","\n","# download XTTS v2.0 files if needed\n","if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n","    print(\" > Downloading XTTS v2.0 files!\")\n","    ModelManager._download_model_files(\n","        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n","    )"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:51.019790Z","iopub.status.busy":"2024-10-12T06:40:51.019394Z","iopub.status.idle":"2024-10-12T06:40:51.024292Z","shell.execute_reply":"2024-10-12T06:40:51.023278Z","shell.execute_reply.started":"2024-10-12T06:40:51.019752Z"},"trusted":true},"outputs":[],"source":["training_dir = \"/kaggle/input/tech-data\""]},{"cell_type":"markdown","metadata":{},"source":["### Batch Size ###\n","\n","* BATCH_SIZE is the amount of items being loaded into VRAM/memory at once.\n","\n","* GRAD_ACCUM_STEPS is the amount of times we perform a forward pass with BATCH_SIZE amount of items before updating the parameters according to the SGD algorithm."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:54.379601Z","iopub.status.busy":"2024-10-12T06:40:54.379226Z","iopub.status.idle":"2024-10-12T06:40:54.384038Z","shell.execute_reply":"2024-10-12T06:40:54.383164Z","shell.execute_reply.started":"2024-10-12T06:40:54.379564Z"},"trusted":true},"outputs":[],"source":["\n","OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  \n","START_WITH_EVAL = True  \n","BATCH_SIZE = 1\n","GRAD_ACUMM_STEPS = 252\n","LANGUAGE = \"en\""]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Config ###\n","\n","Note that the lengths below are lengths of WAV files. So if your WAV file has a sample rate of 22050, then a a max_wav_length of 370000 is: 370000/22050 = ~16.78 seconds long.\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:40:57.379842Z","iopub.status.busy":"2024-10-12T06:40:57.379338Z","iopub.status.idle":"2024-10-12T06:40:57.385823Z","shell.execute_reply":"2024-10-12T06:40:57.384845Z","shell.execute_reply.started":"2024-10-12T06:40:57.379691Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1.87G/1.87G [00:45<00:00, 55.0MiB/s]\u001b[A"]}],"source":["model_args = GPTArgs(\n","    max_conditioning_length=143677,#the audio you will use for conditioning latents should be less than this \n","    min_conditioning_length=66150,#and more than this\n","    debug_loading_failures=True,#this will print output to console and help you find problems in your ds\n","    max_wav_length=223997,#set this to >= the longest audio in your dataset  \n","    max_text_length=200, \n","    mel_norm_file=MEL_NORM_FILE,\n","    dvae_checkpoint=DVAE_CHECKPOINT,\n","    xtts_checkpoint=XTTS_CHECKPOINT,  \n","    tokenizer_file=TOKENIZER_FILE,\n","    gpt_num_audio_tokens=1026, \n","    gpt_start_audio_token=1024,\n","    gpt_stop_audio_token=1025,\n","    gpt_use_masking_gt_prompt_approach=True,\n","    gpt_use_perceiver_resampler=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Audio Config ###\n","\n","The default is 22050 for input and 24000 for output. \n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:41:01.390640Z","iopub.status.busy":"2024-10-12T06:41:01.389861Z","iopub.status.idle":"2024-10-12T06:41:01.395102Z","shell.execute_reply":"2024-10-12T06:41:01.394081Z","shell.execute_reply.started":"2024-10-12T06:41:01.390596Z"},"trusted":true},"outputs":[],"source":["audio_config = XttsAudioConfig(sample_rate=16000, dvae_sample_rate=16000, output_sample_rate=24000) "]},{"cell_type":"markdown","metadata":{},"source":["### Speaker Reference ###\n","\n","This is the audio file that will be used for creating the conditioning latent and speaker embedding. \n","\n","Choosing the right speaker reference is **VERY** important for XTTS-v2. It can completely change how your model will sound. Even two clips taken from the same recording of the same speaker can produce markedly different outputs."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:41:04.739849Z","iopub.status.busy":"2024-10-12T06:41:04.739061Z","iopub.status.idle":"2024-10-12T06:41:04.743847Z","shell.execute_reply":"2024-10-12T06:41:04.742896Z","shell.execute_reply.started":"2024-10-12T06:41:04.739808Z"},"trusted":true},"outputs":[],"source":["SPEAKER_REFERENCE = \"/kaggle/input/tech-data/wavs/audio_1.wav\""]},{"cell_type":"markdown","metadata":{},"source":["### Trainer Config ###\n","\n","- Fine-tune for about 100,000 dataset items but stop early if test outputs sound good; listening is better than just monitoring loss.\n","- US male voices fine-tune faster; complex accents take longer.\n","- Keep test sentences consistent for comparison across model runs.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:41:09.863434Z","iopub.status.busy":"2024-10-12T06:41:09.862871Z","iopub.status.idle":"2024-10-12T06:41:21.271337Z","shell.execute_reply":"2024-10-12T06:41:21.270371Z","shell.execute_reply.started":"2024-10-12T06:41:09.863386Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(f, map_location=map_location, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/tortoise/arch_utils.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.mel_norms = torch.load(f)\n"]},{"name":"stdout","output_type":"stream","text":[">> DVAE weights restored from: /kaggle/working/run/XTTS_v2.0_original_model_files/dvae.pth\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py:185: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dvae_checkpoint = torch.load(self.args.dvae_checkpoint, map_location=torch.device(\"cpu\"))\n"]}],"source":["config = GPTTrainerConfig(\n","    run_eval=True,\n","    epochs = 1000, # assuming you want to end training manually w/ keyboard interrupt\n","    output_path=OUT_PATH,\n","    model_args=model_args,\n","    run_name=RUN_NAME,\n","    project_name=PROJECT_NAME,\n","    run_description=\"\"\"\n","        GPT XTTS training\n","        \"\"\",\n","    dashboard_logger=DASHBOARD_LOGGER,\n","    wandb_entity=None,\n","    logger_uri=LOGGER_URI,\n","    audio=audio_config,\n","    batch_size=BATCH_SIZE,\n","    batch_group_size=48,\n","    eval_batch_size=BATCH_SIZE,\n","    num_loader_workers=8, #consider decreasing if your jupyter env is crashing or similar\n","    eval_split_max_size=256, \n","    print_step=50, \n","    plot_step=100, \n","    log_model_step=1000, \n","    save_step=9999999999, #ALREADY SAVES EVERY EPOCHMaking this high on kaggle because Output dir is limited in size. I changed this to be size of training set/2 so I would effectively have a checkpoint every half epoch \n","    save_n_checkpoints=1,#if you want to store multiple checkpoint rather than just 1, increase this\n","    save_checkpoints=False,# Making this False on kaggle because Output dir is limited\n","    print_eval=False,\n","    optimizer=\"AdamW\",\n","    optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n","    optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n","    lr=5e-06,  \n","    lr_scheduler=\"MultiStepLR\",\n","    lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n","    test_sentences=[ \n","        {\n","            \"text\": \"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n","            \"speaker_wav\": SPEAKER_REFERENCE, \n","            \"language\": LANGUAGE,\n","        },\n","        {\n","            \"text\": \"This cake is great. It's so delicious and moist.\",\n","            \"speaker_wav\": SPEAKER_REFERENCE,\n","            \"language\": LANGUAGE,\n","        },\n","        {\n","            \"text\": \"And soon, nothing more terrible, nothing more true, and specious stuff that says no rational being can fear a thing it will not feel, not seeing that this is what we fear.\",\n","            \"speaker_wav\": SPEAKER_REFERENCE,\n","            \"language\": LANGUAGE,\n","        }\n","        \n","    ],\n",") \n","\n","model = GPTTrainer.init_from_config(config)"]},{"cell_type":"markdown","metadata":{},"source":["### Load Dataset ###\n","\n","The evaluation set is 1% of the training data by default. "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:41:30.860147Z","iopub.status.busy":"2024-10-12T06:41:30.859524Z","iopub.status.idle":"2024-10-12T06:41:30.904723Z","shell.execute_reply":"2024-10-12T06:41:30.903806Z","shell.execute_reply.started":"2024-10-12T06:41:30.860098Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" | > Found 1151 files in /kaggle/input/tech-data\n"]}],"source":["dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"metadata.txt\", language=LANGUAGE, path=training_dir\n",")\n","train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True, eval_split_size=0.02)"]},{"cell_type":"markdown","metadata":{},"source":["### Train! ###"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T06:41:34.340662Z","iopub.status.busy":"2024-10-12T06:41:34.339817Z","iopub.status.idle":"2024-10-12T07:23:00.515954Z","shell.execute_reply":"2024-10-12T07:23:00.514317Z","shell.execute_reply.started":"2024-10-12T06:41:34.340616Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    TrainerArgs(\n","        restore_path=None,\n","        skip_train_epoch=False,\n","        start_with_eval=START_WITH_EVAL,\n","        grad_accum_steps=GRAD_ACUMM_STEPS,\n","    ),\n","    config,\n","    output_path=OUT_PATH,\n","    model=model,\n","    train_samples=train_samples,\n","    eval_samples=eval_samples,\n",")\n","trainer.fit()"]},{"cell_type":"markdown","metadata":{},"source":["Your fine-tuned model will be stored in /kaggle/working/run"]},{"cell_type":"markdown","metadata":{},"source":["# Testing on different sentences"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T07:58:16.972506Z","iopub.status.busy":"2024-10-12T07:58:16.971600Z","iopub.status.idle":"2024-10-12T07:59:06.304970Z","shell.execute_reply":"2024-10-12T07:59:06.304020Z","shell.execute_reply.started":"2024-10-12T07:58:16.972464Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n"," > Using model: xtts\n","/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(f, map_location=map_location, **kwargs)\n"," > Text: Text for TTS\n"," > Text splitted to sentences.\n","['Text for TTS']\n"," > Processing time: 13.16327714920044\n"," > Real-time factor: 2.5231506898984937\n"," > Saving output to /kaggle/working/run/kaggletest-October-12-2024_06+41AM-0000000/output.wav\n","\u001b[0m"]}],"source":["!tts --text \"Text for TTS\" \\\n","    --model_path \"/kaggle/working/run/XTTS_v2.0_original_model_files\" \\\n","    --config_path \"/kaggle/working/run/kaggletest-October-12-2024_06+41AM-0000000/config.json\" \\\n","    --out_path \"/kaggle/working/run/kaggletest-October-12-2024_06+41AM-0000000/output.wav\" \\\n","    --language_idx en \\\n","    --speaker_wav \"/kaggle/input/tech-data/wavs/audio_1.wav\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T07:50:20.351594Z","iopub.status.busy":"2024-10-12T07:50:20.350561Z","iopub.status.idle":"2024-10-12T07:50:33.238598Z","shell.execute_reply":"2024-10-12T07:50:33.237563Z","shell.execute_reply.started":"2024-10-12T07:50:20.351542Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5859366,"sourceId":9603815,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
