{"cells":[{"cell_type":"markdown","metadata":{},"source":["# FINE-TUNING XTTS-v2 For  Hindi Language #"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Your Dataset:\n","\n","\n","### Dataset of this Notebook:\n","The VoxPopuli dataset was chosen for Hindi TTS training and modified to match the LJSpeech format.\n","\n","Simply discard any audio that is significantly worse quality than the rest. Examples of unpromising source audio include: constant background noise (e.g., coughing, clapping, laughter), excessive clipping in waveform view of Audacity, poor quality recording with constant whine/noise/etc. .\n","\n","### Making an LJSpeech Style Dataset:\n","The format for LJSpeech is a dir that contains two things: a metadata.csv file and a dir called 'wavs' that contains your voice recordings. Each line of the metadata.csv file includes:\n","\n","1. The name of an audio file\n","2. The text for that file. E.g., \"Jane eyre by Charlotte Bronte. Chapter 1.\"\n","3. The normalised text. E.g., \"Jane eyre by Charlotte Bronte. Chapter one.\"\n","\n","**If you are fine-tuning XTTS-v2 you don't need to worry about normalising your text, because it gets done for you automatically at training time. So your second and third columns can be identical.**\n","\n","### Note on Model Performance:\n","Some degree of repetition/mushy mouth sounds seems to be inherent to the model. Even the pre-trained voices that comes packaged with TTS suffer from this problem to a small extent. There are two ways I'm aware of to improve your performance (these are already covered in other parts of this/my other notebook, but I'm putting it here again since it's pretty important):\n","\n","1. Improve the quality of your training data. Cull problematic items. Get more training data if your dataset is really small.\n","2. The model does not generalise well to unseen sequence lengths. If you only fine-tune on 10s long audio clips and then try to produce a 1s clip at inference time, it will probably struggle. Make sure you have a good distribution of training lengths. Note that when you try to generate audio from a long text string, *this program is automatically splitting that long string of text into several shorter strings*, because the model cannot generate sequences of arbitrary length. If you are suffering from garbled/repetitious outputs, then I recommend putting some print statements in the 'split_sentence\" function in TTS.tts.layers.xtts.tokenizer. This will show you how your long text is being split up. If you see that your bad outputs are only occuring when the model is trying to generate audio for very short sequences or very long sequences, then you know what needs to be addressed. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:24:36.105560Z","iopub.status.busy":"2024-10-14T05:24:36.105261Z","iopub.status.idle":"2024-10-14T05:26:30.125533Z","shell.execute_reply":"2024-10-14T05:26:30.124376Z","shell.execute_reply.started":"2024-10-14T05:24:36.105528Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/coqui-ai/TTS\n","  Cloning https://github.com/coqui-ai/TTS to /tmp/pip-req-build-8r49_zoc\n","  Running command git clone --filter=blob:none --quiet https://github.com/coqui-ai/TTS /tmp/pip-req-build-8r49_zoc\n","  Resolved https://github.com/coqui-ai/TTS to commit dbf1a08a0d4e47fdad6172e433eeb34bc6b13b4e\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: cython>=0.29.30 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.0.10)\n","Requirement already satisfied: scipy>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (1.14.1)\n","Requirement already satisfied: torch>=2.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2.4.0)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2.4.0)\n","Requirement already satisfied: soundfile>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.12.1)\n","Requirement already satisfied: librosa>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.10.2.post1)\n","Collecting scikit-learn>=1.3.0 (from TTS==0.22.0)\n","  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting inflect>=5.6.0 (from TTS==0.22.0)\n","  Downloading inflect-7.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (4.66.4)\n","Collecting anyascii>=0.3.0 (from TTS==0.22.0)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: pyyaml>=6.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (6.0.2)\n","Requirement already satisfied: fsspec>=2023.6.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (2024.6.1)\n","Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.9.5)\n","Collecting packaging>=23.1 (from TTS==0.22.0)\n","  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Collecting mutagen==1.47.0 (from TTS==0.22.0)\n","  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: flask>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.0.3)\n","Collecting pysbd>=0.3.4 (from TTS==0.22.0)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Collecting umap-learn>=0.5.1 (from TTS==0.22.0)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n","Collecting pandas<2.0,>=1.4 (from TTS==0.22.0)\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.7.5)\n","Collecting trainer>=0.0.36 (from TTS==0.22.0)\n","  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n","Collecting coqpit>=0.0.16 (from TTS==0.22.0)\n","  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.42.1)\n","Collecting pypinyin (from TTS==0.22.0)\n","  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting hangul-romanize (from TTS==0.22.0)\n","  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut-2.2.3.tar.gz (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jamo (from TTS==0.22.0)\n","  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (3.2.4)\n","Collecting g2pkk>=0.1.1 (from TTS==0.22.0)\n","  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n","Collecting bangla (from TTS==0.22.0)\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n","Collecting bnnumerizer (from TTS==0.22.0)\n","  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting bnunicodenormalizer (from TTS==0.22.0)\n","  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n","Collecting einops>=0.6.0 (from TTS==0.22.0)\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: transformers>=4.33.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (4.45.1)\n","Collecting encodec>=0.1.1 (from TTS==0.22.0)\n","  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting unidecode>=1.3.2 (from TTS==0.22.0)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n","Collecting num2words (from TTS==0.22.0)\n","  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: spacy>=3 in /opt/conda/lib/python3.10/site-packages (from spacy[ja]>=3->TTS==0.22.0) (3.7.6)\n","Collecting numpy==1.22.0 (from TTS==0.22.0)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numba>=0.57.0 in /opt/conda/lib/python3.10/site-packages (from TTS==0.22.0) (0.60.0)\n","Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.15.0)\n","Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n","Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n","Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS==0.22.0) (4.0.3)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (3.0.4)\n","Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS==0.22.0) (1.8.2)\n","Requirement already satisfied: more-itertools>=8.5.0 in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS==0.22.0) (10.3.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS==0.22.0) (4.3.0)\n","Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (3.0.1)\n","INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n","Collecting librosa>=0.10.0 (from TTS==0.22.0)\n","  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n","  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (5.1.1)\n","Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS==0.22.0) (1.0.8)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (2.9.0.post0)\n","Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->TTS==0.22.0) (0.6.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.57.0->TTS==0.22.0) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0,>=1.4->TTS==0.22.0) (2024.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->TTS==0.22.0) (3.5.0)\n","INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n","Collecting scipy>=1.11.2 (from TTS==0.22.0)\n","  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.0->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.9.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (70.0.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.4.1)\n","Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS==0.22.0)\n","  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS==0.22.0)\n","  Downloading SudachiDict_core-20240716-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS==0.22.0) (3.15.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS==0.22.0) (1.13.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.36->TTS==0.22.0) (5.9.3)\n","Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.36->TTS==0.22.0) (2.16.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS==0.22.0) (0.20.0)\n","Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS==0.22.0)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS==0.22.0) (2.22)\n","Collecting tzlocal (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n","  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS==0.22.0) (2.1.5)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.2.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.10.0->TTS==0.22.0) (3.11.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (13.7.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (7.0.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1->TTS==0.22.0) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.62.2)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.20.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (0.7.2)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.18.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.2)\n","Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n","Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n","Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n","Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n","Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n","Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n","Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SudachiDict_core-20240716-py3-none-any.whl (72.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: TTS, gruut, encodec, bnnumerizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n","  Building wheel for TTS (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for TTS: filename=TTS-0.22.0-cp310-cp310-linux_x86_64.whl size=904087 sha256=50eb0d83d166b5aab2a52e8e2a336618ed1e14d3ce6070e672531e2344e82051\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-izcow1yn/wheels/45/77/39/42afe730577d15c3bd85ce6db4c0dbb8fcf06e021a8b68bf62\n","  Building wheel for gruut (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75791 sha256=623aae78085f7212f1b772f18857dba4224f53b72d4152883c5b7f925d3bb8f3\n","  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n","  Building wheel for encodec (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=c42dcc635e375a91775d7a766bba7ff3d63a037edd9b5dd6fd16548d0ae27a40\n","  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n","  Building wheel for bnnumerizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=56218d53a08f0a1156527669d9d62a7dce4603b16e2fa826214c39c55d7b61ca\n","  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n","  Building wheel for gruut-ipa (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=c41d98c05a8b673e0a4a2df9db8b3a9afa3977e47389dcb4c1cc5f5f6fd7b7e2\n","  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n","  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498315 sha256=d194c0c611fa892f1c3c68c44cc56818e17c26cb4c6177dba0f0b78c1c7151a0\n","  Stored in directory: /root/.cache/pip/wheels/83/80/5f/775b357ae61d7cb68793327c7470d848715cbc60bb373af8dd\n","  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=9d0662b59f593d2f9daa5380c8f575753ae1e104fe3a93e10591d0b34ab8206f\n","  Stored in directory: /root/.cache/pip/wheels/64/8d/b7/d484d224facd899ed188e00374f25dd3f19d1a3f53da6517bd\n","  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=5ad0806e1435478985d72cb1982723482fedc994ed78790ff419ec6c87a2a7bb\n","  Stored in directory: /root/.cache/pip/wheels/ab/bd/96/5ddde14e8e6932a96f12c5ab5de62b619d39e2507d7daf5188\n","  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968768 sha256=4132b6fbffbb833372b2cb249969f2298d4a38dc5a4218a7ef72c667eeeec5d1\n","  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n","Successfully built TTS gruut encodec bnnumerizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n","Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, bnunicodenormalizer, bnnumerizer, bangla, unidecode, tzlocal, sudachidict-core, python-crfsuite, pysbd, pypinyin, packaging, numpy, num2words, networkx, mutagen, jsonlines, gruut-ipa, einops, coqpit, anyascii, scipy, pandas, inflect, g2pkk, dateparser, trainer, scikit-learn, gruut, pynndescent, librosa, encodec, umap-learn, TTS\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.3\n","    Uninstalling networkx-3.3:\n","      Successfully uninstalled networkx-3.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.14.1\n","    Uninstalling scipy-1.14.1:\n","      Successfully uninstalled scipy-1.14.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.10.2.post1\n","    Uninstalling librosa-0.10.2.post1:\n","      Successfully uninstalled librosa-0.10.2.post1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.8.3 requires cubinlinker, which is not installed.\n","cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires ptxcompiler, which is not installed.\n","cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\n","albucore 0.0.17 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n","albumentations 1.4.17 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n","apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n","arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","bayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.22.0 which is incompatible.\n","beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\n","bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\n","bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\n","cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.22.0 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","cudf 24.8.3 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-cuda 24.8.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.8.3 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n","dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\n","dipy 1.9.0 requires numpy>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\n","jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","mne 1.8.0 requires numpy<3,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.22.0 which is incompatible.\n","pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","pylibraft 24.8.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","raft-dask 24.8.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","rmm 24.8.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n","tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n","tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n","ucx-py 0.39.2 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","ucxx 0.39.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n","xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n","xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 einops-0.8.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 inflect-7.4.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 mutagen-1.47.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 packaging-24.1 pandas-1.5.3 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 scikit-learn-1.5.2 scipy-1.11.4 sudachidict-core-20240716 sudachipy-0.6.8 trainer-0.0.36 tzlocal-5.2 umap-learn-0.5.6 unidecode-1.3.8\n"]}],"source":["!pip install git+https://github.com/coqui-ai/TTS"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:26:48.212770Z","iopub.status.busy":"2024-10-14T05:26:48.211955Z","iopub.status.idle":"2024-10-14T05:27:11.802068Z","shell.execute_reply":"2024-10-14T05:27:11.801040Z","shell.execute_reply.started":"2024-10-14T05:26:48.212707Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.37.1\n","  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (0.25.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (1.22.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (2.32.3)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.1)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.1) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.1) (2024.8.30)\n","Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.0\n","    Uninstalling tokenizers-0.20.0:\n","      Successfully uninstalled tokenizers-0.20.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.45.1\n","    Uninstalling transformers-4.45.1:\n","      Successfully uninstalled transformers-4.45.1\n","Successfully installed tokenizers-0.15.2 transformers-4.37.1\n"]}],"source":["!pip install transformers==4.37.1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T13:39:41.540234Z","iopub.status.busy":"2024-04-22T13:39:41.539854Z","iopub.status.idle":"2024-04-22T13:39:41.54496Z","shell.execute_reply":"2024-04-22T13:39:41.543875Z","shell.execute_reply.started":"2024-04-22T13:39:41.540197Z"},"trusted":true},"outputs":[],"source":["###updated training zone####"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:27:27.600471Z","iopub.status.busy":"2024-10-14T05:27:27.600021Z","iopub.status.idle":"2024-10-14T05:27:49.976018Z","shell.execute_reply":"2024-10-14T05:27:49.975034Z","shell.execute_reply.started":"2024-10-14T05:27:27.600414Z"},"trusted":true},"outputs":[],"source":["from trainer import Trainer, TrainerArgs\n","#from trainer.logging.wandb_logger import WandbLogger\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n","from TTS.utils.manage import ModelManager\n","\n","\n","import sys\n","import os\n","import wandb"]},{"cell_type":"markdown","metadata":{},"source":["### Monkey Patching for wandb (!!!) ###\n","\n","XTTS-v2 uses tensorboard for logging by default. Officially wandb is supported, but it breaks things when I've used it (after a few epochs creating massive amounts of artifact files). For this reason I've monkey patched the offending method so that no artifacts are added.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:28:03.043605Z","iopub.status.busy":"2024-10-14T05:28:03.042909Z","iopub.status.idle":"2024-10-14T05:28:03.048845Z","shell.execute_reply":"2024-10-14T05:28:03.047948Z","shell.execute_reply.started":"2024-10-14T05:28:03.043561Z"},"trusted":true},"outputs":[],"source":["from trainer.logging.wandb_logger import WandbLogger"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:28:06.183623Z","iopub.status.busy":"2024-10-14T05:28:06.182736Z","iopub.status.idle":"2024-10-14T05:28:06.188182Z","shell.execute_reply":"2024-10-14T05:28:06.187274Z","shell.execute_reply.started":"2024-10-14T05:28:06.183572Z"},"trusted":true},"outputs":[],"source":["def add_artifact(self, file_or_dir, name, artifact_type, aliases=None):\n","    ###instead of adding artifact, do nothing###\n","    print(f\"========Ignoring artifact: {name} {file_or_dir}========\")\n","    return\n","\n","\n","WandbLogger.add_artifact = add_artifact"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:28:08.282571Z","iopub.status.busy":"2024-10-14T05:28:08.281682Z","iopub.status.idle":"2024-10-14T05:28:08.286591Z","shell.execute_reply":"2024-10-14T05:28:08.285701Z","shell.execute_reply.started":"2024-10-14T05:28:08.282528Z"},"trusted":true},"outputs":[],"source":["# Logging parameters\n","RUN_NAME = \"kaggletest\"\n","PROJECT_NAME = \"gore\" \n","DASHBOARD_LOGGER = \"wandb\" \n","LOGGER_URI = None"]},{"cell_type":"markdown","metadata":{},"source":["### Dir for Training Run ###\n","\n","Set the training run to store model files in the persistent /kaggle/working dir. \n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:28:27.520469Z","iopub.status.busy":"2024-10-14T05:28:27.519660Z","iopub.status.idle":"2024-10-14T05:28:27.524835Z","shell.execute_reply":"2024-10-14T05:28:27.523894Z","shell.execute_reply.started":"2024-10-14T05:28:27.520431Z"},"trusted":true},"outputs":[],"source":["OUT_PATH = '/kaggle/working/run/'\n","os.makedirs(OUT_PATH, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Retreive the base model files. "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:28:30.047672Z","iopub.status.busy":"2024-10-14T05:28:30.046871Z","iopub.status.idle":"2024-10-14T05:29:09.542808Z","shell.execute_reply":"2024-10-14T05:29:09.541734Z","shell.execute_reply.started":"2024-10-14T05:28:30.047629Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" > Downloading DVAE files!\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0.00/1.07k [00:00<?, ?iB/s]\n","100%|██████████| 1.07k/1.07k [00:00<00:00, 4.31kiB/s]\n","\n","  1%|          | 1.06M/211M [00:00<00:19, 10.6MiB/s]\u001b[A\n","  3%|▎         | 5.54M/211M [00:00<00:06, 30.7MiB/s]\u001b[A\n","  5%|▌         | 11.0M/211M [00:00<00:04, 41.7MiB/s]\u001b[A\n","  8%|▊         | 16.5M/211M [00:00<00:04, 47.0MiB/s]\u001b[A\n"," 10%|█         | 21.9M/211M [00:00<00:03, 49.5MiB/s]\u001b[A\n"," 13%|█▎        | 27.4M/211M [00:00<00:03, 51.3MiB/s]\u001b[A\n"," 15%|█▌        | 32.5M/211M [00:00<00:03, 51.0MiB/s]\u001b[A\n"," 18%|█▊        | 37.7M/211M [00:00<00:03, 51.1MiB/s]\u001b[A\n"," 21%|██        | 43.2M/211M [00:00<00:03, 52.3MiB/s]\u001b[A\n"," 23%|██▎       | 48.5M/211M [00:01<00:03, 52.7MiB/s]\u001b[A\n"," 26%|██▌       | 54.0M/211M [00:01<00:02, 53.5MiB/s]\u001b[A\n"," 28%|██▊       | 59.5M/211M [00:01<00:02, 53.7MiB/s]\u001b[A\n"," 31%|███       | 64.9M/211M [00:01<00:02, 53.9MiB/s]\u001b[A\n"," 33%|███▎      | 70.3M/211M [00:01<00:02, 53.9MiB/s]\u001b[A\n"," 36%|███▌      | 75.7M/211M [00:01<00:02, 53.9MiB/s]\u001b[A\n"," 39%|███▊      | 81.1M/211M [00:01<00:02, 54.0MiB/s]\u001b[A\n"," 41%|████      | 86.5M/211M [00:01<00:02, 53.7MiB/s]\u001b[A\n"," 44%|████▎     | 92.0M/211M [00:01<00:02, 54.2MiB/s]\u001b[A\n"," 46%|████▋     | 97.5M/211M [00:01<00:02, 54.4MiB/s]\u001b[A\n"," 49%|████▉     | 103M/211M [00:02<00:01, 54.6MiB/s] \u001b[A\n"," 52%|█████▏    | 109M/211M [00:02<00:01, 54.8MiB/s]\u001b[A\n"," 54%|█████▍    | 114M/211M [00:02<00:01, 54.1MiB/s]\u001b[A\n"," 57%|█████▋    | 119M/211M [00:02<00:01, 53.6MiB/s]\u001b[A\n"," 59%|█████▉    | 125M/211M [00:02<00:01, 54.3MiB/s]\u001b[A\n"," 62%|██████▏   | 131M/211M [00:02<00:01, 55.1MiB/s]\u001b[A\n"," 65%|██████▍   | 136M/211M [00:02<00:01, 55.5MiB/s]\u001b[A\n"," 67%|██████▋   | 142M/211M [00:02<00:01, 55.8MiB/s]\u001b[A\n"," 70%|███████   | 148M/211M [00:02<00:01, 55.2MiB/s]\u001b[A\n"," 73%|███████▎  | 153M/211M [00:02<00:01, 52.5MiB/s]\u001b[A\n"," 75%|███████▌  | 158M/211M [00:03<00:01, 49.0MiB/s]\u001b[A\n"," 78%|███████▊  | 164M/211M [00:03<00:00, 50.1MiB/s]\u001b[A\n"," 80%|████████  | 169M/211M [00:03<00:00, 51.3MiB/s]\u001b[A\n"," 83%|████████▎ | 175M/211M [00:03<00:00, 52.1MiB/s]\u001b[A\n"," 85%|████████▌ | 180M/211M [00:03<00:00, 52.7MiB/s]\u001b[A\n"," 88%|████████▊ | 185M/211M [00:03<00:00, 53.2MiB/s]\u001b[A\n"," 91%|█████████ | 191M/211M [00:03<00:00, 53.7MiB/s]\u001b[A\n"," 93%|█████████▎| 196M/211M [00:03<00:00, 53.8MiB/s]\u001b[A\n"," 96%|█████████▌| 202M/211M [00:03<00:00, 54.0MiB/s]\u001b[A\n"," 98%|█████████▊| 207M/211M [00:03<00:00, 54.3MiB/s]\u001b[A"]},{"name":"stdout","output_type":"stream","text":[" > Downloading XTTS v2.0 files!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 211M/211M [00:04<00:00, 50.1MiB/s]\n","\n","100%|██████████| 361k/361k [00:00<00:00, 1.70MiB/s]\n","\n","  0%|          | 3.87M/1.87G [00:00<00:48, 38.7MiB/s]\u001b[A\n","  1%|          | 9.37M/1.87G [00:00<00:38, 48.3MiB/s]\u001b[A\n","  1%|          | 14.9M/1.87G [00:00<00:36, 51.3MiB/s]\u001b[A\n","  1%|          | 20.2M/1.87G [00:00<00:35, 52.2MiB/s]\u001b[A\n","  1%|▏         | 25.6M/1.87G [00:00<00:34, 52.9MiB/s]\u001b[A\n","  2%|▏         | 30.9M/1.87G [00:00<00:35, 52.2MiB/s]\u001b[A\n","  2%|▏         | 36.2M/1.87G [00:00<00:35, 51.9MiB/s]\u001b[A\n","  2%|▏         | 41.5M/1.87G [00:00<00:34, 52.3MiB/s]\u001b[A\n","  3%|▎         | 46.8M/1.87G [00:00<00:34, 52.6MiB/s]\u001b[A\n","  3%|▎         | 52.2M/1.87G [00:01<00:34, 52.9MiB/s]\u001b[A\n","  3%|▎         | 57.5M/1.87G [00:01<00:34, 53.1MiB/s]\u001b[A\n","  3%|▎         | 62.8M/1.87G [00:01<00:33, 53.1MiB/s]\u001b[A\n","  4%|▎         | 68.2M/1.87G [00:01<00:34, 52.9MiB/s]\u001b[A\n","  4%|▍         | 73.8M/1.87G [00:01<00:33, 53.9MiB/s]\u001b[A\n","  4%|▍         | 79.4M/1.87G [00:01<00:32, 54.7MiB/s]\u001b[A\n","  5%|▍         | 85.1M/1.87G [00:01<00:32, 55.2MiB/s]\u001b[A\n","  5%|▍         | 90.7M/1.87G [00:01<00:31, 55.5MiB/s]\u001b[A\n","  5%|▌         | 96.3M/1.87G [00:01<00:31, 55.6MiB/s]\u001b[A\n","  5%|▌         | 102M/1.87G [00:01<00:31, 55.7MiB/s] \u001b[A\n","  6%|▌         | 108M/1.87G [00:02<00:31, 55.9MiB/s]\u001b[A\n","  6%|▌         | 113M/1.87G [00:02<00:31, 56.0MiB/s]\u001b[A\n","  6%|▋         | 119M/1.87G [00:02<00:31, 55.9MiB/s]\u001b[A\n","  7%|▋         | 124M/1.87G [00:02<00:31, 55.5MiB/s]\u001b[A\n","  7%|▋         | 130M/1.87G [00:02<00:31, 55.8MiB/s]\u001b[A\n","  7%|▋         | 136M/1.87G [00:02<00:30, 56.0MiB/s]\u001b[A\n","  8%|▊         | 141M/1.87G [00:02<00:31, 55.4MiB/s]\u001b[A\n","  8%|▊         | 147M/1.87G [00:02<00:31, 55.3MiB/s]\u001b[A\n","  8%|▊         | 152M/1.87G [00:02<00:31, 54.8MiB/s]\u001b[A\n","  8%|▊         | 158M/1.87G [00:02<00:32, 53.3MiB/s]\u001b[A\n","  9%|▊         | 163M/1.87G [00:03<00:32, 53.2MiB/s]\u001b[A\n","  9%|▉         | 169M/1.87G [00:03<00:31, 53.4MiB/s]\u001b[A\n","  9%|▉         | 174M/1.87G [00:03<00:31, 53.5MiB/s]\u001b[A\n"," 10%|▉         | 179M/1.87G [00:03<00:31, 53.3MiB/s]\u001b[A\n"," 10%|▉         | 185M/1.87G [00:03<00:31, 53.3MiB/s]\u001b[A\n"," 10%|█         | 190M/1.87G [00:03<00:30, 54.3MiB/s]\u001b[A\n"," 10%|█         | 196M/1.87G [00:03<00:30, 55.0MiB/s]\u001b[A\n"," 11%|█         | 202M/1.87G [00:03<00:30, 55.3MiB/s]\u001b[A\n"," 11%|█         | 207M/1.87G [00:03<00:29, 55.5MiB/s]\u001b[A\n"," 11%|█▏        | 213M/1.87G [00:03<00:29, 55.8MiB/s]\u001b[A\n"," 12%|█▏        | 218M/1.87G [00:04<00:29, 55.9MiB/s]\u001b[A\n"," 12%|█▏        | 224M/1.87G [00:04<00:29, 55.8MiB/s]\u001b[A\n"," 12%|█▏        | 230M/1.87G [00:04<00:29, 56.0MiB/s]\u001b[A\n"," 13%|█▎        | 235M/1.87G [00:04<00:29, 55.9MiB/s]\u001b[A\n"," 13%|█▎        | 241M/1.87G [00:04<00:29, 56.0MiB/s]\u001b[A\n"," 13%|█▎        | 246M/1.87G [00:04<00:28, 56.1MiB/s]\u001b[A\n"," 13%|█▎        | 252M/1.87G [00:04<00:28, 56.2MiB/s]\u001b[A\n"," 14%|█▍        | 258M/1.87G [00:04<00:28, 56.2MiB/s]\u001b[A\n"," 14%|█▍        | 263M/1.87G [00:04<00:28, 56.4MiB/s]\u001b[A\n"," 14%|█▍        | 269M/1.87G [00:04<00:28, 56.4MiB/s]\u001b[A\n"," 15%|█▍        | 275M/1.87G [00:05<00:28, 56.4MiB/s]\u001b[A\n"," 15%|█▌        | 280M/1.87G [00:05<00:28, 56.5MiB/s]\u001b[A\n"," 15%|█▌        | 286M/1.87G [00:05<00:28, 56.4MiB/s]\u001b[A\n"," 16%|█▌        | 292M/1.87G [00:05<00:28, 56.1MiB/s]\u001b[A\n"," 16%|█▌        | 297M/1.87G [00:05<00:28, 55.5MiB/s]\u001b[A\n"," 16%|█▌        | 303M/1.87G [00:05<00:28, 54.7MiB/s]\u001b[A\n"," 17%|█▋        | 308M/1.87G [00:05<00:28, 54.4MiB/s]\u001b[A\n"," 17%|█▋        | 314M/1.87G [00:05<00:28, 54.2MiB/s]\u001b[A\n"," 17%|█▋        | 319M/1.87G [00:05<00:28, 54.3MiB/s]\u001b[A\n"," 17%|█▋        | 325M/1.87G [00:05<00:28, 54.2MiB/s]\u001b[A\n"," 18%|█▊        | 330M/1.87G [00:06<00:28, 54.0MiB/s]\u001b[A\n"," 18%|█▊        | 335M/1.87G [00:06<00:28, 53.9MiB/s]\u001b[A\n"," 18%|█▊        | 341M/1.87G [00:06<00:28, 54.1MiB/s]\u001b[A\n"," 19%|█▊        | 346M/1.87G [00:06<00:28, 53.8MiB/s]\u001b[A\n"," 19%|█▉        | 352M/1.87G [00:06<00:28, 53.8MiB/s]\u001b[A\n"," 19%|█▉        | 357M/1.87G [00:06<00:28, 53.7MiB/s]\u001b[A\n"," 19%|█▉        | 363M/1.87G [00:06<00:28, 53.5MiB/s]\u001b[A\n"," 20%|█▉        | 368M/1.87G [00:06<00:28, 53.3MiB/s]\u001b[A\n"," 20%|█▉        | 373M/1.87G [00:06<00:27, 53.9MiB/s]\u001b[A\n"," 20%|██        | 379M/1.87G [00:06<00:27, 54.3MiB/s]\u001b[A\n"," 21%|██        | 385M/1.87G [00:07<00:27, 54.8MiB/s]\u001b[A\n"," 21%|██        | 390M/1.87G [00:07<00:26, 55.0MiB/s]\u001b[A\n"," 21%|██        | 396M/1.87G [00:07<00:26, 55.0MiB/s]\u001b[A\n"," 21%|██▏       | 401M/1.87G [00:07<00:26, 55.0MiB/s]\u001b[A\n"," 22%|██▏       | 407M/1.87G [00:07<00:26, 54.8MiB/s]\u001b[A\n"," 22%|██▏       | 412M/1.87G [00:07<00:26, 54.9MiB/s]\u001b[A\n"," 22%|██▏       | 418M/1.87G [00:07<00:26, 54.5MiB/s]\u001b[A\n"," 23%|██▎       | 423M/1.87G [00:07<00:26, 54.3MiB/s]\u001b[A\n"," 23%|██▎       | 428M/1.87G [00:07<00:26, 54.1MiB/s]\u001b[A\n"," 23%|██▎       | 434M/1.87G [00:07<00:26, 53.8MiB/s]\u001b[A\n"," 24%|██▎       | 439M/1.87G [00:08<00:26, 53.9MiB/s]\u001b[A\n"," 24%|██▍       | 445M/1.87G [00:08<00:26, 54.2MiB/s]\u001b[A\n"," 24%|██▍       | 450M/1.87G [00:08<00:26, 54.2MiB/s]\u001b[A\n"," 24%|██▍       | 456M/1.87G [00:08<00:26, 54.1MiB/s]\u001b[A\n"," 25%|██▍       | 461M/1.87G [00:08<00:26, 53.3MiB/s]\u001b[A\n"," 25%|██▍       | 466M/1.87G [00:08<00:26, 53.3MiB/s]\u001b[A\n"," 25%|██▌       | 472M/1.87G [00:08<00:27, 50.1MiB/s]\u001b[A\n"," 26%|██▌       | 477M/1.87G [00:08<00:27, 50.8MiB/s]\u001b[A\n"," 26%|██▌       | 482M/1.87G [00:08<00:26, 51.6MiB/s]\u001b[A\n"," 26%|██▌       | 488M/1.87G [00:08<00:26, 52.2MiB/s]\u001b[A\n"," 26%|██▋       | 493M/1.87G [00:09<00:25, 53.2MiB/s]\u001b[A\n"," 27%|██▋       | 499M/1.87G [00:09<00:25, 53.5MiB/s]\u001b[A\n"," 27%|██▋       | 504M/1.87G [00:09<00:25, 53.2MiB/s]\u001b[A\n"," 27%|██▋       | 509M/1.87G [00:09<00:25, 53.0MiB/s]\u001b[A\n"," 28%|██▊       | 515M/1.87G [00:09<00:25, 53.0MiB/s]\u001b[A\n"," 28%|██▊       | 520M/1.87G [00:09<00:25, 53.3MiB/s]\u001b[A\n"," 28%|██▊       | 525M/1.87G [00:09<00:25, 53.5MiB/s]\u001b[A\n"," 28%|██▊       | 531M/1.87G [00:09<00:25, 53.4MiB/s]\u001b[A\n"," 29%|██▊       | 536M/1.87G [00:09<00:24, 53.6MiB/s]\u001b[A\n"," 29%|██▉       | 542M/1.87G [00:09<00:24, 53.6MiB/s]\u001b[A\n"," 29%|██▉       | 547M/1.87G [00:10<00:24, 53.5MiB/s]\u001b[A\n"," 30%|██▉       | 552M/1.87G [00:10<00:24, 53.7MiB/s]\u001b[A\n"," 30%|██▉       | 558M/1.87G [00:10<00:24, 53.7MiB/s]\u001b[A\n"," 30%|███       | 563M/1.87G [00:10<00:24, 53.5MiB/s]\u001b[A\n"," 30%|███       | 568M/1.87G [00:10<00:24, 53.6MiB/s]\u001b[A\n"," 31%|███       | 574M/1.87G [00:10<00:36, 35.6MiB/s]\u001b[A\n"," 31%|███       | 579M/1.87G [00:10<00:32, 39.5MiB/s]\u001b[A\n"," 31%|███▏      | 584M/1.87G [00:10<00:29, 42.8MiB/s]\u001b[A\n"," 32%|███▏      | 590M/1.87G [00:11<00:27, 45.8MiB/s]\u001b[A\n"," 32%|███▏      | 595M/1.87G [00:11<00:26, 48.0MiB/s]\u001b[A\n"," 32%|███▏      | 601M/1.87G [00:11<00:25, 49.6MiB/s]\u001b[A\n"," 32%|███▏      | 606M/1.87G [00:11<00:24, 50.5MiB/s]\u001b[A\n"," 33%|███▎      | 611M/1.87G [00:11<00:24, 51.2MiB/s]\u001b[A\n"," 33%|███▎      | 617M/1.87G [00:11<00:24, 51.9MiB/s]\u001b[A\n"," 33%|███▎      | 622M/1.87G [00:11<00:23, 52.5MiB/s]\u001b[A\n"," 34%|███▎      | 627M/1.87G [00:11<00:23, 52.7MiB/s]\u001b[A\n"," 34%|███▍      | 633M/1.87G [00:11<00:23, 53.0MiB/s]\u001b[A\n"," 34%|███▍      | 638M/1.87G [00:11<00:23, 53.1MiB/s]\u001b[A\n"," 34%|███▍      | 643M/1.87G [00:12<00:22, 53.5MiB/s]\u001b[A\n"," 35%|███▍      | 649M/1.87G [00:12<00:22, 54.5MiB/s]\u001b[A\n"," 35%|███▌      | 655M/1.87G [00:12<00:21, 55.2MiB/s]\u001b[A\n"," 35%|███▌      | 660M/1.87G [00:12<00:21, 55.4MiB/s]\u001b[A\n"," 36%|███▌      | 666M/1.87G [00:12<00:21, 55.7MiB/s]\u001b[A\n"," 36%|███▌      | 672M/1.87G [00:12<00:21, 55.8MiB/s]\u001b[A\n"," 36%|███▋      | 677M/1.87G [00:12<00:21, 56.1MiB/s]\u001b[A\n"," 37%|███▋      | 683M/1.87G [00:12<00:21, 56.2MiB/s]\u001b[A\n"," 37%|███▋      | 689M/1.87G [00:12<00:20, 56.3MiB/s]\u001b[A\n"," 37%|███▋      | 694M/1.87G [00:12<00:20, 56.4MiB/s]\u001b[A\n"," 37%|███▋      | 700M/1.87G [00:13<00:20, 56.4MiB/s]\u001b[A\n"," 38%|███▊      | 706M/1.87G [00:13<00:20, 56.4MiB/s]\u001b[A\n"," 38%|███▊      | 711M/1.87G [00:13<00:20, 56.5MiB/s]\u001b[A\n"," 38%|███▊      | 717M/1.87G [00:13<00:20, 56.3MiB/s]\u001b[A\n"," 39%|███▊      | 723M/1.87G [00:13<00:20, 56.5MiB/s]\u001b[A\n"," 39%|███▉      | 728M/1.87G [00:13<00:20, 56.5MiB/s]\u001b[A\n"," 39%|███▉      | 734M/1.87G [00:13<00:20, 56.6MiB/s]\u001b[A\n"," 40%|███▉      | 740M/1.87G [00:13<00:19, 56.4MiB/s]\u001b[A\n"," 40%|███▉      | 745M/1.87G [00:13<00:19, 56.5MiB/s]\u001b[A\n"," 40%|████      | 751M/1.87G [00:13<00:19, 56.1MiB/s]\u001b[A\n"," 41%|████      | 757M/1.87G [00:14<00:19, 56.0MiB/s]\u001b[A\n"," 41%|████      | 762M/1.87G [00:14<00:19, 55.9MiB/s]\u001b[A\n"," 41%|████      | 768M/1.87G [00:14<00:19, 55.7MiB/s]\u001b[A\n"," 41%|████▏     | 773M/1.87G [00:14<00:19, 55.5MiB/s]\u001b[A\n"," 42%|████▏     | 779M/1.87G [00:14<00:19, 55.5MiB/s]\u001b[A\n"," 42%|████▏     | 784M/1.87G [00:14<00:19, 55.6MiB/s]\u001b[A\n"," 42%|████▏     | 790M/1.87G [00:14<00:19, 55.7MiB/s]\u001b[A\n"," 43%|████▎     | 796M/1.87G [00:14<00:19, 55.6MiB/s]\u001b[A\n"," 43%|████▎     | 801M/1.87G [00:14<00:19, 55.8MiB/s]\u001b[A\n"," 43%|████▎     | 807M/1.87G [00:14<00:19, 55.7MiB/s]\u001b[A\n"," 43%|████▎     | 813M/1.87G [00:15<00:18, 56.1MiB/s]\u001b[A\n"," 44%|████▍     | 818M/1.87G [00:15<00:18, 56.5MiB/s]\u001b[A\n"," 44%|████▍     | 824M/1.87G [00:15<00:18, 56.6MiB/s]\u001b[A\n"," 44%|████▍     | 830M/1.87G [00:15<00:18, 56.5MiB/s]\u001b[A\n"," 45%|████▍     | 835M/1.87G [00:15<00:18, 56.6MiB/s]\u001b[A\n"," 45%|████▌     | 841M/1.87G [00:15<00:18, 56.6MiB/s]\u001b[A\n"," 45%|████▌     | 847M/1.87G [00:15<00:18, 56.3MiB/s]\u001b[A\n"," 46%|████▌     | 852M/1.87G [00:15<00:18, 56.4MiB/s]\u001b[A\n"," 46%|████▌     | 858M/1.87G [00:15<00:17, 56.5MiB/s]\u001b[A\n"," 46%|████▌     | 864M/1.87G [00:15<00:17, 56.5MiB/s]\u001b[A\n"," 47%|████▋     | 869M/1.87G [00:16<00:17, 56.6MiB/s]\u001b[A\n"," 47%|████▋     | 875M/1.87G [00:16<00:17, 56.5MiB/s]\u001b[A\n"," 47%|████▋     | 881M/1.87G [00:16<00:17, 56.7MiB/s]\u001b[A\n"," 47%|████▋     | 886M/1.87G [00:16<00:17, 56.5MiB/s]\u001b[A\n"," 48%|████▊     | 892M/1.87G [00:16<00:17, 56.6MiB/s]\u001b[A\n"," 48%|████▊     | 898M/1.87G [00:16<00:17, 56.3MiB/s]\u001b[A\n"," 48%|████▊     | 903M/1.87G [00:16<00:17, 55.8MiB/s]\u001b[A\n"," 49%|████▊     | 909M/1.87G [00:16<00:17, 55.5MiB/s]\u001b[A\n"," 49%|████▉     | 914M/1.87G [00:16<00:17, 55.0MiB/s]\u001b[A\n"," 49%|████▉     | 920M/1.87G [00:16<00:17, 54.8MiB/s]\u001b[A\n"," 50%|████▉     | 925M/1.87G [00:17<00:17, 54.7MiB/s]\u001b[A\n"," 50%|████▉     | 931M/1.87G [00:17<00:17, 54.7MiB/s]\u001b[A\n"," 50%|█████     | 936M/1.87G [00:17<00:17, 54.8MiB/s]\u001b[A\n"," 50%|█████     | 942M/1.87G [00:17<00:16, 54.8MiB/s]\u001b[A\n"," 51%|█████     | 947M/1.87G [00:17<00:16, 54.9MiB/s]\u001b[A\n"," 51%|█████     | 953M/1.87G [00:17<00:16, 55.3MiB/s]\u001b[A\n"," 51%|█████▏    | 959M/1.87G [00:17<00:16, 55.8MiB/s]\u001b[A\n"," 52%|█████▏    | 964M/1.87G [00:17<00:16, 55.2MiB/s]\u001b[A\n"," 52%|█████▏    | 970M/1.87G [00:17<00:16, 55.5MiB/s]\u001b[A\n"," 52%|█████▏    | 976M/1.87G [00:17<00:15, 55.9MiB/s]\u001b[A\n"," 53%|█████▎    | 981M/1.87G [00:18<00:15, 56.3MiB/s]\u001b[A\n"," 53%|█████▎    | 987M/1.87G [00:18<00:15, 56.4MiB/s]\u001b[A\n"," 53%|█████▎    | 993M/1.87G [00:18<00:15, 56.6MiB/s]\u001b[A\n"," 53%|█████▎    | 998M/1.87G [00:18<00:15, 55.7MiB/s]\u001b[A\n"," 54%|█████▎    | 1.00G/1.87G [00:18<00:15, 55.0MiB/s]\u001b[A\n"," 54%|█████▍    | 1.01G/1.87G [00:18<00:16, 53.1MiB/s]\u001b[A\n"," 54%|█████▍    | 1.01G/1.87G [00:18<00:16, 52.3MiB/s]\u001b[A\n"," 55%|█████▍    | 1.02G/1.87G [00:18<00:16, 52.8MiB/s]\u001b[A\n"," 55%|█████▍    | 1.03G/1.87G [00:18<00:15, 53.3MiB/s]\u001b[A\n"," 55%|█████▌    | 1.03G/1.87G [00:19<00:15, 53.8MiB/s]\u001b[A\n"," 55%|█████▌    | 1.04G/1.87G [00:19<00:15, 54.1MiB/s]\u001b[A\n"," 56%|█████▌    | 1.04G/1.87G [00:19<00:15, 54.5MiB/s]\u001b[A\n"," 56%|█████▌    | 1.05G/1.87G [00:19<00:14, 54.8MiB/s]\u001b[A\n"," 56%|█████▋    | 1.05G/1.87G [00:19<00:14, 54.9MiB/s]\u001b[A\n"," 57%|█████▋    | 1.06G/1.87G [00:19<00:14, 55.4MiB/s]\u001b[A\n"," 57%|█████▋    | 1.06G/1.87G [00:19<00:14, 55.7MiB/s]\u001b[A\n"," 57%|█████▋    | 1.07G/1.87G [00:19<00:14, 55.8MiB/s]\u001b[A\n"," 58%|█████▊    | 1.08G/1.87G [00:19<00:14, 55.8MiB/s]\u001b[A\n"," 58%|█████▊    | 1.08G/1.87G [00:19<00:14, 53.5MiB/s]\u001b[A\n"," 58%|█████▊    | 1.09G/1.87G [00:20<00:14, 53.1MiB/s]\u001b[A\n"," 58%|█████▊    | 1.09G/1.87G [00:20<00:14, 52.4MiB/s]\u001b[A\n"," 59%|█████▊    | 1.10G/1.87G [00:20<00:14, 52.8MiB/s]\u001b[A\n"," 59%|█████▉    | 1.10G/1.87G [00:20<00:15, 50.2MiB/s]\u001b[A\n"," 59%|█████▉    | 1.11G/1.87G [00:20<00:14, 51.1MiB/s]\u001b[A\n"," 60%|█████▉    | 1.11G/1.87G [00:20<00:14, 52.4MiB/s]\u001b[A\n"," 60%|█████▉    | 1.12G/1.87G [00:20<00:13, 53.5MiB/s]\u001b[A\n"," 60%|██████    | 1.12G/1.87G [00:20<00:13, 54.2MiB/s]\u001b[A\n"," 61%|██████    | 1.13G/1.87G [00:20<00:13, 55.0MiB/s]\u001b[A\n"," 61%|██████    | 1.14G/1.87G [00:20<00:13, 55.1MiB/s]\u001b[A\n"," 61%|██████    | 1.14G/1.87G [00:21<00:13, 55.4MiB/s]\u001b[A\n"," 61%|██████▏   | 1.15G/1.87G [00:21<00:12, 55.7MiB/s]\u001b[A\n"," 62%|██████▏   | 1.15G/1.87G [00:21<00:13, 54.9MiB/s]\u001b[A\n"," 62%|██████▏   | 1.16G/1.87G [00:21<00:13, 54.5MiB/s]\u001b[A\n"," 62%|██████▏   | 1.16G/1.87G [00:21<00:12, 54.4MiB/s]\u001b[A\n"," 63%|██████▎   | 1.17G/1.87G [00:21<00:12, 54.3MiB/s]\u001b[A\n"," 63%|██████▎   | 1.17G/1.87G [00:21<00:12, 54.1MiB/s]\u001b[A\n"," 63%|██████▎   | 1.18G/1.87G [00:21<00:12, 53.9MiB/s]\u001b[A\n"," 63%|██████▎   | 1.19G/1.87G [00:21<00:12, 54.0MiB/s]\u001b[A\n"," 64%|██████▍   | 1.19G/1.87G [00:21<00:12, 54.0MiB/s]\u001b[A\n"," 64%|██████▍   | 1.20G/1.87G [00:22<00:12, 54.0MiB/s]\u001b[A\n"," 64%|██████▍   | 1.20G/1.87G [00:22<00:12, 54.1MiB/s]\u001b[A\n"," 65%|██████▍   | 1.21G/1.87G [00:22<00:12, 54.1MiB/s]\u001b[A\n"," 65%|██████▍   | 1.21G/1.87G [00:22<00:12, 54.4MiB/s]\u001b[A\n"," 65%|██████▌   | 1.22G/1.87G [00:22<00:11, 55.0MiB/s]\u001b[A\n"," 66%|██████▌   | 1.22G/1.87G [00:22<00:11, 55.2MiB/s]\u001b[A\n"," 66%|██████▌   | 1.23G/1.87G [00:22<00:11, 55.5MiB/s]\u001b[A\n"," 66%|██████▌   | 1.24G/1.87G [00:22<00:11, 55.7MiB/s]\u001b[A\n"," 66%|██████▋   | 1.24G/1.87G [00:22<00:11, 55.2MiB/s]\u001b[A\n"," 67%|██████▋   | 1.25G/1.87G [00:22<00:11, 54.6MiB/s]\u001b[A\n"," 67%|██████▋   | 1.25G/1.87G [00:23<00:11, 54.4MiB/s]\u001b[A\n"," 67%|██████▋   | 1.26G/1.87G [00:23<00:11, 54.0MiB/s]\u001b[A\n"," 68%|██████▊   | 1.26G/1.87G [00:23<00:11, 53.8MiB/s]\u001b[A\n"," 68%|██████▊   | 1.27G/1.87G [00:23<00:11, 53.2MiB/s]\u001b[A\n"," 68%|██████▊   | 1.27G/1.87G [00:23<00:11, 53.4MiB/s]\u001b[A\n"," 68%|██████▊   | 1.28G/1.87G [00:23<00:10, 53.8MiB/s]\u001b[A\n"," 69%|██████▊   | 1.28G/1.87G [00:23<00:10, 54.0MiB/s]\u001b[A\n"," 69%|██████▉   | 1.29G/1.87G [00:23<00:10, 53.8MiB/s]\u001b[A\n"," 69%|██████▉   | 1.29G/1.87G [00:23<00:10, 53.8MiB/s]\u001b[A\n"," 70%|██████▉   | 1.30G/1.87G [00:23<00:10, 54.7MiB/s]\u001b[A\n"," 70%|██████▉   | 1.31G/1.87G [00:24<00:10, 54.3MiB/s]\u001b[A\n"," 70%|███████   | 1.31G/1.87G [00:24<00:10, 54.1MiB/s]\u001b[A\n"," 71%|███████   | 1.32G/1.87G [00:24<00:10, 54.1MiB/s]\u001b[A\n"," 71%|███████   | 1.32G/1.87G [00:24<00:10, 53.7MiB/s]\u001b[A\n"," 71%|███████   | 1.33G/1.87G [00:24<00:10, 53.7MiB/s]\u001b[A\n"," 71%|███████▏  | 1.33G/1.87G [00:24<00:09, 53.6MiB/s]\u001b[A\n"," 72%|███████▏  | 1.34G/1.87G [00:24<00:09, 53.5MiB/s]\u001b[A\n"," 72%|███████▏  | 1.34G/1.87G [00:24<00:09, 53.5MiB/s]\u001b[A\n"," 72%|███████▏  | 1.35G/1.87G [00:24<00:09, 53.6MiB/s]\u001b[A\n"," 73%|███████▎  | 1.35G/1.87G [00:24<00:09, 53.7MiB/s]\u001b[A\n"," 73%|███████▎  | 1.36G/1.87G [00:25<00:09, 54.5MiB/s]\u001b[A\n"," 73%|███████▎  | 1.37G/1.87G [00:25<00:09, 55.2MiB/s]\u001b[A\n"," 73%|███████▎  | 1.37G/1.87G [00:25<00:08, 55.9MiB/s]\u001b[A\n"," 74%|███████▎  | 1.38G/1.87G [00:25<00:08, 55.1MiB/s]\u001b[A\n"," 74%|███████▍  | 1.38G/1.87G [00:25<00:08, 54.8MiB/s]\u001b[A\n"," 74%|███████▍  | 1.39G/1.87G [00:25<00:08, 54.5MiB/s]\u001b[A\n"," 75%|███████▍  | 1.39G/1.87G [00:25<00:08, 54.1MiB/s]\u001b[A\n"," 75%|███████▍  | 1.40G/1.87G [00:25<00:08, 54.6MiB/s]\u001b[A\n"," 75%|███████▌  | 1.40G/1.87G [00:25<00:08, 55.0MiB/s]\u001b[A\n"," 76%|███████▌  | 1.41G/1.87G [00:26<00:08, 55.5MiB/s]\u001b[A\n"," 76%|███████▌  | 1.42G/1.87G [00:26<00:08, 55.8MiB/s]\u001b[A\n"," 76%|███████▌  | 1.42G/1.87G [00:26<00:07, 56.1MiB/s]\u001b[A\n"," 76%|███████▋  | 1.43G/1.87G [00:26<00:07, 56.0MiB/s]\u001b[A\n"," 77%|███████▋  | 1.43G/1.87G [00:26<00:07, 55.3MiB/s]\u001b[A\n"," 77%|███████▋  | 1.44G/1.87G [00:26<00:07, 55.0MiB/s]\u001b[A\n"," 77%|███████▋  | 1.44G/1.87G [00:26<00:07, 54.7MiB/s]\u001b[A\n"," 78%|███████▊  | 1.45G/1.87G [00:26<00:07, 54.6MiB/s]\u001b[A\n"," 78%|███████▊  | 1.46G/1.87G [00:26<00:07, 55.1MiB/s]\u001b[A\n"," 78%|███████▊  | 1.46G/1.87G [00:26<00:07, 55.5MiB/s]\u001b[A\n"," 79%|███████▊  | 1.47G/1.87G [00:27<00:07, 55.9MiB/s]\u001b[A\n"," 79%|███████▉  | 1.47G/1.87G [00:27<00:07, 56.3MiB/s]\u001b[A\n"," 79%|███████▉  | 1.48G/1.87G [00:27<00:06, 56.4MiB/s]\u001b[A\n"," 79%|███████▉  | 1.48G/1.87G [00:27<00:06, 56.6MiB/s]\u001b[A\n"," 80%|███████▉  | 1.49G/1.87G [00:27<00:06, 56.4MiB/s]\u001b[A\n"," 80%|████████  | 1.50G/1.87G [00:27<00:06, 56.7MiB/s]\u001b[A\n"," 80%|████████  | 1.50G/1.87G [00:27<00:06, 56.3MiB/s]\u001b[A\n"," 81%|████████  | 1.51G/1.87G [00:27<00:06, 55.5MiB/s]\u001b[A\n"," 81%|████████  | 1.51G/1.87G [00:27<00:06, 55.5MiB/s]\u001b[A\n"," 81%|████████  | 1.52G/1.87G [00:27<00:06, 55.1MiB/s]\u001b[A\n"," 82%|████████▏ | 1.52G/1.87G [00:28<00:06, 54.9MiB/s]\u001b[A\n"," 82%|████████▏ | 1.53G/1.87G [00:28<00:06, 54.9MiB/s]\u001b[A\n"," 82%|████████▏ | 1.53G/1.87G [00:28<00:06, 55.1MiB/s]\u001b[A\n"," 82%|████████▏ | 1.54G/1.87G [00:28<00:05, 55.2MiB/s]\u001b[A\n"," 83%|████████▎ | 1.55G/1.87G [00:28<00:05, 54.6MiB/s]\u001b[A\n"," 83%|████████▎ | 1.55G/1.87G [00:28<00:05, 53.1MiB/s]\u001b[A\n"," 83%|████████▎ | 1.56G/1.87G [00:28<00:06, 49.0MiB/s]\u001b[A\n"," 84%|████████▎ | 1.56G/1.87G [00:28<00:06, 48.7MiB/s]\u001b[A\n"," 84%|████████▍ | 1.57G/1.87G [00:28<00:06, 48.8MiB/s]\u001b[A\n"," 84%|████████▍ | 1.57G/1.87G [00:28<00:06, 48.6MiB/s]\u001b[A\n"," 84%|████████▍ | 1.58G/1.87G [00:29<00:06, 48.7MiB/s]\u001b[A\n"," 85%|████████▍ | 1.58G/1.87G [00:29<00:05, 48.1MiB/s]\u001b[A\n"," 85%|████████▍ | 1.59G/1.87G [00:29<00:05, 47.8MiB/s]\u001b[A\n"," 85%|████████▌ | 1.59G/1.87G [00:29<00:08, 32.5MiB/s]\u001b[A\n"," 85%|████████▌ | 1.60G/1.87G [00:29<00:07, 37.6MiB/s]\u001b[A\n"," 86%|████████▌ | 1.60G/1.87G [00:29<00:06, 41.9MiB/s]\u001b[A\n"," 86%|████████▌ | 1.61G/1.87G [00:29<00:05, 45.6MiB/s]\u001b[A\n"," 86%|████████▋ | 1.61G/1.87G [00:29<00:05, 48.4MiB/s]\u001b[A\n"," 87%|████████▋ | 1.62G/1.87G [00:30<00:04, 50.5MiB/s]\u001b[A\n"," 87%|████████▋ | 1.62G/1.87G [00:30<00:04, 52.1MiB/s]\u001b[A\n"," 87%|████████▋ | 1.63G/1.87G [00:30<00:04, 53.4MiB/s]\u001b[A\n"," 88%|████████▊ | 1.63G/1.87G [00:30<00:04, 54.1MiB/s]\u001b[A\n"," 88%|████████▊ | 1.64G/1.87G [00:30<00:04, 54.6MiB/s]\u001b[A\n"," 88%|████████▊ | 1.65G/1.87G [00:30<00:04, 54.8MiB/s]\u001b[A\n"," 88%|████████▊ | 1.65G/1.87G [00:30<00:03, 55.1MiB/s]\u001b[A\n"," 89%|████████▊ | 1.66G/1.87G [00:30<00:03, 55.4MiB/s]\u001b[A\n"," 89%|████████▉ | 1.66G/1.87G [00:30<00:03, 55.7MiB/s]\u001b[A\n"," 89%|████████▉ | 1.67G/1.87G [00:30<00:03, 55.8MiB/s]\u001b[A\n"," 90%|████████▉ | 1.67G/1.87G [00:31<00:03, 55.8MiB/s]\u001b[A\n"," 90%|████████▉ | 1.68G/1.87G [00:31<00:03, 55.9MiB/s]\u001b[A\n"," 90%|█████████ | 1.69G/1.87G [00:31<00:03, 55.9MiB/s]\u001b[A\n"," 91%|█████████ | 1.69G/1.87G [00:31<00:03, 56.1MiB/s]\u001b[A\n"," 91%|█████████ | 1.70G/1.87G [00:31<00:03, 55.8MiB/s]\u001b[A\n"," 91%|█████████ | 1.70G/1.87G [00:31<00:02, 55.9MiB/s]\u001b[A\n"," 91%|█████████▏| 1.71G/1.87G [00:31<00:02, 56.0MiB/s]\u001b[A\n"," 92%|█████████▏| 1.71G/1.87G [00:31<00:02, 56.2MiB/s]\u001b[A\n"," 92%|█████████▏| 1.72G/1.87G [00:31<00:02, 56.4MiB/s]\u001b[A\n"," 92%|█████████▏| 1.72G/1.87G [00:31<00:02, 56.5MiB/s]\u001b[A\n"," 93%|█████████▎| 1.73G/1.87G [00:32<00:02, 56.7MiB/s]\u001b[A\n"," 93%|█████████▎| 1.74G/1.87G [00:32<00:02, 56.7MiB/s]\u001b[A\n"," 93%|█████████▎| 1.74G/1.87G [00:32<00:02, 56.9MiB/s]\u001b[A\n"," 94%|█████████▎| 1.75G/1.87G [00:32<00:02, 57.0MiB/s]\u001b[A\n"," 94%|█████████▍| 1.75G/1.87G [00:32<00:02, 56.5MiB/s]\u001b[A\n"," 94%|█████████▍| 1.76G/1.87G [00:32<00:01, 56.5MiB/s]\u001b[A\n"," 94%|█████████▍| 1.76G/1.87G [00:32<00:01, 54.9MiB/s]\u001b[A\n"," 95%|█████████▍| 1.77G/1.87G [00:32<00:01, 54.4MiB/s]\u001b[A\n"," 95%|█████████▌| 1.78G/1.87G [00:32<00:01, 54.2MiB/s]\u001b[A\n"," 95%|█████████▌| 1.78G/1.87G [00:32<00:01, 54.4MiB/s]\u001b[A\n"," 96%|█████████▌| 1.79G/1.87G [00:33<00:01, 54.4MiB/s]\u001b[A\n"," 96%|█████████▌| 1.79G/1.87G [00:33<00:01, 54.3MiB/s]\u001b[A\n"," 96%|█████████▌| 1.80G/1.87G [00:33<00:01, 53.9MiB/s]\u001b[A\n"," 97%|█████████▋| 1.80G/1.87G [00:33<00:01, 53.8MiB/s]\u001b[A\n"," 97%|█████████▋| 1.81G/1.87G [00:33<00:01, 53.5MiB/s]\u001b[A\n"," 97%|█████████▋| 1.81G/1.87G [00:33<00:01, 53.6MiB/s]\u001b[A\n"," 97%|█████████▋| 1.82G/1.87G [00:33<00:00, 54.0MiB/s]\u001b[A\n"," 98%|█████████▊| 1.82G/1.87G [00:33<00:00, 53.7MiB/s]\u001b[A\n"," 98%|█████████▊| 1.83G/1.87G [00:33<00:00, 54.1MiB/s]\u001b[A\n"," 98%|█████████▊| 1.84G/1.87G [00:33<00:00, 53.8MiB/s]\u001b[A\n"," 99%|█████████▊| 1.84G/1.87G [00:34<00:00, 54.0MiB/s]\u001b[A\n"," 99%|█████████▉| 1.85G/1.87G [00:34<00:00, 54.2MiB/s]\u001b[A\n"," 99%|█████████▉| 1.85G/1.87G [00:34<00:00, 54.5MiB/s]\u001b[A\n"," 99%|█████████▉| 1.86G/1.87G [00:34<00:00, 54.6MiB/s]\u001b[A\n","100%|█████████▉| 1.86G/1.87G [00:34<00:00, 54.5MiB/s]\u001b[A"]}],"source":["# Define the path where XTTS v2.0.1 files will be downloaded\n","CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n","os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n","\n","# DVAE files\n","DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n","MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n","\n","# Set the path to the downloaded files\n","DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n","MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n","\n","# download DVAE files if needed\n","if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n","    print(\" > Downloading DVAE files!\")\n","    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n","\n","# Download XTTS v2.0 checkpoint if needed\n","TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n","XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n","\n","# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n","TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n","XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n","\n","# download XTTS v2.0 files if needed\n","if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n","    print(\" > Downloading XTTS v2.0 files!\")\n","    ModelManager._download_model_files(\n","        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n","    )"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:13.671128Z","iopub.status.busy":"2024-10-14T05:29:13.670732Z","iopub.status.idle":"2024-10-14T05:29:13.675681Z","shell.execute_reply":"2024-10-14T05:29:13.674701Z","shell.execute_reply.started":"2024-10-14T05:29:13.671090Z"},"trusted":true},"outputs":[],"source":["training_dir = \"/kaggle/input/hindi-speech1\""]},{"cell_type":"markdown","metadata":{},"source":["### Batch Size ###\n","\n","* BATCH_SIZE is the amount of items being loaded into VRAM/memory at once.\n","\n","* GRAD_ACCUM_STEPS is the amount of times we perform a forward pass with BATCH_SIZE amount of items before updating the parameters according to the SGD algorithm.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:18.134360Z","iopub.status.busy":"2024-10-14T05:29:18.133670Z","iopub.status.idle":"2024-10-14T05:29:18.138923Z","shell.execute_reply":"2024-10-14T05:29:18.137821Z","shell.execute_reply.started":"2024-10-14T05:29:18.134291Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1.87G/1.87G [00:45<00:00, 54.5MiB/s]\u001b[A"]}],"source":["\n","OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  \n","START_WITH_EVAL = True  \n","BATCH_SIZE = 1\n","GRAD_ACUMM_STEPS = 252\n","LANGUAGE = \"hi\""]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T19:20:31.458736Z","iopub.status.busy":"2024-10-13T19:20:31.458305Z","iopub.status.idle":"2024-10-13T19:20:31.473609Z","shell.execute_reply":"2024-10-13T19:20:31.472548Z","shell.execute_reply.started":"2024-10-13T19:20:31.458694Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample rate: 8000 Hz\n"]}],"source":["import librosa\n","\n","# Load the audio file\n","audio_path = \"/kaggle/input/hindi-speech1/wavs/0001_030.wav\"\n","audio, sample_rate = librosa.load(audio_path, sr=None)  # sr=None preserves the original sample rate\n","\n","print(f\"Sample rate: {sample_rate} Hz\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:33.548697Z","iopub.status.busy":"2024-10-14T05:29:33.548204Z","iopub.status.idle":"2024-10-14T05:29:40.275361Z","shell.execute_reply":"2024-10-14T05:29:40.274387Z","shell.execute_reply.started":"2024-10-14T05:29:33.548640Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Min length: 8480 samples\n","Max length: 82720 samples\n"]}],"source":["import os\n","import wave\n","\n","wav_folder = \"/kaggle/input/hindi-speech1/wavs\"\n","sample_rate = 8000   # Replace with the actual sample rate of your dataset\n","\n","min_length = float('inf')\n","max_length = 0\n","\n","for wav_file in os.listdir(wav_folder):\n","    if wav_file.endswith('.wav'):\n","        with wave.open(os.path.join(wav_folder, wav_file), 'r') as wav:\n","            frames = wav.getnframes()\n","            duration = frames / float(wav.getframerate())  # in seconds\n","            length_in_samples = int(duration * sample_rate)\n","\n","            # Update min and max lengths\n","            if length_in_samples < min_length:\n","                min_length = length_in_samples\n","            if length_in_samples > max_length:\n","                max_length = length_in_samples\n","\n","print(f\"Min length: {min_length} samples\")\n","print(f\"Max length: {max_length} samples\")"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Config ###\n","\n","Note that the lengths below are lengths of WAV files. So if your WAV file has a sample rate of 22050, then a a max_wav_length of 370000 is: 370000/22050 = ~16.78 seconds long.\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:40.277245Z","iopub.status.busy":"2024-10-14T05:29:40.276936Z","iopub.status.idle":"2024-10-14T05:29:40.284722Z","shell.execute_reply":"2024-10-14T05:29:40.283963Z","shell.execute_reply.started":"2024-10-14T05:29:40.277212Z"},"trusted":true},"outputs":[],"source":["model_args = GPTArgs(\n","    max_conditioning_length=82720,  # Increased to accommodate longer audio files\n","    min_conditioning_length=8480,   \n","    debug_loading_failures=True,\n","    max_wav_length=82720,           # Increased to handle the longest audio file (675507)\n","    max_text_length=1000,             # Increased to handle longer text inputs\n","    mel_norm_file=MEL_NORM_FILE,\n","    dvae_checkpoint=DVAE_CHECKPOINT,\n","    xtts_checkpoint=XTTS_CHECKPOINT,  \n","    tokenizer_file=TOKENIZER_FILE,\n","    gpt_num_audio_tokens=1026, \n","    gpt_start_audio_token=1024,\n","    gpt_stop_audio_token=1025,      \n","    gpt_use_masking_gt_prompt_approach=True,\n","    gpt_use_perceiver_resampler=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Audio Config ###\n","\n","The coqui TTS docs mention inspecting your data with the CheckSpectrograms.ipynb notebook to help decide on audio parameters. I think this is irrelevant for XTTS-v2, because it doesn't use the same audio config as some of the older coqui models and doesn't have the same parameters.\n","\n","The default is 22050 for input and 24000 for output. "]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:43.990501Z","iopub.status.busy":"2024-10-14T05:29:43.989738Z","iopub.status.idle":"2024-10-14T05:29:43.994684Z","shell.execute_reply":"2024-10-14T05:29:43.993738Z","shell.execute_reply.started":"2024-10-14T05:29:43.990460Z"},"trusted":true},"outputs":[],"source":["audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)"]},{"cell_type":"markdown","metadata":{},"source":["### Speaker Reference ###\n","\n","This is the audio file that will be used for creating the conditioning latent and speaker embedding.\n","\n","Choosing the right speaker reference is **VERY** important for XTTS-v2. It can completely change how your model will sound. Even two clips taken from the same recording of the same speaker can produce markedly different outputs. Unfortunately I can't provide an algorithm for selecting this. I recommend that you manually go through your dataset and select approximately 10 clips of your speaker where they are saying a full sentence with an intonation/rythm/speed/style that sounds pretty good. Then just experiment with all of them and find one you like. This is especially important at inference time.\n","\n","Note that you can give a speaker reference that 'doesn't belong' to your model. "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:49.665434Z","iopub.status.busy":"2024-10-14T05:29:49.664624Z","iopub.status.idle":"2024-10-14T05:29:49.669487Z","shell.execute_reply":"2024-10-14T05:29:49.668388Z","shell.execute_reply.started":"2024-10-14T05:29:49.665390Z"},"trusted":true},"outputs":[],"source":["SPEAKER_REFERENCE = \"/kaggle/input/hindi-speech1/wavs/0001_030.wav\""]},{"cell_type":"markdown","metadata":{},"source":["### Trainer Config ###\n","\n","Fine-tune for about 100,000 dataset items but stop early if test outputs sound good; listening is better than just monitoring loss.\n","US male voices fine-tune faster; complex accents take longer.\n","Keep test sentences consistent for comparison across model runs."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:54.243054Z","iopub.status.busy":"2024-10-14T05:29:54.242333Z","iopub.status.idle":"2024-10-14T05:29:54.249800Z","shell.execute_reply":"2024-10-14T05:29:54.248790Z","shell.execute_reply.started":"2024-10-14T05:29:54.243012Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'/kaggle/input/hindi-speech1/wavs/0001_030.wav'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["SPEAKER_REFERENCE"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:29:56.616502Z","iopub.status.busy":"2024-10-14T05:29:56.615511Z","iopub.status.idle":"2024-10-14T05:30:07.956611Z","shell.execute_reply":"2024-10-14T05:30:07.955647Z","shell.execute_reply.started":"2024-10-14T05:29:56.616458Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(f, map_location=map_location, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/tortoise/arch_utils.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.mel_norms = torch.load(f)\n"]},{"name":"stdout","output_type":"stream","text":[">> DVAE weights restored from: /kaggle/working/run/XTTS_v2.0_original_model_files/dvae.pth\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py:185: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  dvae_checkpoint = torch.load(self.args.dvae_checkpoint, map_location=torch.device(\"cpu\"))\n"]}],"source":["config = GPTTrainerConfig(\n","    run_eval=True,\n","    epochs = 1000, # assuming you want to end training manually w/ keyboard interrupt\n","    output_path=OUT_PATH,\n","    model_args=model_args,\n","    run_name=RUN_NAME,\n","    project_name=PROJECT_NAME,\n","    run_description=\"\"\"\n","        GPT XTTS training\n","        \"\"\",\n","    dashboard_logger=DASHBOARD_LOGGER,\n","    wandb_entity=None,\n","    logger_uri=LOGGER_URI,\n","    audio=audio_config,\n","    batch_size=BATCH_SIZE,\n","    batch_group_size=48,\n","    eval_batch_size=BATCH_SIZE,\n","    num_loader_workers=8, #consider decreasing if your jupyter env is crashing or similar\n","    eval_split_max_size=256, \n","    print_step=50, \n","    plot_step=100, \n","    log_model_step=1000, \n","    save_step=9999999999, #ALREADY SAVES EVERY EPOCHMaking this high on kaggle because Output dir is limited in size. I changed this to be size of training set/2 so I would effectively have a checkpoint every half epoch \n","    save_n_checkpoints=1,#if you want to store multiple checkpoint rather than just 1, increase this\n","    save_checkpoints=False,# Making this False on kaggle because Output dir is limited\n","    print_eval=False,\n","    optimizer=\"AdamW\",\n","    optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n","    optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n","    lr=5e-06,  \n","    lr_scheduler=\"MultiStepLR\",\n","    lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n","    test_sentences=[ \n","        {\n","            \"text\": \"भारत एक विशाल और विविधतापूर्ण देश है।\",\n","            \"speaker_wav\": SPEAKER_REFERENCE,\n","            \"language\": LANGUAGE,\n","        },\n","        {\n","            \"text\": \"हिंदी भारत की सबसे अधिक बोली जाने वाली भाषाओं में से एक है।\",\n","            \"speaker_wav\": SPEAKER_REFERENCE,\n","            \"language\": LANGUAGE,\n","        },\n","        {\n","            \"text\": \"ताजमहल भारत का एक प्रसिद्ध ऐतिहासिक स्मारक है।\",\n","            \"speaker_wav\": SPEAKER_REFERENCE,\n","            \"language\": LANGUAGE,\n","        }\n","        \n","    ],\n",") \n","\n","model = GPTTrainer.init_from_config(config)"]},{"cell_type":"markdown","metadata":{},"source":["### Load Dataset ###\n","\n","The evaluation set is 1% of the training data by default. This seems very low, but when you consider that you will probably want to evaluate performance by listening to tests rather than just comparing loss values."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:30:17.119984Z","iopub.status.busy":"2024-10-14T05:30:17.119585Z","iopub.status.idle":"2024-10-14T05:30:17.162964Z","shell.execute_reply":"2024-10-14T05:30:17.162164Z","shell.execute_reply.started":"2024-10-14T05:30:17.119947Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" | > Found 1099 files in /kaggle/input/hindi-speech1\n"]}],"source":["dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"deduplicated_transcripts1.txt\", language=LANGUAGE, path=training_dir\n",")\n","train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True, eval_split_size=0.02)"]},{"cell_type":"markdown","metadata":{},"source":["### Train! ###\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T05:30:20.552044Z","iopub.status.busy":"2024-10-14T05:30:20.551404Z","iopub.status.idle":"2024-10-14T06:16:51.449519Z","shell.execute_reply":"2024-10-14T06:16:51.447379Z","shell.execute_reply.started":"2024-10-14T05:30:20.552000Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    TrainerArgs(\n","        restore_path=None,\n","        skip_train_epoch=False,\n","        start_with_eval=START_WITH_EVAL,\n","        grad_accum_steps=GRAD_ACUMM_STEPS,\n","    ),\n","    config,\n","    output_path=OUT_PATH,\n","    model=model,\n","    train_samples=train_samples,\n","    eval_samples=eval_samples,\n",")\n","trainer.fit()"]},{"cell_type":"markdown","metadata":{},"source":["# Testing on Different Texts"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T06:24:09.488443Z","iopub.status.busy":"2024-10-14T06:24:09.487927Z","iopub.status.idle":"2024-10-14T06:25:01.210662Z","shell.execute_reply":"2024-10-14T06:25:01.209695Z","shell.execute_reply.started":"2024-10-14T06:24:09.488396Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n","RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .\n"," > Using model: xtts\n","/opt/conda/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(f, map_location=map_location, **kwargs)\n"," > Text: वह उसके पीछे भागा\n"," > Text splitted to sentences.\n","['वह उसके पीछे भागा']\n"," > Processing time: 16.48351764678955\n"," > Real-time factor: 3.5137428858440605\n"," > Saving output to /kaggle/working/run/kaggletest-October-14-2024_05+30AM-0000000/output_1.wav\n","\u001b[0m"]}],"source":["!tts --text \"वह उसके पीछे भागा\" \\\n","    --model_path \"/kaggle/working/run/XTTS_v2.0_original_model_files\" \\\n","    --config_path \"/kaggle/working/run/kaggletest-October-14-2024_05+30AM-0000000/config.json\" \\\n","    --out_path \"/kaggle/working/run/kaggletest-October-14-2024_05+30AM-0000000/output_1.wav\" \\\n","    --language_idx hi \\\n","    --speaker_wav \"/kaggle/input/hindi-speech1/wavs/0001_030.wav\"\n"]},{"cell_type":"markdown","metadata":{},"source":["Your fine-tuned model will be stored in /kaggle/working/run"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T06:32:13.653200Z","iopub.status.busy":"2024-10-14T06:32:13.652201Z","iopub.status.idle":"2024-10-14T06:34:03.313381Z","shell.execute_reply":"2024-10-14T06:34:03.312230Z","shell.execute_reply.started":"2024-10-14T06:32:13.653154Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/run/XTTS_v2.0_original_model_files/ (stored 0%)\n","  adding: kaggle/working/run/XTTS_v2.0_original_model_files/mel_stats.pth (deflated 37%)\n","  adding: kaggle/working/run/XTTS_v2.0_original_model_files/model.pth (deflated 7%)\n","  adding: kaggle/working/run/XTTS_v2.0_original_model_files/dvae.pth (deflated 7%)\n","  adding: kaggle/working/run/XTTS_v2.0_original_model_files/vocab.json (deflated 81%)\n","Zip file created: /kaggle/working/checkpoint-1000.zip\n"]}],"source":["import os\n","\n","# Define the path to the checkpoint\n","checkpoint_path = \"/kaggle/working/run/XTTS_v2.0_original_model_files\"\n","\n","# Create a zip file name\n","zip_name = \"checkpoint-1000.zip\"\n","\n","# Create the zip file\n","!zip -r /kaggle/working/{zip_name} {checkpoint_path}\n","\n","print(f\"Zip file created: /kaggle/working/{zip_name}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5869263,"sourceId":9617230,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
